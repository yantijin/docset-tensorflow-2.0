<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.tpu.experimental.DeviceAssignment" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="core_assignment"/>
<meta itemprop="property" content="num_cores_per_replica"/>
<meta itemprop="property" content="num_replicas"/>
<meta itemprop="property" content="topology"/>
<meta itemprop="property" content="__init__"/>
<meta itemprop="property" content="build"/>
<meta itemprop="property" content="coordinates"/>
<meta itemprop="property" content="host_device"/>
<meta itemprop="property" content="lookup_replicas"/>
<meta itemprop="property" content="tpu_device"/>
<meta itemprop="property" content="tpu_ordinal"/>
</div>


<h1>tf.tpu.experimental.DeviceAssignment</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p><a target="_blank" href="/code/stable/tensorflow/python/tpu/device_assignment.py">View source</a></p>

<h2>Class <code>DeviceAssignment</code></h2>

<!-- Start diff -->


<p>Mapping from logical cores in a computation to the physical TPU topology.</p>

<h3>Aliases:</h3>

<ul>
<li>Class <code>tf.compat.v1.tpu.experimental.DeviceAssignment</code></li>
<li>Class <code>tf.compat.v2.tpu.experimental.DeviceAssignment</code></li>
</ul>


<!-- Placeholder for "Used in" -->


<p>Prefer to use the <a href="../../../tf/tpu/experimental/DeviceAssignment.html#build"><code>DeviceAssignment.build()</code></a> helper to construct a
<code>DeviceAssignment</code>; it is easier if less flexible than constructing a
<code>DeviceAssignment</code> directly.</p>

<h2 id="__init__"><code>__init__</code></h2>


<p><a target="_blank" href="/code/stable/tensorflow/python/tpu/device_assignment.py">View source</a></p>

<p><code>python
__init__(
    topology,
    core_assignment
)
</code></p>

<p>Constructs a <code>DeviceAssignment</code> object.</p>

<h4>Args:</h4>

<ul>
<li><b><code>topology</code></b>: A <code>Topology</code> object that describes the physical TPU topology.</li>
<li><b><code>core_assignment</code></b>: A logical to physical core mapping, represented as a
rank 3 numpy array. See the description of the <code>core_assignment</code>
property for more details.</li>
</ul>


<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: If <code>topology</code> is not <code>Topology</code> object.</li>
<li><b><code>ValueError</code></b>: If <code>core_assignment</code> is not a rank 3 numpy array.</li>
</ul>


<h2>Properties</h2>

<h3 id="core_assignment"><code>core_assignment</code></h3>


<p>The logical to physical core mapping.</p>

<h4>Returns:</h4>

<p>An integer numpy array of rank 3, with shape
<code>[num_replicas, num_cores_per_replica, topology_rank]</code>. Maps
(replica, logical core) pairs to physical topology coordinates.</p>

<h3 id="num_cores_per_replica"><code>num_cores_per_replica</code></h3>


<p>The number of cores per replica.</p>

<h3 id="num_replicas"><code>num_replicas</code></h3>


<p>The number of replicas of the computation.</p>

<h3 id="topology"><code>topology</code></h3>


<p>A <code>Topology</code> that describes the TPU topology.</p>

<h2>Methods</h2>

<h3 id="build"><code>build</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/tpu/device_assignment.py">View source</a></p>

<p><code>python
@staticmethod
build(
    topology,
    computation_shape=None,
    computation_stride=None,
    num_replicas=1
)
</code></p>

<h3 id="coordinates"><code>coordinates</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/tpu/device_assignment.py">View source</a></p>

<p><code>python
coordinates(
    replica,
    logical_core
)
</code></p>

<p>Returns the physical topology coordinates of a logical core.</p>

<h3 id="host_device"><code>host_device</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/tpu/device_assignment.py">View source</a></p>

<p><code>python
host_device(
    replica=0,
    logical_core=0,
    job=None
)
</code></p>

<p>Returns the CPU device attached to a logical core.</p>

<h3 id="lookup_replicas"><code>lookup_replicas</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/tpu/device_assignment.py">View source</a></p>

<p><code>python
lookup_replicas(
    task_id,
    logical_core
)
</code></p>

<p>Lookup replica ids by task number and logical core.</p>

<h4>Args:</h4>

<ul>
<li><b><code>task_id</code></b>: TensorFlow task number.</li>
<li><b><code>logical_core</code></b>: An integer, identifying a logical core.</li>
</ul>


<h4>Returns:</h4>

<p>A sorted list of the replicas that are attached to that task and
logical_core.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: If no replica exists in the task which contains the logical
core.</li>
</ul>


<h3 id="tpu_device"><code>tpu_device</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/tpu/device_assignment.py">View source</a></p>

<p><code>python
tpu_device(
    replica=0,
    logical_core=0,
    job=None
)
</code></p>

<p>Returns the name of the TPU device assigned to a logical core.</p>

<h3 id="tpu_ordinal"><code>tpu_ordinal</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/tpu/device_assignment.py">View source</a></p>

<p><code>python
tpu_ordinal(
    replica=0,
    logical_core=0
)
</code></p>

<p>Returns the ordinal of the TPU device assigned to a logical core.</p>
