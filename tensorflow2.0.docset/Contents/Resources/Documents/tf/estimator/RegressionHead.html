<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.estimator.RegressionHead" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="logits_dimension"/>
<meta itemprop="property" content="loss_reduction"/>
<meta itemprop="property" content="name"/>
<meta itemprop="property" content="__init__"/>
<meta itemprop="property" content="create_estimator_spec"/>
<meta itemprop="property" content="loss"/>
<meta itemprop="property" content="metrics"/>
<meta itemprop="property" content="predictions"/>
<meta itemprop="property" content="update_metrics"/>
</div>


<h1>tf.estimator.RegressionHead</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">

<td>
  <a target="_blank" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/regression_head.py">
    <img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" />
    View source on GitHub
  </a>
</td></table>


<h2>Class <code>RegressionHead</code></h2>

<!-- Start diff -->


<p>Creates a <code>Head</code> for regression using the <code>mean_squared_error</code> loss.</p>

<p>Inherits From: <a href="../../tf/estimator/Head.html"><code>Head</code></a></p>

<h3>Aliases:</h3>

<ul>
<li>Class <code>tf.compat.v1.estimator.RegressionHead</code></li>
<li>Class <code>tf.compat.v2.estimator.RegressionHead</code></li>
</ul>


<!-- Placeholder for "Used in" -->


<p>The loss is the weighted sum over all input dimensions. Namely, if the input
labels have shape <code>[batch_size, label_dimension]</code>, the loss is the weighted
sum over both <code>batch_size</code> and <code>label_dimension</code>.</p>

<p>The head expects <code>logits</code> with shape <code>[D0, D1, ... DN, label_dimension]</code>.
In many applications, the shape is <code>[batch_size, label_dimension]</code>.</p>

<p>The <code>labels</code> shape must match <code>logits</code>, namely
<code>[D0, D1, ... DN, label_dimension]</code>. If <code>label_dimension=1</code>, shape
<code>[D0, D1, ... DN]</code> is also supported.</p>

<p>If <code>weight_column</code> is specified, weights must be of shape
<code>[D0, D1, ... DN]</code>, <code>[D0, D1, ... DN, 1]</code> or
<code>[D0, D1, ... DN, label_dimension]</code>.</p>

<p>Supports custom <code>loss_fn</code>. <code>loss_fn</code> takes <code>(labels, logits)</code> or
<code>(labels, logits, features, loss_reduction)</code> as arguments and returns
unreduced loss with shape <code>[D0, D1, ... DN, label_dimension]</code>.</p>

<p>Also supports custom <code>inverse_link_fn</code>, also known as &lsquo;mean function&rsquo;.
<code>inverse_link_fn</code> is only used in <code>PREDICT</code> mode. It takes <code>logits</code> as
argument and returns predicted values. This function is the inverse of the
link function defined in
https://en.wikipedia.org/wiki/Generalized_linear_model#Link_function
Namely, for poisson regression, set <code>inverse_link_fn=tf.exp</code>.</p>

<p>The head can be used with a canned estimator. Example:</p>

<p><code>python
my_head = tf.estimator.RegressionHead()
my_estimator = tf.estimator.DNNEstimator(
    head=my_head,
    hidden_units=...,
    feature_columns=...)
</code></p>

<p>It can also be used with a custom <code>model_fn</code>. Example:</p>

<p>```python
def _my_model_fn(features, labels, mode):
  my_head = tf.estimator.RegressionHead()
  logits = tf.keras.Model(&hellip;)(features)</p>

<p>  return my_head.create_estimator_spec(
      features=features,
      mode=mode,
      labels=labels,
      optimizer=tf.keras.optimizers.Adagrad(lr=0.1),
      logits=logits)</p>

<p>my_estimator = tf.estimator.Estimator(model_fn=_my_model_fn)
```</p>

<h4>Args:</h4>

<ul>
<li><b><code>weight_column</code></b>: A string or a <code>NumericColumn</code> created by
<a href="../../tf/feature_column/numeric_column.html"><code>tf.feature_column.numeric_column</code></a> defining feature column representing
weights. It is used to down weight or boost examples during training. It
will be multiplied by the loss of the example.</li>
<li><b><code>label_dimension</code></b>: Number of regression labels per example. This is the size
of the last dimension of the labels <code>Tensor</code> (typically, this has shape
<code>[batch_size, label_dimension]</code>).</li>
<li><b><code>loss_reduction</code></b>: One of <a href="../../tf/keras/losses/Reduction.html"><code>tf.losses.Reduction</code></a> except <code>NONE</code>. Decides how to
reduce training loss over batch and label dimension. Defaults to
<code>SUM_OVER_BATCH_SIZE</code>, namely weighted sum of losses divided by
<code>batch size * label_dimension</code>.</li>
<li><b><code>loss_fn</code></b>: Optional loss function. Defaults to <code>mean_squared_error</code>.</li>
<li><b><code>inverse_link_fn</code></b>: Optional inverse link function, also known as &lsquo;mean
function&rsquo;. Defaults to identity.</li>
<li><b><code>name</code></b>: name of the head. If provided, summary and metrics keys will be
suffixed by <code>"/" + name</code>. Also used as <code>name_scope</code> when creating ops.</li>
</ul>


<h2 id="__init__"><code>__init__</code></h2>


<p><a target="_blank" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/regression_head.py">View source</a></p>

<p><code>python
__init__(
    label_dimension=1,
    weight_column=None,
    loss_reduction=losses_utils.ReductionV2.SUM_OVER_BATCH_SIZE,
    loss_fn=None,
    inverse_link_fn=None,
    name=None
)
</code></p>

<p>Initialize self.  See help(type(self)) for accurate signature.</p>

<h2>Properties</h2>

<h3 id="logits_dimension"><code>logits_dimension</code></h3>


<p>See <code>base_head.Head</code> for details.</p>

<h3 id="loss_reduction"><code>loss_reduction</code></h3>


<p>See <code>base_head.Head</code> for details.</p>

<h3 id="name"><code>name</code></h3>


<p>See <code>base_head.Head</code> for details.</p>

<h2>Methods</h2>

<h3 id="create_estimator_spec"><code>create_estimator_spec</code></h3>


<p><a target="_blank" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/base_head.py">View source</a></p>

<p><code>python
create_estimator_spec(
    features,
    mode,
    logits,
    labels=None,
    optimizer=None,
    trainable_variables=None,
    train_op_fn=None,
    update_ops=None,
    regularization_losses=None
)
</code></p>

<p>Returns <code>EstimatorSpec</code> that a model_fn can return.</p>

<p>It is recommended to pass all args via name.</p>

<h4>Args:</h4>

<ul>
<li><b><code>features</code></b>: Input <code>dict</code> mapping string feature names to <code>Tensor</code> or
<code>SparseTensor</code> objects containing the values for that feature in a
minibatch. Often to be used to fetch example-weight tensor.</li>
<li><b><code>mode</code></b>: Estimator&rsquo;s <code>ModeKeys</code>.</li>
<li><b><code>logits</code></b>: Logits <code>Tensor</code> to be used by the head.</li>
<li><b><code>labels</code></b>: Labels <code>Tensor</code>, or <code>dict</code> mapping string label names to <code>Tensor</code>
objects of the label values.</li>
<li><b><code>optimizer</code></b>: An <a href="../../tf/keras/optimizers/Optimizer.html"><code>tf.keras.optimizers.Optimizer</code></a> instance to optimize the
loss in TRAIN mode. Namely, sets <code>train_op = optimizer.get_updates(loss,
trainable_variables)</code>, which updates variables to minimize <code>loss</code>.</li>
<li><b><code>trainable_variables</code></b>: A list or tuple of <code>Variable</code> objects to update to
minimize <code>loss</code>. In Tensorflow 1.x, by default these are the list of
variables collected in the graph under the key
<code>GraphKeys.TRAINABLE_VARIABLES</code>. As Tensorflow 2.x doesn&rsquo;t have
collections and GraphKeys, trainable_variables need to be passed
explicitly here.</li>
<li><b><code>train_op_fn</code></b>: Function that takes a scalar loss <code>Tensor</code> and returns an op
to optimize the model with the loss in TRAIN mode. Used if <code>optimizer</code>
is <code>None</code>. Exactly one of <code>train_op_fn</code> and <code>optimizer</code> must be set in
TRAIN mode. By default, it is <code>None</code> in other modes. If you want to
optimize loss yourself, you can pass <code>lambda _: tf.no_op()</code> and then use
<a href="../../tf/estimator/EstimatorSpec.html#loss"><code>EstimatorSpec.loss</code></a> to compute and apply gradients.</li>
<li><b><code>update_ops</code></b>: A list or tuple of update ops to be run at training time. For
example, layers such as BatchNormalization create mean and variance
update ops that need to be run at training time. In Tensorflow 1.x,
these are thrown into an UPDATE_OPS collection. As Tensorflow 2.x
doesn&rsquo;t have collections, update_ops need to be passed explicitly here.</li>
<li><b><code>regularization_losses</code></b>: A list of additional scalar losses to be added to
the training loss, such as regularization losses.</li>
</ul>


<h4>Returns:</h4>

<p><code>EstimatorSpec</code>.</p>

<h3 id="loss"><code>loss</code></h3>


<p><a target="_blank" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/regression_head.py">View source</a></p>

<p><code>python
loss(
    labels,
    logits,
    features=None,
    mode=None,
    regularization_losses=None
)
</code></p>

<p>Return predictions based on keys. See <code>base_head.Head</code> for details.</p>

<h3 id="metrics"><code>metrics</code></h3>


<p><a target="_blank" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/regression_head.py">View source</a></p>

<p><code>python
metrics(regularization_losses=None)
</code></p>

<p>Creates metrics. See <code>base_head.Head</code> for details.</p>

<h3 id="predictions"><code>predictions</code></h3>


<p><a target="_blank" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/regression_head.py">View source</a></p>

<p><code>python
predictions(logits)
</code></p>

<p>Return predictions based on keys.  See <code>base_head.Head</code> for details.</p>

<h4>Args:</h4>

<ul>
<li><b><code>logits</code></b>: logits <code>Tensor</code> with shape <code>[D0, D1, ... DN, logits_dimension]</code>.
For many applications, the shape is <code>[batch_size, logits_dimension]</code>.</li>
</ul>


<h4>Returns:</h4>

<p>A dict of predictions.</p>

<h3 id="update_metrics"><code>update_metrics</code></h3>


<p><a target="_blank" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/regression_head.py">View source</a></p>

<p><code>python
update_metrics(
    eval_metrics,
    features,
    logits,
    labels,
    regularization_losses=None
)
</code></p>

<p>Updates eval metrics. See <code>base_head.Head</code> for details.</p>
