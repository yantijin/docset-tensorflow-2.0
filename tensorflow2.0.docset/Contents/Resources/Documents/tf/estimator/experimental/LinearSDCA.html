<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.estimator.experimental.LinearSDCA" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="__init__"/>
<meta itemprop="property" content="get_train_step"/>
</div>


<h1>tf.estimator.experimental.LinearSDCA</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">

<td>
  <a target="_blank" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/canned/linear.py">
    <img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" />
    View source on GitHub
  </a>
</td></table>


<h2>Class <code>LinearSDCA</code></h2>

<!-- Start diff -->


<p>Stochastic Dual Coordinate Ascent helper for linear estimators.</p>

<h3>Aliases:</h3>

<ul>
<li>Class <code>tf.compat.v1.estimator.experimental.LinearSDCA</code></li>
<li>Class <code>tf.compat.v2.estimator.experimental.LinearSDCA</code></li>
</ul>


<!-- Placeholder for "Used in" -->


<p>Objects of this class are intended to be provided as the optimizer argument
(though LinearSDCA objects do not implement the <code>tf.train.Optimizer</code> interface)
when creating <a href="../../../tf/estimator/LinearClassifier.html"><code>tf.estimator.LinearClassifier</code></a> or <a href="../../../tf/estimator/LinearRegressor.html"><code>tf.estimator.LinearRegressor</code></a>.</p>

<p>SDCA can only be used with <code>LinearClassifier</code> and <code>LinearRegressor</code> under the
following conditions:</p>

<ul>
<li>Feature columns are of type V2.</li>
<li>Multivalent categorical columns are not normalized. In other words the
<code>sparse_combiner</code> argument in the estimator constructor should be &ldquo;sum&rdquo;.</li>
<li>For classification: binary label.</li>
<li>For regression: one-dimensional label.</li>
</ul>


<h4>Example usage:</h4>

<p><code>python
real_feature_column = numeric_column(...)
sparse_feature_column = categorical_column_with_hash_bucket(...)
linear_sdca = tf.estimator.experimental.LinearSDCA(
    example_id_column='example_id',
    num_loss_partitions=1,
    num_table_shards=1,
    symmetric_l2_regularization=2.0)
classifier = tf.estimator.LinearClassifier(
    feature_columns=[real_feature_column, sparse_feature_column],
    weight_column=...,
    optimizer=linear_sdca)
classifier.train(input_fn_train, steps=50)
classifier.evaluate(input_fn=input_fn_eval)
</code></p>

<p>Here the expectation is that the <code>input_fn_*</code> functions passed to train and
evaluate return a pair (dict, label_tensor) where dict has <code>example_id_column</code>
as <code>key</code> whose value is a <code>Tensor</code> of shape [batch_size] and dtype string.
num_loss_partitions defines sigma' in eq (11) of [3]. Convergence of (global)
loss is guaranteed if <code>num_loss_partitions</code> is larger or equal to the product
<code>(#concurrent train ops/per worker) x (#workers)</code>. Larger values for
<code>num_loss_partitions</code> lead to slower convergence. The recommended value for
<code>num_loss_partitions</code> in <a href="../../../tf/estimator.html"><code>tf.estimator</code></a> (where currently there is one process
per worker) is the number of workers running the train steps. It defaults to 1
(single machine).
<code>num_table_shards</code> defines the number of shards for the internal state
table, typically set to match the number of parameter servers for large
data sets.</p>

<p>The SDCA algorithm was originally introduced in [1] and it was followed by
the L1 proximal step [2], a distributed version [3] and adaptive sampling [4].
[1] www.jmlr.org/papers/volume14/shalev-shwartz13a/shalev-shwartz13a.pdf
[2] https://arxiv.org/pdf/1309.2375.pdf
[3] https://arxiv.org/pdf/1502.03508.pdf
[4] https://arxiv.org/pdf/1502.08053.pdf
Details specific to this implementation are provided in:
https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/canned/linear_optimizer/doc/sdca.ipynb</p>

<h2 id="__init__"><code>__init__</code></h2>


<p><a target="_blank" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/canned/linear.py">View source</a></p>

<p><code>python
__init__(
    example_id_column,
    num_loss_partitions=1,
    num_table_shards=None,
    symmetric_l1_regularization=0.0,
    symmetric_l2_regularization=1.0,
    adaptive=False
)
</code></p>

<p>Construct a new SDCA optimizer for linear estimators.</p>

<h4>Args:</h4>

<ul>
<li><b><code>example_id_column</code></b>: The column name containing the example ids.</li>
<li><b><code>num_loss_partitions</code></b>: Number of workers.</li>
<li><b><code>num_table_shards</code></b>: Number of shards of the internal state table, typically
set to match the number of parameter servers.</li>
<li><b><code>symmetric_l1_regularization</code></b>: A float value, must be greater than or
equal to zero.</li>
<li><b><code>symmetric_l2_regularization</code></b>: A float value, must be greater than zero and
should typically be greater than 1.</li>
<li><b><code>adaptive</code></b>: A boolean indicating whether to use adaptive sampling.</li>
</ul>


<h2>Methods</h2>

<h3 id="get_train_step"><code>get_train_step</code></h3>


<p><a target="_blank" href="https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/canned/linear.py">View source</a></p>

<p><code>python
get_train_step(
    state_manager,
    weight_column_name,
    loss_type,
    feature_columns,
    features,
    targets,
    bias_var,
    global_step
)
</code></p>

<p>Returns the training operation of an SdcaModel optimizer.</p>
