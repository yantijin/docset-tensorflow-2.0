<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.keras.layers.Layer" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="activity_regularizer"/>
<meta itemprop="property" content="dtype"/>
<meta itemprop="property" content="dynamic"/>
<meta itemprop="property" content="input"/>
<meta itemprop="property" content="input_mask"/>
<meta itemprop="property" content="input_shape"/>
<meta itemprop="property" content="input_spec"/>
<meta itemprop="property" content="losses"/>
<meta itemprop="property" content="metrics"/>
<meta itemprop="property" content="name"/>
<meta itemprop="property" content="non_trainable_variables"/>
<meta itemprop="property" content="non_trainable_weights"/>
<meta itemprop="property" content="output"/>
<meta itemprop="property" content="output_mask"/>
<meta itemprop="property" content="output_shape"/>
<meta itemprop="property" content="trainable"/>
<meta itemprop="property" content="trainable_variables"/>
<meta itemprop="property" content="trainable_weights"/>
<meta itemprop="property" content="updates"/>
<meta itemprop="property" content="variables"/>
<meta itemprop="property" content="weights"/>
<meta itemprop="property" content="__call__"/>
<meta itemprop="property" content="__init__"/>
<meta itemprop="property" content="add_loss"/>
<meta itemprop="property" content="add_metric"/>
<meta itemprop="property" content="add_update"/>
<meta itemprop="property" content="add_weight"/>
<meta itemprop="property" content="build"/>
<meta itemprop="property" content="call"/>
<meta itemprop="property" content="compute_mask"/>
<meta itemprop="property" content="compute_output_shape"/>
<meta itemprop="property" content="compute_output_signature"/>
<meta itemprop="property" content="count_params"/>
<meta itemprop="property" content="from_config"/>
<meta itemprop="property" content="get_config"/>
<meta itemprop="property" content="get_input_at"/>
<meta itemprop="property" content="get_input_mask_at"/>
<meta itemprop="property" content="get_input_shape_at"/>
<meta itemprop="property" content="get_losses_for"/>
<meta itemprop="property" content="get_output_at"/>
<meta itemprop="property" content="get_output_mask_at"/>
<meta itemprop="property" content="get_output_shape_at"/>
<meta itemprop="property" content="get_updates_for"/>
<meta itemprop="property" content="get_weights"/>
<meta itemprop="property" content="set_weights"/>
</div>


<h1>tf.keras.layers.Layer</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<h2>Class <code>Layer</code></h2>

<!-- Start diff -->


<p>Base layer class.</p>

<p>Inherits From: <a href="../../../tf/Module.html"><code>Module</code></a></p>

<h3>Aliases:</h3>

<ul>
<li>Class <code>tf.compat.v1.keras.layers.Layer</code></li>
<li>Class <code>tf.compat.v2.keras.layers.Layer</code></li>
</ul>


<!-- Placeholder for "Used in" -->


<p>This is the class from which all layers inherit.</p>

<p>A layer is a class implementing common neural networks operations, such
as convolution, batch norm, etc. These operations require managing weights,
losses, updates, and inter-layer connectivity.</p>

<p>Users will just instantiate a layer and then treat it as a callable.</p>

<p>We recommend that descendants of <code>Layer</code> implement the following methods:</p>

<ul>
<li><code>__init__()</code>: Save configuration in member variables</li>
<li><code>build()</code>: Called once from <code>__call__</code>, when we know the shapes of inputs
and <code>dtype</code>. Should have the calls to <code>add_weight()</code>, and then
call the super&rsquo;s <code>build()</code> (which sets <code>self.built = True</code>, which is
nice in case the user wants to call <code>build()</code> manually before the
first <code>__call__</code>).</li>
<li><code>call()</code>: Called in <code>__call__</code> after making sure <code>build()</code> has been called
once. Should actually perform the logic of applying the layer to the
input tensors (which should be passed in as the first argument).</li>
</ul>


<h4>Arguments:</h4>

<ul>
<li><b><code>trainable</code></b>: Boolean, whether the layer&rsquo;s variables should be trainable.</li>
<li><b><code>name</code></b>: String name of the layer.</li>
<li><b><code>dtype</code></b>: The dtype of the layer&rsquo;s computations and weights (default of
<code>None</code> means use <a href="../../../tf/keras/backend/floatx.html"><code>tf.keras.backend.floatx</code></a> in TensorFlow 2, or the type
of the first input in TensorFlow 1).</li>
<li><b><code>dynamic</code></b>: Set this to <code>True</code> if your layer should only be run eagerly, and
should not be used to generate a static computation graph.
This would be the case for a Tree-RNN or a recursive network,
for example, or generally for any layer that manipulates tensors
using Python control flow. If <code>False</code>, we assume that the layer can
safely be used to generate a static computation graph.</li>
</ul>


<p>Read-only properties:
  name: The name of the layer (string).
  dtype: The dtype of the layer&rsquo;s computations and weights. If mixed
    precision is used with a <a href="../../../tf/keras/mixed_precision/experimental/Policy.html"><code>tf.keras.mixed_precision.experimental.Policy</code></a>,
    this is instead just the dtype of the layer&rsquo;s weights, as the computations
    are done in a different dtype.
  updates: List of update ops of this layer.
  losses: List of losses added by this layer.
  trainable_weights: List of variables to be included in backprop.
  non_trainable_weights: List of variables that should not be
    included in backprop.
  weights: The concatenation of the lists trainable_weights and
    non_trainable_weights (in this order).</p>

<h4>Mutable properties:</h4>

<ul>
<li><b><code>trainable</code></b>: Whether the layer should be trained (boolean).</li>
<li><b><code>input_spec</code></b>: Optional (list of) <code>InputSpec</code> object(s) specifying the
constraints on inputs that can be accepted by the layer.</li>
</ul>


<h3>Dtypes and casting</h3>

<p>Each layer has a dtype, which is typically the dtype of the layer&rsquo;s
computations and variables. A layer&rsquo;s dtype can be queried via the
<a href="../../../tf/keras/layers/Layer.html#dtype"><code>Layer.dtype</code></a> property. The dtype is specified with the <code>dtype</code> constructor
argument. In TensorFlow 2, the dtype defaults to <a href="../../../tf/keras/backend/floatx.html"><code>tf.keras.backend.floatx()</code></a>
if no dtype is passed. <code>floatx()</code> itself defaults to &ldquo;float32&rdquo;. Additionally,
layers will cast their inputs to the layer&rsquo;s dtype in TensorFlow 2. For
example:</p>

<p>```
x = tf.ones((4, 4, 4, 4), dtype=&lsquo;float64&rsquo;)
layer = tf.keras.layers.Conv2D(filters=4, kernel_size=2)
print(layer.dtype)  # float32</p>

<h1><code>layer</code> casts it&rsquo;s inputs to layer.dtype, which is float32, and does</h1>

<h1>computations in float32.</h1>

<p>y = layer(x)
```</p>

<p>Currently, only tensors in the first argument to the layer&rsquo;s <code>call</code> method are
casted. For example:</p>

<p><code>``
class MyLayer(tf.keras.layers.Layer):
  # Bug!</code>b` will not be casted.
  def call(self, a, b):
    return a + 1., b + 1.</p>

<p>a = tf.constant(1., dtype=&ldquo;float32&rdquo;)
b = tf.constant(1., dtype=&ldquo;float32&rdquo;)</p>

<p>layer = MyLayer(dtype=&ldquo;float64&rdquo;)
x, y = layer(a, b)
print(x.dtype)  # float64
print(y.dtype)  # float32. Not casted since <code>b</code> was not passed to first input
```</p>

<p>It is recommended to accept tensors only in the first argument. This way,
all tensors are casted to the layer&rsquo;s dtype. <code>MyLayer</code> should therefore be
written as:</p>

<p>```
class MyLayer(tf.keras.layers.Layer):
  # Now, all tensor inputs will be casted.
  def call(self, inputs):
    a, b = inputs
    return a + 1., b + 1.</p>

<p>a = tf.constant(1., dtype=&ldquo;float32&rdquo;)
b = tf.constant(1., dtype=&ldquo;float32&rdquo;)</p>

<p>layer = MyLayer(dtype=&ldquo;float64&rdquo;)
x, y = layer((a, b))
print(x.dtype)  # float64
print(y.dtype)  # float64.
```</p>

<p>In a future minor release, tensors in other arguments may be casted as well.</p>

<p>Currently, other arguments are not automatically casted for
technical reasons, but this may change in a future minor release.</p>

<p>A layer subclass can prevent its inputs from being autocasted by passing
<code>autocast=False</code> to the layer constructor. For example:</p>

<p>```
class MyLayer(tf.keras.layers.Layer):</p>

<p>  def <strong>init</strong>(self, <strong>kwargs):
    kwargs[&lsquo;autocast&rsquo;]=False
    super(MyLayer, self).<strong>init</strong>(</strong>kwargs)</p>

<p>  def call(self, inp):
    return inp</p>

<p>x = tf.ones((4, 4, 4, 4), dtype=&lsquo;float64&rsquo;)
layer = MyLayer()
print(layer.dtype)  # float32.
y = layer(x)  # MyLayer will not cast inputs to it&rsquo;s dtype of float32
print(y.dtype)  # float64
```</p>

<h4>Running models in float64 in TensorFlow 2</h4>

<p>If you want to run a Model in float64, you can set floatx to be float64 by
calling <code>tf.keras.backend.set_floatx('float64')</code>. This will cause all layers
to default to float64 instead of float32:</p>

<p>```
tf.keras.backend.set_floatx(&lsquo;float64&rsquo;)
layer1 = tf.keras.layers.Dense(4)
layer2 = tf.keras.layers.Dense(4)</p>

<p>x = tf.ones((4, 4))
y = layer2(layer1(x))  # Both layers run in float64
```</p>

<p>Alternatively, you can pass <code>dtype='float64'</code> to each individual layer. Note
that if you have any layers which contain other layers as members, you must
ensure each sublayer gets <code>dtype='float64'</code> passed to it&rsquo;s constructor as
well:</p>

<p>```
layer1 = tf.keras.layers.Dense(4, dtype=&lsquo;float64&rsquo;)
layer2 = tf.keras.layers.Dense(4, dtype=&lsquo;float64&rsquo;)</p>

<p>x = tf.ones((4, 4))
y = layer2(layer1(x))  # Both layers run in float64</p>

<p>class NestedLayer(tf.keras.layers.Layer):
  def <strong>init</strong>(self, <strong>kwargs):
    super(NestedLayer, self).<strong>init</strong>(</strong>kwargs)
    self.dense = tf.keras.layers.Dense(4, dtype=kwargs.get(&lsquo;dtype&rsquo;))</p>

<p>  def call(self, inp):
    return self.dense(inp)</p>

<p>layer3 = NestedLayer(dtype=&lsquo;float64&rsquo;)
z = layer3(x)  # layer3&rsquo;s dense layer runs in float64, since NestedLayer
               # correcty passed it&rsquo;s dtype to it&rsquo;s dense layer</p>

<p>```</p>

<h2 id="__init__"><code>__init__</code></h2>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
__init__(
    trainable=True,
    name=None,
    dtype=None,
    dynamic=False,
    **kwargs
)
</code></p>

<h2>Properties</h2>

<h3 id="activity_regularizer"><code>activity_regularizer</code></h3>


<p>Optional regularizer function for the output of this layer.</p>

<h3 id="dtype"><code>dtype</code></h3>




<h3 id="dynamic"><code>dynamic</code></h3>




<h3 id="input"><code>input</code></h3>


<p>Retrieves the input tensor(s) of a layer.</p>

<p>Only applicable if the layer has exactly one input,
i.e. if it is connected to one incoming layer.</p>

<h4>Returns:</h4>

<p>Input tensor or list of input tensors.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>RuntimeError</code></b>: If called in Eager mode.</li>
<li><b><code>AttributeError</code></b>: If no inbound nodes are found.</li>
</ul>


<h3 id="input_mask"><code>input_mask</code></h3>


<p>Retrieves the input mask tensor(s) of a layer.</p>

<p>Only applicable if the layer has exactly one inbound node,
i.e. if it is connected to one incoming layer.</p>

<h4>Returns:</h4>

<p>Input mask tensor (potentially None) or list of input
mask tensors.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>AttributeError</code></b>: if the layer is connected to
more than one incoming layers.</li>
</ul>


<h3 id="input_shape"><code>input_shape</code></h3>


<p>Retrieves the input shape(s) of a layer.</p>

<p>Only applicable if the layer has exactly one input,
i.e. if it is connected to one incoming layer, or if all inputs
have the same shape.</p>

<h4>Returns:</h4>

<p>Input shape, as an integer shape tuple
(or list of shape tuples, one tuple per input tensor).</p>

<h4>Raises:</h4>

<ul>
<li><b><code>AttributeError</code></b>: if the layer has no defined input_shape.</li>
<li><b><code>RuntimeError</code></b>: if called in Eager mode.</li>
</ul>


<h3 id="input_spec"><code>input_spec</code></h3>




<h3 id="losses"><code>losses</code></h3>


<p>Losses which are associated with this <code>Layer</code>.</p>

<p>Variable regularization tensors are created when this property is accessed,
so it is eager safe: accessing <code>losses</code> under a <a href="../../../tf/GradientTape.html"><code>tf.GradientTape</code></a> will
propagate gradients back to the corresponding variables.</p>

<h4>Returns:</h4>

<p>A list of tensors.</p>

<h3 id="metrics"><code>metrics</code></h3>




<h3 id="name"><code>name</code></h3>


<p>Returns the name of this module as passed or determined in the ctor.</p>

<p>NOTE: This is not the same as the <code>self.name_scope.name</code> which includes
parent module names.</p>

<h3 id="non_trainable_variables"><code>non_trainable_variables</code></h3>




<h3 id="non_trainable_weights"><code>non_trainable_weights</code></h3>




<h3 id="output"><code>output</code></h3>


<p>Retrieves the output tensor(s) of a layer.</p>

<p>Only applicable if the layer has exactly one output,
i.e. if it is connected to one incoming layer.</p>

<h4>Returns:</h4>

<p>Output tensor or list of output tensors.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>AttributeError</code></b>: if the layer is connected to more than one incoming
layers.</li>
<li><b><code>RuntimeError</code></b>: if called in Eager mode.</li>
</ul>


<h3 id="output_mask"><code>output_mask</code></h3>


<p>Retrieves the output mask tensor(s) of a layer.</p>

<p>Only applicable if the layer has exactly one inbound node,
i.e. if it is connected to one incoming layer.</p>

<h4>Returns:</h4>

<p>Output mask tensor (potentially None) or list of output
mask tensors.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>AttributeError</code></b>: if the layer is connected to
more than one incoming layers.</li>
</ul>


<h3 id="output_shape"><code>output_shape</code></h3>


<p>Retrieves the output shape(s) of a layer.</p>

<p>Only applicable if the layer has one output,
or if all outputs have the same shape.</p>

<h4>Returns:</h4>

<p>Output shape, as an integer shape tuple
(or list of shape tuples, one tuple per output tensor).</p>

<h4>Raises:</h4>

<ul>
<li><b><code>AttributeError</code></b>: if the layer has no defined output shape.</li>
<li><b><code>RuntimeError</code></b>: if called in Eager mode.</li>
</ul>


<h3 id="trainable"><code>trainable</code></h3>




<h3 id="trainable_variables"><code>trainable_variables</code></h3>


<p>Sequence of variables owned by this module and it&rsquo;s submodules.</p>

<p>Note: this method uses reflection to find variables on the current instance
and submodules. For performance reasons you may wish to cache the result
of calling this method if you don&rsquo;t expect the return value to change.</p>

<h4>Returns:</h4>

<p>A sequence of variables for the current module (sorted by attribute
name) followed by variables from all submodules recursively (breadth
first).</p>

<h3 id="trainable_weights"><code>trainable_weights</code></h3>




<h3 id="updates"><code>updates</code></h3>




<h3 id="variables"><code>variables</code></h3>


<p>Returns the list of all layer variables/weights.</p>

<p>Alias of <code>self.weights</code>.</p>

<h4>Returns:</h4>

<p>A list of variables.</p>

<h3 id="weights"><code>weights</code></h3>


<p>Returns the list of all layer variables/weights.</p>

<h4>Returns:</h4>

<p>A list of variables.</p>

<h2>Methods</h2>

<h3 id="__call__"><code>__call__</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
__call__(
    inputs,
    *args,
    **kwargs
)
</code></p>

<p>Wraps <code>call</code>, applying pre- and post-processing steps.</p>

<h4>Arguments:</h4>

<ul>
<li><b><code>inputs</code></b>: input tensor(s).</li>
<li><b><code>*args</code></b>: additional positional arguments to be passed to <code>self.call</code>.</li>
<li><b><code>**kwargs</code></b>: additional keyword arguments to be passed to <code>self.call</code>.</li>
</ul>


<h4>Returns:</h4>

<p>Output tensor(s).</p>

<h4>Note:</h4>

<ul>
<li>The following optional keyword arguments are reserved for specific uses:

<ul>
<li><code>training</code>: Boolean scalar tensor of Python boolean indicating
whether the <code>call</code> is meant for training or inference.</li>
<li><code>mask</code>: Boolean input mask.</li>
</ul>
</li>
<li>If the layer&rsquo;s <code>call</code> method takes a <code>mask</code> argument (as some Keras
layers do), its default value will be set to the mask generated
for <code>inputs</code> by the previous layer (if <code>input</code> did come from
a layer that generated a corresponding mask, i.e. if it came from
a Keras layer with masking support.</li>
</ul>


<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: if the layer&rsquo;s <code>call</code> method returns None (an invalid value).</li>
</ul>


<h3 id="add_loss"><code>add_loss</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
add_loss(
    losses,
    inputs=None
)
</code></p>

<p>Add loss tensor(s), potentially dependent on layer inputs.</p>

<p>Some losses (for instance, activity regularization losses) may be dependent
on the inputs passed when calling a layer. Hence, when reusing the same
layer on different inputs <code>a</code> and <code>b</code>, some entries in <code>layer.losses</code> may
be dependent on <code>a</code> and some on <code>b</code>. This method automatically keeps track
of dependencies.</p>

<p>This method can be used inside a subclassed layer or model&rsquo;s <code>call</code>
function, in which case <code>losses</code> should be a Tensor or list of Tensors.</p>

<h4>Example:</h4>

<p><code>python
class MyLayer(tf.keras.layers.Layer):
  def call(inputs, self):
    self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)
    return inputs
</code></p>

<p>This method can also be called directly on a Functional Model during
construction. In this case, any loss Tensors passed to this Model must
be symbolic and be able to be traced back to the model&rsquo;s <code>Input</code>s. These
losses become part of the model&rsquo;s topology and are tracked in <code>get_config</code>.</p>

<h4>Example:</h4>

<p>```python
inputs = tf.keras.Input(shape=(10,))
x = tf.keras.layers.Dense(10)(inputs)
outputs = tf.keras.layers.Dense(1)(x)
model = tf.keras.Model(inputs, outputs)</p>

<h1>Actvity regularization.</h1>

<p>model.add_loss(tf.abs(tf.reduce_mean(x)))
```</p>

<p>If this is not the case for your loss (if, for example, your loss references
a <code>Variable</code> of one of the model&rsquo;s layers), you can wrap your loss in a
zero-argument lambda. These losses are not tracked as part of the model&rsquo;s
topology since they can&rsquo;t be serialized.</p>

<h4>Example:</h4>

<p>```python
inputs = tf.keras.Input(shape=(10,))
x = tf.keras.layers.Dense(10)(inputs)
outputs = tf.keras.layers.Dense(1)(x)
model = tf.keras.Model(inputs, outputs)</p>

<h1>Weight regularization.</h1>

<p>model.add_loss(lambda: tf.reduce_mean(x.kernel))
```</p>

<p>The <code>get_losses_for</code> method allows to retrieve the losses relevant to a
specific set of inputs.</p>

<h4>Arguments:</h4>

<ul>
<li><b><code>losses</code></b>: Loss tensor, or list/tuple of tensors. Rather than tensors, losses
may also be zero-argument callables which create a loss tensor.</li>
<li><b><code>inputs</code></b>: Ignored when executing eagerly. If anything other than None is
passed, it signals the losses are conditional on some of the layer&rsquo;s
inputs, and thus they should only be run where these inputs are
available. This is the case for activity regularization losses, for
instance. If <code>None</code> is passed, the losses are assumed
to be unconditional, and will apply across all dataflows of the layer
(e.g. weight regularization losses).</li>
</ul>


<h3 id="add_metric"><code>add_metric</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
add_metric(
    value,
    aggregation=None,
    name=None
)
</code></p>

<p>Adds metric tensor to the layer.</p>

<h4>Args:</h4>

<ul>
<li><b><code>value</code></b>: Metric tensor.</li>
<li><b><code>aggregation</code></b>: Sample-wise metric reduction function. If <code>aggregation=None</code>,
it indicates that the metric tensor provided has been aggregated
already. eg, <code>bin_acc = BinaryAccuracy(name='acc')</code> followed by
<code>model.add_metric(bin_acc(y_true, y_pred))</code>. If aggregation=&lsquo;mean&rsquo;, the
given metric tensor will be sample-wise reduced using <code>mean</code> function.
eg, <code>model.add_metric(tf.reduce_sum(outputs), name='output_mean',
aggregation='mean')</code>.</li>
<li><b><code>name</code></b>: String metric name.</li>
</ul>


<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: If <code>aggregation</code> is anything other than None or <code>mean</code>.</li>
</ul>


<h3 id="add_update"><code>add_update</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
add_update(
    updates,
    inputs=None
)
</code></p>

<p>Add update op(s), potentially dependent on layer inputs. (deprecated arguments)</p>

<p>Warning: SOME ARGUMENTS ARE DEPRECATED: <code>(inputs)</code>. They will be removed in a future version.
Instructions for updating:
<code>inputs</code> is now automatically inferred</p>

<p>Weight updates (for instance, the updates of the moving mean and variance
in a BatchNormalization layer) may be dependent on the inputs passed
when calling a layer. Hence, when reusing the same layer on
different inputs <code>a</code> and <code>b</code>, some entries in <code>layer.updates</code> may be
dependent on <code>a</code> and some on <code>b</code>. This method automatically keeps track
of dependencies.</p>

<p>The <code>get_updates_for</code> method allows to retrieve the updates relevant to a
specific set of inputs.</p>

<p>This call is ignored when eager execution is enabled (in that case, variable
updates are run on the fly and thus do not need to be tracked for later
execution).</p>

<h4>Arguments:</h4>

<ul>
<li><b><code>updates</code></b>: Update op, or list/tuple of update ops, or zero-arg callable
that returns an update op. A zero-arg callable should be passed in
order to disable running the updates by setting <code>trainable=False</code>
on this Layer, when executing in Eager mode.</li>
<li><b><code>inputs</code></b>: Deprecated, will be automatically inferred.</li>
</ul>


<h3 id="add_weight"><code>add_weight</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
add_weight(
    name=None,
    shape=None,
    dtype=None,
    initializer=None,
    regularizer=None,
    trainable=None,
    constraint=None,
    partitioner=None,
    use_resource=None,
    synchronization=tf.VariableSynchronization.AUTO,
    aggregation=tf.compat.v1.VariableAggregation.NONE,
    **kwargs
)
</code></p>

<p>Adds a new variable to the layer.</p>

<h4>Arguments:</h4>

<ul>
<li><b><code>name</code></b>: Variable name.</li>
<li><b><code>shape</code></b>: Variable shape. Defaults to scalar if unspecified.</li>
<li><b><code>dtype</code></b>: The type of the variable. Defaults to <code>self.dtype</code> or <code>float32</code>.</li>
<li><b><code>initializer</code></b>: Initializer instance (callable).</li>
<li><b><code>regularizer</code></b>: Regularizer instance (callable).</li>
<li><b><code>trainable</code></b>: Boolean, whether the variable should be part of the layer&rsquo;s
&ldquo;trainable_variables&rdquo; (e.g. variables, biases)
or &ldquo;non_trainable_variables&rdquo; (e.g. BatchNorm mean and variance).
Note that <code>trainable</code> cannot be <code>True</code> if <code>synchronization</code>
is set to <code>ON_READ</code>.</li>
<li><b><code>constraint</code></b>: Constraint instance (callable).</li>
<li><b><code>partitioner</code></b>: Partitioner to be passed to the <code>Trackable</code> API.</li>
<li><b><code>use_resource</code></b>: Whether to use <code>ResourceVariable</code>.</li>
<li><b><code>synchronization</code></b>: Indicates when a distributed a variable will be
aggregated. Accepted values are constants defined in the class
<a href="../../../tf/VariableSynchronization.html"><code>tf.VariableSynchronization</code></a>. By default the synchronization is set to
<code>AUTO</code> and the current <code>DistributionStrategy</code> chooses
when to synchronize. If <code>synchronization</code> is set to <code>ON_READ</code>,
<code>trainable</code> must not be set to <code>True</code>.</li>
<li><b><code>aggregation</code></b>: Indicates how a distributed variable will be aggregated.
Accepted values are constants defined in the class
<a href="../../../tf/VariableAggregation.html"><code>tf.VariableAggregation</code></a>.</li>
<li><b><code>**kwargs</code></b>: Additional keyword arguments. Accepted values are <code>getter</code> and
<code>collections</code>.</li>
</ul>


<h4>Returns:</h4>

<p>The created variable. Usually either a <code>Variable</code> or <code>ResourceVariable</code>
instance. If <code>partitioner</code> is not <code>None</code>, a <code>PartitionedVariable</code>
instance is returned.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>RuntimeError</code></b>: If called with partitioned variable regularization and
eager execution is enabled.</li>
<li><b><code>ValueError</code></b>: When giving unsupported dtype and no initializer or when
trainable has been set to True with synchronization set as <code>ON_READ</code>.</li>
</ul>


<h3 id="build"><code>build</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
build(input_shape)
</code></p>

<p>Creates the variables of the layer (optional, for subclass implementers).</p>

<p>This is a method that implementers of subclasses of <code>Layer</code> or <code>Model</code>
can override if they need a state-creation step in-between
layer instantiation and layer call.</p>

<p>This is typically used to create the weights of <code>Layer</code> subclasses.</p>

<h4>Arguments:</h4>

<ul>
<li><b><code>input_shape</code></b>: Instance of <code>TensorShape</code>, or list of instances of
<code>TensorShape</code> if the layer expects a list of inputs
(one instance per input).</li>
</ul>


<h3 id="call"><code>call</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
call(
    inputs,
    **kwargs
)
</code></p>

<p>This is where the layer&rsquo;s logic lives.</p>

<h4>Arguments:</h4>

<ul>
<li><b><code>inputs</code></b>: Input tensor, or list/tuple of input tensors.</li>
<li><b><code>**kwargs</code></b>: Additional keyword arguments.</li>
</ul>


<h4>Returns:</h4>

<p>A tensor or list/tuple of tensors.</p>

<h3 id="compute_mask"><code>compute_mask</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
compute_mask(
    inputs,
    mask=None
)
</code></p>

<p>Computes an output mask tensor.</p>

<h4>Arguments:</h4>

<ul>
<li><b><code>inputs</code></b>: Tensor or list of tensors.</li>
<li><b><code>mask</code></b>: Tensor or list of tensors.</li>
</ul>


<h4>Returns:</h4>

<p>None or a tensor (or list of tensors,
    one per output tensor of the layer).</p>

<h3 id="compute_output_shape"><code>compute_output_shape</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
compute_output_shape(input_shape)
</code></p>

<p>Computes the output shape of the layer.</p>

<p>If the layer has not been built, this method will call <code>build</code> on the
layer. This assumes that the layer will later be used with inputs that
match the input shape provided here.</p>

<h4>Arguments:</h4>

<ul>
<li><b><code>input_shape</code></b>: Shape tuple (tuple of integers)
  or list of shape tuples (one per output tensor of the layer).
  Shape tuples can include None for free dimensions,
  instead of an integer.</li>
</ul>


<h4>Returns:</h4>

<p>An input shape tuple.</p>

<h3 id="compute_output_signature"><code>compute_output_signature</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
compute_output_signature(input_signature)
</code></p>

<p>Compute the output tensor signature of the layer based on the inputs.</p>

<p>Unlike a TensorShape object, a TensorSpec object contains both shape
and dtype information for a tensor. This method allows layers to provide
output dtype information if it is different from the input dtype.
For any layer that doesn&rsquo;t implement this function,
the framework will fall back to use <code>compute_output_shape</code>, and will
assume that the output dtype matches the input dtype.</p>

<h4>Args:</h4>

<ul>
<li><b><code>input_signature</code></b>: Single TensorSpec or nested structure of TensorSpec
objects, describing a candidate input for the layer.</li>
</ul>


<h4>Returns:</h4>

<p>Single TensorSpec or nested structure of TensorSpec objects, describing
  how the layer would transform the provided input.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>TypeError</code></b>: If input_signature contains a non-TensorSpec object.</li>
</ul>


<h3 id="count_params"><code>count_params</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
count_params()
</code></p>

<p>Count the total number of scalars composing the weights.</p>

<h4>Returns:</h4>

<p>An integer count.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: if the layer isn&rsquo;t yet built
(in which case its weights aren&rsquo;t yet defined).</li>
</ul>


<h3 id="from_config"><code>from_config</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
@classmethod
from_config(
    cls,
    config
)
</code></p>

<p>Creates a layer from its config.</p>

<p>This method is the reverse of <code>get_config</code>,
capable of instantiating the same layer from the config
dictionary. It does not handle layer connectivity
(handled by Network), nor weights (handled by <code>set_weights</code>).</p>

<h4>Arguments:</h4>

<ul>
<li><b><code>config</code></b>: A Python dictionary, typically the
  output of get_config.</li>
</ul>


<h4>Returns:</h4>

<p>A layer instance.</p>

<h3 id="get_config"><code>get_config</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
get_config()
</code></p>

<p>Returns the config of the layer.</p>

<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>

<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <code>Network</code> (one layer of abstraction above).</p>

<h4>Returns:</h4>

<p>Python dictionary.</p>

<h3 id="get_input_at"><code>get_input_at</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
get_input_at(node_index)
</code></p>

<p>Retrieves the input tensor(s) of a layer at a given node.</p>

<h4>Arguments:</h4>

<ul>
<li><b><code>node_index</code></b>: Integer, index of the node
  from which to retrieve the attribute.
  E.g. <code>node_index=0</code> will correspond to the
  first time the layer was called.</li>
</ul>


<h4>Returns:</h4>

<p>A tensor (or list of tensors if the layer has multiple inputs).</p>

<h4>Raises:</h4>

<ul>
<li><b><code>RuntimeError</code></b>: If called in Eager mode.</li>
</ul>


<h3 id="get_input_mask_at"><code>get_input_mask_at</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
get_input_mask_at(node_index)
</code></p>

<p>Retrieves the input mask tensor(s) of a layer at a given node.</p>

<h4>Arguments:</h4>

<ul>
<li><b><code>node_index</code></b>: Integer, index of the node
  from which to retrieve the attribute.
  E.g. <code>node_index=0</code> will correspond to the
  first time the layer was called.</li>
</ul>


<h4>Returns:</h4>

<p>A mask tensor
(or list of tensors if the layer has multiple inputs).</p>

<h3 id="get_input_shape_at"><code>get_input_shape_at</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
get_input_shape_at(node_index)
</code></p>

<p>Retrieves the input shape(s) of a layer at a given node.</p>

<h4>Arguments:</h4>

<ul>
<li><b><code>node_index</code></b>: Integer, index of the node
  from which to retrieve the attribute.
  E.g. <code>node_index=0</code> will correspond to the
  first time the layer was called.</li>
</ul>


<h4>Returns:</h4>

<p>A shape tuple
(or list of shape tuples if the layer has multiple inputs).</p>

<h4>Raises:</h4>

<ul>
<li><b><code>RuntimeError</code></b>: If called in Eager mode.</li>
</ul>


<h3 id="get_losses_for"><code>get_losses_for</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
get_losses_for(inputs)
</code></p>

<p>Retrieves losses relevant to a specific set of inputs.</p>

<h4>Arguments:</h4>

<ul>
<li><b><code>inputs</code></b>: Input tensor or list/tuple of input tensors.</li>
</ul>


<h4>Returns:</h4>

<p>List of loss tensors of the layer that depend on <code>inputs</code>.</p>

<h3 id="get_output_at"><code>get_output_at</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
get_output_at(node_index)
</code></p>

<p>Retrieves the output tensor(s) of a layer at a given node.</p>

<h4>Arguments:</h4>

<ul>
<li><b><code>node_index</code></b>: Integer, index of the node
  from which to retrieve the attribute.
  E.g. <code>node_index=0</code> will correspond to the
  first time the layer was called.</li>
</ul>


<h4>Returns:</h4>

<p>A tensor (or list of tensors if the layer has multiple outputs).</p>

<h4>Raises:</h4>

<ul>
<li><b><code>RuntimeError</code></b>: If called in Eager mode.</li>
</ul>


<h3 id="get_output_mask_at"><code>get_output_mask_at</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
get_output_mask_at(node_index)
</code></p>

<p>Retrieves the output mask tensor(s) of a layer at a given node.</p>

<h4>Arguments:</h4>

<ul>
<li><b><code>node_index</code></b>: Integer, index of the node
  from which to retrieve the attribute.
  E.g. <code>node_index=0</code> will correspond to the
  first time the layer was called.</li>
</ul>


<h4>Returns:</h4>

<p>A mask tensor
(or list of tensors if the layer has multiple outputs).</p>

<h3 id="get_output_shape_at"><code>get_output_shape_at</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
get_output_shape_at(node_index)
</code></p>

<p>Retrieves the output shape(s) of a layer at a given node.</p>

<h4>Arguments:</h4>

<ul>
<li><b><code>node_index</code></b>: Integer, index of the node
  from which to retrieve the attribute.
  E.g. <code>node_index=0</code> will correspond to the
  first time the layer was called.</li>
</ul>


<h4>Returns:</h4>

<p>A shape tuple
(or list of shape tuples if the layer has multiple outputs).</p>

<h4>Raises:</h4>

<ul>
<li><b><code>RuntimeError</code></b>: If called in Eager mode.</li>
</ul>


<h3 id="get_updates_for"><code>get_updates_for</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
get_updates_for(inputs)
</code></p>

<p>Retrieves updates relevant to a specific set of inputs.</p>

<h4>Arguments:</h4>

<ul>
<li><b><code>inputs</code></b>: Input tensor or list/tuple of input tensors.</li>
</ul>


<h4>Returns:</h4>

<p>List of update ops of the layer that depend on <code>inputs</code>.</p>

<h3 id="get_weights"><code>get_weights</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
get_weights()
</code></p>

<p>Returns the current weights of the layer.</p>

<h4>Returns:</h4>

<p>Weights values as a list of numpy arrays.</p>

<h3 id="set_weights"><code>set_weights</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/engine/base_layer.py">View source</a></p>

<p><code>python
set_weights(weights)
</code></p>

<p>Sets the weights of the layer, from Numpy arrays.</p>

<h4>Arguments:</h4>

<ul>
<li><b><code>weights</code></b>: a list of Numpy arrays. The number
  of arrays and their shape must match
  number of the dimensions of the weights
  of the layer (i.e. it should match the
  output of <code>get_weights</code>).</li>
</ul>


<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: If the provided weights list does not match the
  layer&rsquo;s specifications.</li>
</ul>

