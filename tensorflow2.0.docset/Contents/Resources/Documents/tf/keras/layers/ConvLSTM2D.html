<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.keras.layers.ConvLSTM2D" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="activation"/>
<meta itemprop="property" content="bias_constraint"/>
<meta itemprop="property" content="bias_initializer"/>
<meta itemprop="property" content="bias_regularizer"/>
<meta itemprop="property" content="data_format"/>
<meta itemprop="property" content="dilation_rate"/>
<meta itemprop="property" content="dropout"/>
<meta itemprop="property" content="filters"/>
<meta itemprop="property" content="kernel_constraint"/>
<meta itemprop="property" content="kernel_initializer"/>
<meta itemprop="property" content="kernel_regularizer"/>
<meta itemprop="property" content="kernel_size"/>
<meta itemprop="property" content="padding"/>
<meta itemprop="property" content="recurrent_activation"/>
<meta itemprop="property" content="recurrent_constraint"/>
<meta itemprop="property" content="recurrent_dropout"/>
<meta itemprop="property" content="recurrent_initializer"/>
<meta itemprop="property" content="recurrent_regularizer"/>
<meta itemprop="property" content="states"/>
<meta itemprop="property" content="strides"/>
<meta itemprop="property" content="unit_forget_bias"/>
<meta itemprop="property" content="use_bias"/>
<meta itemprop="property" content="__init__"/>
<meta itemprop="property" content="get_initial_state"/>
<meta itemprop="property" content="reset_states"/>
</div>


<h1>tf.keras.layers.ConvLSTM2D</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/layers/convolutional_recurrent.py">View source</a></p>

<h2>Class <code>ConvLSTM2D</code></h2>

<!-- Start diff -->


<p>Convolutional LSTM.</p>

<h3>Aliases:</h3>

<ul>
<li>Class <code>tf.compat.v1.keras.layers.ConvLSTM2D</code></li>
<li>Class <code>tf.compat.v2.keras.layers.ConvLSTM2D</code></li>
</ul>


<!-- Placeholder for "Used in" -->


<p>It is similar to an LSTM layer, but the input transformations
and recurrent transformations are both convolutional.</p>

<h4>Arguments:</h4>

<ul>
<li><b><code>filters</code></b>: Integer, the dimensionality of the output space
(i.e. the number of output filters in the convolution).</li>
<li><b><code>kernel_size</code></b>: An integer or tuple/list of n integers, specifying the
dimensions of the convolution window.</li>
<li><b><code>strides</code></b>: An integer or tuple/list of n integers,
specifying the strides of the convolution.
Specifying any stride value != 1 is incompatible with specifying
any <code>dilation_rate</code> value != 1.</li>
<li><b><code>padding</code></b>: One of <code>"valid"</code> or <code>"same"</code> (case-insensitive).</li>
<li><b><code>data_format</code></b>: A string,
one of <code>channels_last</code> (default) or <code>channels_first</code>.
The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape
<code>(batch, time, ..., channels)</code>
while <code>channels_first</code> corresponds to
inputs with shape <code>(batch, time, channels, ...)</code>.
It defaults to the <code>image_data_format</code> value found in your
Keras config file at <code>~/.keras/keras.json</code>.
If you never set it, then it will be &ldquo;channels_last&rdquo;.</li>
<li><b><code>dilation_rate</code></b>: An integer or tuple/list of n integers, specifying
the dilation rate to use for dilated convolution.
Currently, specifying any <code>dilation_rate</code> value != 1 is
incompatible with specifying any <code>strides</code> value != 1.</li>
<li><b><code>activation</code></b>: Activation function to use.
By default hyperbolic tangent activation function is applied
(<code>tanh(x)</code>).</li>
<li><b><code>recurrent_activation</code></b>: Activation function to use
for the recurrent step.</li>
<li><b><code>use_bias</code></b>: Boolean, whether the layer uses a bias vector.</li>
<li><b><code>kernel_initializer</code></b>: Initializer for the <code>kernel</code> weights matrix,
used for the linear transformation of the inputs.</li>
<li><b><code>recurrent_initializer</code></b>: Initializer for the <code>recurrent_kernel</code>
weights matrix,
used for the linear transformation of the recurrent state.</li>
<li><b><code>bias_initializer</code></b>: Initializer for the bias vector.</li>
<li><b><code>unit_forget_bias</code></b>: Boolean.
If True, add 1 to the bias of the forget gate at initialization.
Use in combination with <code>bias_initializer="zeros"</code>.
This is recommended in [Jozefowicz et al.]
(http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)</li>
<li><b><code>kernel_regularizer</code></b>: Regularizer function applied to
the <code>kernel</code> weights matrix.</li>
<li><b><code>recurrent_regularizer</code></b>: Regularizer function applied to
the <code>recurrent_kernel</code> weights matrix.</li>
<li><b><code>bias_regularizer</code></b>: Regularizer function applied to the bias vector.</li>
<li><b><code>activity_regularizer</code></b>: Regularizer function applied to.</li>
<li><b><code>kernel_constraint</code></b>: Constraint function applied to
the <code>kernel</code> weights matrix.</li>
<li><b><code>recurrent_constraint</code></b>: Constraint function applied to
the <code>recurrent_kernel</code> weights matrix.</li>
<li><b><code>bias_constraint</code></b>: Constraint function applied to the bias vector.</li>
<li><b><code>return_sequences</code></b>: Boolean. Whether to return the last output
in the output sequence, or the full sequence.</li>
<li><b><code>go_backwards</code></b>: Boolean (default False).
If True, process the input sequence backwards.</li>
<li><b><code>stateful</code></b>: Boolean (default False). If True, the last state
for each sample at index i in a batch will be used as initial
state for the sample of index i in the following batch.</li>
<li><b><code>dropout</code></b>: Float between 0 and 1.
Fraction of the units to drop for
the linear transformation of the inputs.</li>
<li><b><code>recurrent_dropout</code></b>: Float between 0 and 1.
Fraction of the units to drop for
the linear transformation of the recurrent state.</li>
</ul>


<h4>Call arguments:</h4>

<ul>
<li><b><code>inputs</code></b>: A 5D tensor.</li>
<li><b><code>mask</code></b>: Binary tensor of shape <code>(samples, timesteps)</code> indicating whether
a given timestep should be masked.</li>
<li><b><code>training</code></b>: Python boolean indicating whether the layer should behave in
training mode or in inference mode. This argument is passed to the cell
when calling it. This is only relevant if <code>dropout</code> or <code>recurrent_dropout</code>
are set.</li>
<li><b><code>initial_state</code></b>: List of initial state tensors to be passed to the first
call of the cell.</li>
</ul>


<h4>Input shape:</h4>

<ul>
<li>If data_format=&lsquo;channels_first&rsquo;
  5D tensor with shape:
  <code>(samples, time, channels, rows, cols)</code></li>
<li>If data_format=&lsquo;channels_last&rsquo;
  5D tensor with shape:
  <code>(samples, time, rows, cols, channels)</code></li>
</ul>


<h4>Output shape:</h4>

<ul>
<li>If <code>return_sequences</code>

<ul>
<li>If data_format=&lsquo;channels_first&rsquo;
 5D tensor with shape:
 <code>(samples, time, filters, output_row, output_col)</code></li>
<li>If data_format=&lsquo;channels_last&rsquo;
 5D tensor with shape:
 <code>(samples, time, output_row, output_col, filters)</code></li>
</ul>
</li>
<li>Else

<ul>
<li>If data_format =&lsquo;channels_first&rsquo;
  4D tensor with shape:
  <code>(samples, filters, output_row, output_col)</code></li>
<li>If data_format=&lsquo;channels_last&rsquo;
  4D tensor with shape:
  <code>(samples, output_row, output_col, filters)</code>
where <code>o_row</code> and <code>o_col</code> depend on the shape of the filter and
the padding</li>
</ul>
</li>
</ul>


<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: in case of invalid constructor arguments.</li>
</ul>


<h4>References:</h4>

<ul>
<li><a href="http://arxiv.org/abs/1506.04214v1">Convolutional LSTM Network: A Machine Learning Approach for
Precipitation Nowcasting</a>
The current implementation does not include the feedback loop on the
cells output.</li>
</ul>


<h2 id="__init__"><code>__init__</code></h2>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/layers/convolutional_recurrent.py">View source</a></p>

<p><code>python
__init__(
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    data_format=None,
    dilation_rate=(1, 1),
    activation='tanh',
    recurrent_activation='hard_sigmoid',
    use_bias=True,
    kernel_initializer='glorot_uniform',
    recurrent_initializer='orthogonal',
    bias_initializer='zeros',
    unit_forget_bias=True,
    kernel_regularizer=None,
    recurrent_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    recurrent_constraint=None,
    bias_constraint=None,
    return_sequences=False,
    go_backwards=False,
    stateful=False,
    dropout=0.0,
    recurrent_dropout=0.0,
    **kwargs
)
</code></p>

<h2>Properties</h2>

<h3 id="activation"><code>activation</code></h3>




<h3 id="bias_constraint"><code>bias_constraint</code></h3>




<h3 id="bias_initializer"><code>bias_initializer</code></h3>




<h3 id="bias_regularizer"><code>bias_regularizer</code></h3>




<h3 id="data_format"><code>data_format</code></h3>




<h3 id="dilation_rate"><code>dilation_rate</code></h3>




<h3 id="dropout"><code>dropout</code></h3>




<h3 id="filters"><code>filters</code></h3>




<h3 id="kernel_constraint"><code>kernel_constraint</code></h3>




<h3 id="kernel_initializer"><code>kernel_initializer</code></h3>




<h3 id="kernel_regularizer"><code>kernel_regularizer</code></h3>




<h3 id="kernel_size"><code>kernel_size</code></h3>




<h3 id="padding"><code>padding</code></h3>




<h3 id="recurrent_activation"><code>recurrent_activation</code></h3>




<h3 id="recurrent_constraint"><code>recurrent_constraint</code></h3>




<h3 id="recurrent_dropout"><code>recurrent_dropout</code></h3>




<h3 id="recurrent_initializer"><code>recurrent_initializer</code></h3>




<h3 id="recurrent_regularizer"><code>recurrent_regularizer</code></h3>




<h3 id="states"><code>states</code></h3>




<h3 id="strides"><code>strides</code></h3>




<h3 id="unit_forget_bias"><code>unit_forget_bias</code></h3>




<h3 id="use_bias"><code>use_bias</code></h3>


<h2>Methods</h2>

<h3 id="get_initial_state"><code>get_initial_state</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/layers/convolutional_recurrent.py">View source</a></p>

<p><code>python
get_initial_state(inputs)
</code></p>

<h3 id="reset_states"><code>reset_states</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/layers/convolutional_recurrent.py">View source</a></p>

<p><code>python
reset_states(states=None)
</code></p>
