<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.keras.layers.Embedding" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="__init__"/>
</div>


<h1>tf.keras.layers.Embedding</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/layers/embeddings.py">View source</a></p>

<h2>Class <code>Embedding</code></h2>

<!-- Start diff -->


<p>Turns positive integers (indexes) into dense vectors of fixed size.</p>

<p>Inherits From: <a href="../../../tf/keras/layers/Layer.html"><code>Layer</code></a></p>

<h3>Aliases:</h3>

<ul>
<li>Class <code>tf.compat.v1.keras.layers.Embedding</code></li>
<li>Class <code>tf.compat.v2.keras.layers.Embedding</code></li>
</ul>


<!-- Placeholder for "Used in" -->


<p>e.g. <code>[[4], [20]] -&gt; [[0.25, 0.1], [0.6, -0.2]]</code></p>

<p>This layer can only be used as the first layer in a model.</p>

<h4>Example:</h4>

<p>```python
model = Sequential()
model.add(Embedding(1000, 64, input_length=10))</p>

<h1>the model will take as input an integer matrix of size (batch,</h1>

<h1>input_length).</h1>

<h1>the largest integer (i.e. word index) in the input should be no larger</h1>

<h1>than 999 (vocabulary size).</h1>

<h1>now model.output_shape == (None, 10, 64), where None is the batch</h1>

<h1>dimension.</h1>

<p>input_array = np.random.randint(1000, size=(32, 10))</p>

<p>model.compile(&lsquo;rmsprop&rsquo;, &lsquo;mse&rsquo;)
output_array = model.predict(input_array)
assert output_array.shape == (32, 10, 64)
```</p>

<h4>Arguments:</h4>

<ul>
<li><b><code>input_dim</code></b>: int > 0. Size of the vocabulary,
i.e. maximum integer index + 1.</li>
<li><b><code>output_dim</code></b>: int >= 0. Dimension of the dense embedding.</li>
<li><b><code>embeddings_initializer</code></b>: Initializer for the <code>embeddings</code> matrix.</li>
<li><b><code>embeddings_regularizer</code></b>: Regularizer function applied to
the <code>embeddings</code> matrix.</li>
<li><b><code>embeddings_constraint</code></b>: Constraint function applied to
the <code>embeddings</code> matrix.</li>
<li><b><code>mask_zero</code></b>: Whether or not the input value 0 is a special &ldquo;padding&rdquo;
value that should be masked out.
This is useful when using recurrent layers
which may take variable length input.
If this is <code>True</code> then all subsequent layers
in the model need to support masking or an exception will be raised.
If mask_zero is set to True, as a consequence, index 0 cannot be
used in the vocabulary (input_dim should equal size of
vocabulary + 1).</li>
<li><b><code>input_length</code></b>: Length of input sequences, when it is constant.
This argument is required if you are going to connect
<code>Flatten</code> then <code>Dense</code> layers upstream
(without it, the shape of the dense outputs cannot be computed).</li>
</ul>


<h4>Input shape:</h4>

<p>2D tensor with shape: <code>(batch_size, input_length)</code>.</p>

<h4>Output shape:</h4>

<p>3D tensor with shape: <code>(batch_size, input_length, output_dim)</code>.</p>

<h2 id="__init__"><code>__init__</code></h2>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/layers/embeddings.py">View source</a></p>

<p><code>python
__init__(
    input_dim,
    output_dim,
    embeddings_initializer='uniform',
    embeddings_regularizer=None,
    activity_regularizer=None,
    embeddings_constraint=None,
    mask_zero=False,
    input_length=None,
    **kwargs
)
</code></p>
