<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.keras.losses.CosineSimilarity" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="__call__"/>
<meta itemprop="property" content="__init__"/>
<meta itemprop="property" content="from_config"/>
<meta itemprop="property" content="get_config"/>
</div>


<h1>tf.keras.losses.CosineSimilarity</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/losses.py">View source</a></p>

<h2>Class <code>CosineSimilarity</code></h2>

<!-- Start diff -->


<p>Computes the cosine similarity between <code>y_true</code> and <code>y_pred</code>.</p>

<h3>Aliases:</h3>

<ul>
<li>Class <code>tf.compat.v1.keras.losses.CosineSimilarity</code></li>
<li>Class <code>tf.compat.v2.keras.losses.CosineSimilarity</code></li>
<li>Class <code>tf.compat.v2.losses.CosineSimilarity</code></li>
<li>Class <code>tf.losses.CosineSimilarity</code></li>
</ul>


<!-- Placeholder for "Used in" -->


<h4>Usage:</h4>

<p>```python
cosine_loss = tf.keras.losses.CosineSimilarity(axis=1)
loss = cosine_loss([[0., 1.], [1., 1.]], [[1., 0.], [1., 1.]])</p>

<h1>l2_norm(y_true) = [[0., 1.], [1./1.414], 1./1.414]]]</h1>

<h1>l2_norm(y_pred) = [[1., 0.], [1./1.414], 1./1.414]]]</h1>

<h1>l2_norm(y_true) . l2_norm(y_pred) = [[0., 0.], [0.5, 0.5]]</h1>

<h1>loss = mean(sum(l2_norm(y_true) . l2_norm(y_pred), axis=1))</h1>

<pre><code>   = ((0. + 0.) +  (0.5 + 0.5)) / 2
</code></pre>

<p>print(&lsquo;Loss: &rsquo;, loss.numpy())  # Loss: 0.5
```</p>

<p>Usage with the <code>compile</code> API:</p>

<p><code>python
model = tf.keras.Model(inputs, outputs)
model.compile('sgd', loss=tf.keras.losses.CosineSimilarity(axis=1))
</code></p>

<h4>Args:</h4>

<ul>
<li><b><code>axis</code></b>: (Optional) Defaults to -1. The dimension along which the cosine
similarity is computed.</li>
<li><b><code>reduction</code></b>: (Optional) Type of <a href="../../../tf/keras/losses/Reduction.html"><code>tf.keras.losses.Reduction</code></a> to apply to loss.
Default value is <code>AUTO</code>. <code>AUTO</code> indicates that the reduction option will
be determined by the usage context. For almost all cases this defaults to
<code>SUM_OVER_BATCH_SIZE</code>.
When used with <a href="../../../tf/distribute/Strategy.html"><code>tf.distribute.Strategy</code></a>, outside of built-in training
loops such as <a href="../../../tf/keras.html"><code>tf.keras</code></a> <code>compile</code> and <code>fit</code>, using <code>AUTO</code> or
<code>SUM_OVER_BATCH_SIZE</code> will raise an error. Please see
https://www.tensorflow.org/alpha/tutorials/distribute/training_loops
for more details on this.</li>
<li><b><code>name</code></b>: Optional name for the op.</li>
</ul>


<h2 id="__init__"><code>__init__</code></h2>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/losses.py">View source</a></p>

<p><code>python
__init__(
    axis=-1,
    reduction=losses_utils.ReductionV2.AUTO,
    name='cosine_similarity'
)
</code></p>

<p>Initialize self.  See help(type(self)) for accurate signature.</p>

<h2>Methods</h2>

<h3 id="__call__"><code>__call__</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/losses.py">View source</a></p>

<p><code>python
__call__(
    y_true,
    y_pred,
    sample_weight=None
)
</code></p>

<p>Invokes the <code>Loss</code> instance.</p>

<h4>Args:</h4>

<ul>
<li><b><code>y_true</code></b>: Ground truth values. shape = <code>[batch_size, d0, .. dN]</code></li>
<li><b><code>y_pred</code></b>: The predicted values. shape = <code>[batch_size, d0, .. dN]</code></li>
<li><b><code>sample_weight</code></b>: Optional <code>sample_weight</code> acts as a
coefficient for the loss. If a scalar is provided, then the loss is
simply scaled by the given value. If <code>sample_weight</code> is a tensor of size
<code>[batch_size]</code>, then the total loss for each sample of the batch is
rescaled by the corresponding element in the <code>sample_weight</code> vector. If
the shape of <code>sample_weight</code> is <code>[batch_size, d0, .. dN-1]</code> (or can be
broadcasted to this shape), then each loss element of <code>y_pred</code> is scaled
by the corresponding value of <code>sample_weight</code>. (Note on<code>dN-1</code>: all loss
functions reduce by 1 dimension, usually axis=-1.)</li>
</ul>


<h4>Returns:</h4>

<p>Weighted loss float <code>Tensor</code>. If <code>reduction</code> is <code>NONE</code>, this has
  shape <code>[batch_size, d0, .. dN-1]</code>; otherwise, it is scalar. (Note <code>dN-1</code>
  because all loss functions reduce by 1 dimension, usually axis=-1.)</p>

<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: If the shape of <code>sample_weight</code> is invalid.</li>
</ul>


<h3 id="from_config"><code>from_config</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/losses.py">View source</a></p>

<p><code>python
from_config(
    cls,
    config
)
</code></p>

<p>Instantiates a <code>Loss</code> from its config (output of <code>get_config()</code>).</p>

<h4>Args:</h4>

<ul>
<li><b><code>config</code></b>: Output of <code>get_config()</code>.</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Loss</code> instance.</p>

<h3 id="get_config"><code>get_config</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/losses.py">View source</a></p>

<p><code>python
get_config()
</code></p>
