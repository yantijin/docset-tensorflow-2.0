<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.keras.metrics.SensitivityAtSpecificity" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="__init__"/>
<meta itemprop="property" content="__new__"/>
<meta itemprop="property" content="reset_states"/>
<meta itemprop="property" content="result"/>
<meta itemprop="property" content="update_state"/>
</div>


<h1>tf.keras.metrics.SensitivityAtSpecificity</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/metrics.py">View source</a></p>

<h2>Class <code>SensitivityAtSpecificity</code></h2>

<!-- Start diff -->


<p>Computes the sensitivity at a given specificity.</p>

<h3>Aliases:</h3>

<ul>
<li>Class <code>tf.compat.v1.keras.metrics.SensitivityAtSpecificity</code></li>
<li>Class <code>tf.compat.v2.keras.metrics.SensitivityAtSpecificity</code></li>
<li>Class <code>tf.compat.v2.metrics.SensitivityAtSpecificity</code></li>
<li>Class <code>tf.metrics.SensitivityAtSpecificity</code></li>
</ul>


<!-- Placeholder for "Used in" -->


<p><code>Sensitivity</code> measures the proportion of actual positives that are correctly
identified as such (tp / (tp + fn)).
<code>Specificity</code> measures the proportion of actual negatives that are correctly
identified as such (tn / (tn + fp)).</p>

<p>This metric creates four local variables, <code>true_positives</code>, <code>true_negatives</code>,
<code>false_positives</code> and <code>false_negatives</code> that are used to compute the
sensitivity at the given specificity. The threshold for the given specificity
value is computed and used to evaluate the corresponding sensitivity.</p>

<p>If <code>sample_weight</code> is <code>None</code>, weights default to 1.
Use <code>sample_weight</code> of 0 to mask values.</p>

<p>For additional information about specificity and sensitivity, see the
following: https://en.wikipedia.org/wiki/Sensitivity_and_specificity</p>

<h4>Usage:</h4>

<p><code>python
m = tf.keras.metrics.SensitivityAtSpecificity(0.4, num_thresholds=1)
m.update_state([0, 0, 1, 1], [0, 0.5, 0.3, 0.9])
print('Final result: ', m.result().numpy())  # Final result: 0.5
</code></p>

<p>Usage with tf.keras API:</p>

<p><code>python
model = tf.keras.Model(inputs, outputs)
model.compile(
    'sgd',
    loss='mse',
    metrics=[tf.keras.metrics.SensitivityAtSpecificity()])
</code></p>

<h2 id="__init__"><code>__init__</code></h2>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/metrics.py">View source</a></p>

<p><code>python
__init__(
    specificity,
    num_thresholds=200,
    name=None,
    dtype=None
)
</code></p>

<p>Creates a <code>SensitivityAtSpecificity</code> instance.</p>

<h4>Args:</h4>

<ul>
<li><b><code>specificity</code></b>: A scalar value in range <code>[0, 1]</code>.</li>
<li><b><code>num_thresholds</code></b>: (Optional) Defaults to 200. The number of thresholds to
use for matching the given specificity.</li>
<li><b><code>name</code></b>: (Optional) string name of the metric instance.</li>
<li><b><code>dtype</code></b>: (Optional) data type of the metric result.</li>
</ul>


<h2 id="__new__"><code>__new__</code></h2>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/metrics.py">View source</a></p>

<p><code>python
__new__(
    cls,
    *args,
    **kwargs
)
</code></p>

<p>Create and return a new object.  See help(type) for accurate signature.</p>

<h2>Methods</h2>

<h3 id="reset_states"><code>reset_states</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/metrics.py">View source</a></p>

<p><code>python
reset_states()
</code></p>

<p>Resets all of the metric state variables.</p>

<p>This function is called between epochs/steps,
when a metric is evaluated during training.</p>

<h3 id="result"><code>result</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/metrics.py">View source</a></p>

<p><code>python
result()
</code></p>

<p>Computes and returns the metric value tensor.</p>

<p>Result computation is an idempotent operation that simply calculates the
metric value using the state variables.</p>

<h3 id="update_state"><code>update_state</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/metrics.py">View source</a></p>

<p><code>python
update_state(
    y_true,
    y_pred,
    sample_weight=None
)
</code></p>

<p>Accumulates confusion matrix statistics.</p>

<h4>Args:</h4>

<ul>
<li><b><code>y_true</code></b>: The ground truth values.</li>
<li><b><code>y_pred</code></b>: The predicted values.</li>
<li><b><code>sample_weight</code></b>: Optional weighting of each example. Defaults to 1. Can be a
<code>Tensor</code> whose rank is either 0, or the same rank as <code>y_true</code>, and must
be broadcastable to <code>y_true</code>.</li>
</ul>


<h4>Returns:</h4>

<p>Update op.</p>
