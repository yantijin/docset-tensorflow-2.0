<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.keras.metrics.AUC" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="__init__"/>
<meta itemprop="property" content="__new__"/>
<meta itemprop="property" content="interpolate_pr_auc"/>
<meta itemprop="property" content="reset_states"/>
<meta itemprop="property" content="result"/>
<meta itemprop="property" content="update_state"/>
</div>


<h1>tf.keras.metrics.AUC</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/metrics.py">View source</a></p>

<h2>Class <code>AUC</code></h2>

<!-- Start diff -->


<p>Computes the approximate AUC (Area under the curve) via a Riemann sum.</p>

<p>Inherits From: <a href="../../../tf/keras/metrics/Metric.html"><code>Metric</code></a></p>

<h3>Aliases:</h3>

<ul>
<li>Class <code>tf.compat.v1.keras.metrics.AUC</code></li>
<li>Class <code>tf.compat.v2.keras.metrics.AUC</code></li>
<li>Class <code>tf.compat.v2.metrics.AUC</code></li>
<li>Class <code>tf.metrics.AUC</code></li>
</ul>


<!-- Placeholder for "Used in" -->


<p>This metric creates four local variables, <code>true_positives</code>, <code>true_negatives</code>,
<code>false_positives</code> and <code>false_negatives</code> that are used to compute the AUC.
To discretize the AUC curve, a linearly spaced set of thresholds is used to
compute pairs of recall and precision values. The area under the ROC-curve is
therefore computed using the height of the recall values by the false positive
rate, while the area under the PR-curve is the computed using the height of
the precision values by the recall.</p>

<p>This value is ultimately returned as <code>auc</code>, an idempotent operation that
computes the area under a discretized curve of precision versus recall values
(computed using the aforementioned variables). The <code>num_thresholds</code> variable
controls the degree of discretization with larger numbers of thresholds more
closely approximating the true AUC. The quality of the approximation may vary
dramatically depending on <code>num_thresholds</code>. The <code>thresholds</code> parameter can be
used to manually specify thresholds which split the predictions more evenly.</p>

<p>For best results, <code>predictions</code> should be distributed approximately uniformly
in the range [0, 1] and not peaked around 0 or 1. The quality of the AUC
approximation may be poor if this is not the case. Setting <code>summation_method</code>
to &lsquo;minoring&rsquo; or &lsquo;majoring&rsquo; can help quantify the error in the approximation
by providing lower or upper bound estimate of the AUC.</p>

<p>If <code>sample_weight</code> is <code>None</code>, weights default to 1.
Use <code>sample_weight</code> of 0 to mask values.</p>

<h4>Usage:</h4>

<p>```python
m = tf.keras.metrics.AUC(num_thresholds=3)
m.update_state([0, 0, 1, 1], [0, 0.5, 0.3, 0.9])</p>

<h1>threshold values are [0 - 1e-7, 0.5, 1 + 1e-7]</h1>

<h1>tp = [2, 1, 0], fp = [2, 0, 0], fn = [0, 1, 2], tn = [0, 2, 2]</h1>

<h1>recall = [1, 0.5, 0], fp_rate = [1, 0, 0]</h1>

<h1>auc = ((((1+0.5)/2)<em>(1-0))+ (((0.5+0)/2)</em>(0-0))) = 0.75</h1>

<p>print(&lsquo;Final result: &rsquo;, m.result().numpy())  # Final result: 0.75
```</p>

<p>Usage with tf.keras API:</p>

<p><code>python
model = tf.keras.Model(inputs, outputs)
model.compile('sgd', loss='mse', metrics=[tf.keras.metrics.AUC()])
</code></p>

<h2 id="__init__"><code>__init__</code></h2>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/metrics.py">View source</a></p>

<p><code>python
__init__(
    num_thresholds=200,
    curve='ROC',
    summation_method='interpolation',
    name=None,
    dtype=None,
    thresholds=None
)
</code></p>

<p>Creates an <code>AUC</code> instance.</p>

<h4>Args:</h4>

<ul>
<li><b><code>num_thresholds</code></b>: (Optional) Defaults to 200. The number of thresholds to
use when discretizing the roc curve. Values must be > 1.</li>
<li><b><code>curve</code></b>: (Optional) Specifies the name of the curve to be computed, &lsquo;ROC&rsquo;
[default] or &lsquo;PR&rsquo; for the Precision-Recall-curve.</li>
<li><b><code>summation_method</code></b>: (Optional) Specifies the Riemann summation method used
(https://en.wikipedia.org/wiki/Riemann_sum): &lsquo;interpolation&rsquo; [default],
  applies mid-point summation scheme for <code>ROC</code>. For PR-AUC, interpolates
  (true/false) positives but not the ratio that is precision (see Davis
  &amp; Goadrich 2006 for details); &lsquo;minoring&rsquo; that applies left summation
  for increasing intervals and right summation for decreasing intervals;
  &lsquo;majoring&rsquo; that does the opposite.</li>
<li><b><code>name</code></b>: (Optional) string name of the metric instance.</li>
<li><b><code>dtype</code></b>: (Optional) data type of the metric result.</li>
<li><b><code>thresholds</code></b>: (Optional) A list of floating point values to use as the
thresholds for discretizing the curve. If set, the <code>num_thresholds</code>
parameter is ignored. Values should be in [0, 1]. Endpoint thresholds
equal to {-epsilon, 1+epsilon} for a small positive epsilon value will
be automatically included with these to correctly handle predictions
equal to exactly 0 or 1.</li>
</ul>


<h2 id="__new__"><code>__new__</code></h2>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/metrics.py">View source</a></p>

<p><code>python
__new__(
    cls,
    *args,
    **kwargs
)
</code></p>

<p>Create and return a new object.  See help(type) for accurate signature.</p>

<h2>Methods</h2>

<h3 id="interpolate_pr_auc"><code>interpolate_pr_auc</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/metrics.py">View source</a></p>

<p><code>python
interpolate_pr_auc()
</code></p>

<p>Interpolation formula inspired by section 4 of Davis &amp; Goadrich 2006.</p>

<p>https://www.biostat.wisc.edu/~page/rocpr.pdf</p>

<p>Note here we derive &amp; use a closed formula not present in the paper
as follows:</p>

<p>  Precision = TP / (TP + FP) = TP / P</p>

<p>Modeling all of TP (true positive), FP (false positive) and their sum
P = TP + FP (predicted positive) as varying linearly within each interval
[A, B] between successive thresholds, we get</p>

<p>  Precision slope = dTP / dP
                  = (TP_B - TP_A) / (P_B - P_A)
                  = (TP - TP_A) / (P - P_A)
  Precision = (TP_A + slope * (P - P_A)) / P</p>

<p>The area within the interval is (slope / total_pos_weight) times</p>

<p>  int_A<sup>B</sup>{Precision.dP} = int_A<sup>B</sup>{(TP_A + slope * (P - P_A)) * dP / P}
  int_A<sup>B</sup>{Precision.dP} = int_A<sup>B</sup>{slope * dP + intercept * dP / P}</p>

<p>where intercept = TP_A - slope * P_A = TP_B - slope * P_B, resulting in</p>

<p>  int_A<sup>B</sup>{Precision.dP} = TP_B - TP_A + intercept * log(P_B / P_A)</p>

<p>Bringing back the factor (slope / total_pos_weight) we&rsquo;d put aside, we get</p>

<p>  slope * [dTP + intercept *  log(P_B / P_A)] / total_pos_weight</p>

<p>where dTP == TP_B - TP_A.</p>

<p>Note that when P_A == 0 the above calculation simplifies into</p>

<p>  int_A<sup>B</sup>{Precision.dTP} = int_A<sup>B</sup>{slope * dTP} = slope * (TP_B - TP_A)</p>

<p>which is really equivalent to imputing constant precision throughout the
first bucket having >0 true positives.</p>

<h4>Returns:</h4>

<ul>
<li><b><code>pr_auc</code></b>: an approximation of the area under the P-R curve.</li>
</ul>


<h3 id="reset_states"><code>reset_states</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/metrics.py">View source</a></p>

<p><code>python
reset_states()
</code></p>

<p>Resets all of the metric state variables.</p>

<p>This function is called between epochs/steps,
when a metric is evaluated during training.</p>

<h3 id="result"><code>result</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/metrics.py">View source</a></p>

<p><code>python
result()
</code></p>

<p>Computes and returns the metric value tensor.</p>

<p>Result computation is an idempotent operation that simply calculates the
metric value using the state variables.</p>

<h3 id="update_state"><code>update_state</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/metrics.py">View source</a></p>

<p><code>python
update_state(
    y_true,
    y_pred,
    sample_weight=None
)
</code></p>

<p>Accumulates confusion matrix statistics.</p>

<h4>Args:</h4>

<ul>
<li><b><code>y_true</code></b>: The ground truth values.</li>
<li><b><code>y_pred</code></b>: The predicted values.</li>
<li><b><code>sample_weight</code></b>: Optional weighting of each example. Defaults to 1. Can be a
<code>Tensor</code> whose rank is either 0, or the same rank as <code>y_true</code>, and must
be broadcastable to <code>y_true</code>.</li>
</ul>


<h4>Returns:</h4>

<p>Update op.</p>
