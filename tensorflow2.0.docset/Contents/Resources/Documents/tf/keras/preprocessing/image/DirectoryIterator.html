<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.keras.preprocessing.image.DirectoryIterator" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="filepaths"/>
<meta itemprop="property" content="labels"/>
<meta itemprop="property" content="sample_weight"/>
<meta itemprop="property" content="__getitem__"/>
<meta itemprop="property" content="__init__"/>
<meta itemprop="property" content="__iter__"/>
<meta itemprop="property" content="__len__"/>
<meta itemprop="property" content="next"/>
<meta itemprop="property" content="on_epoch_end"/>
<meta itemprop="property" content="reset"/>
<meta itemprop="property" content="set_processing_attrs"/>
<meta itemprop="property" content="allowed_class_modes"/>
<meta itemprop="property" content="white_list_formats"/>
</div>


<h1>tf.keras.preprocessing.image.DirectoryIterator</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/preprocessing/image.py">View source</a></p>

<h2>Class <code>DirectoryIterator</code></h2>

<!-- Start diff -->


<p>Iterator capable of reading images from a directory on disk.</p>

<p>Inherits From: <a href="../../../../tf/keras/preprocessing/image/Iterator.html"><code>Iterator</code></a></p>

<h3>Aliases:</h3>

<ul>
<li>Class <code>tf.compat.v1.keras.preprocessing.image.DirectoryIterator</code></li>
<li>Class <code>tf.compat.v2.keras.preprocessing.image.DirectoryIterator</code></li>
</ul>


<!-- Placeholder for "Used in" -->


<h4>Arguments:</h4>

<ul>
<li><b><code>directory</code></b>: Path to the directory to read images from.
  Each subdirectory in this directory will be
  considered to contain images from one class,
  or alternatively you could specify class subdirectories
  via the <code>classes</code> argument.</li>
<li><b><code>image_data_generator</code></b>: Instance of <code>ImageDataGenerator</code>
  to use for random transformations and normalization.</li>
<li><b><code>target_size</code></b>: tuple of integers, dimensions to resize input images to.</li>
<li><b><code>color_mode</code></b>: One of <code>"rgb"</code>, <code>"rgba"</code>, <code>"grayscale"</code>.
  Color mode to read images.</li>
<li><b><code>classes</code></b>: Optional list of strings, names of subdirectories
  containing images from each class (e.g. <code>["dogs", "cats"]</code>).
  It will be computed automatically if not set.</li>
<li><b><code>class_mode</code></b>: Mode for yielding the targets:
  <code>"binary"</code>: binary targets (if there are only two classes),
  <code>"categorical"</code>: categorical targets,
  <code>"sparse"</code>: integer targets,
  <code>"input"</code>: targets are images identical to input images (mainly
      used to work with autoencoders),
  <code>None</code>: no targets get yielded (only input images are yielded).</li>
<li><b><code>batch_size</code></b>: Integer, size of a batch.</li>
<li><b><code>shuffle</code></b>: Boolean, whether to shuffle the data between epochs.</li>
<li><b><code>seed</code></b>: Random seed for data shuffling.</li>
<li><b><code>data_format</code></b>: String, one of <code>channels_first</code>, <code>channels_last</code>.</li>
<li><b><code>save_to_dir</code></b>: Optional directory where to save the pictures
  being yielded, in a viewable format. This is useful
  for visualizing the random transformations being
  applied, for debugging purposes.</li>
<li><b><code>save_prefix</code></b>: String prefix to use for saving sample
  images (if <code>save_to_dir</code> is set).</li>
<li><b><code>save_format</code></b>: Format to use for saving sample images
  (if <code>save_to_dir</code> is set).</li>
<li><b><code>subset</code></b>: Subset of data (<code>"training"</code> or <code>"validation"</code>) if
  validation_split is set in ImageDataGenerator.</li>
<li><b><code>interpolation</code></b>: Interpolation method used to resample the image if the
  target size is different from that of the loaded image.
  Supported methods are &ldquo;nearest&rdquo;, &ldquo;bilinear&rdquo;, and &ldquo;bicubic&rdquo;.
  If PIL version 1.1.3 or newer is installed, &ldquo;lanczos&rdquo; is also
  supported. If PIL version 3.4.0 or newer is installed, &ldquo;box&rdquo; and
  &ldquo;hamming&rdquo; are also supported. By default, &ldquo;nearest&rdquo; is used.</li>
<li><b><code>dtype</code></b>: Dtype to use for generated arrays.</li>
</ul>


<h2 id="__init__"><code>__init__</code></h2>


<p><a target="_blank" href="/code/stable/tensorflow/python/keras/preprocessing/image.py">View source</a></p>

<p><code>python
__init__(
    directory,
    image_data_generator,
    target_size=(256, 256),
    color_mode='rgb',
    classes=None,
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=None,
    data_format=None,
    save_to_dir=None,
    save_prefix='',
    save_format='png',
    follow_links=False,
    subset=None,
    interpolation='nearest',
    dtype=None
)
</code></p>

<p>Initialize self.  See help(type(self)) for accurate signature.</p>

<h2>Properties</h2>

<h3 id="filepaths"><code>filepaths</code></h3>


<p>List of absolute paths to image files</p>

<h3 id="labels"><code>labels</code></h3>


<p>Class labels of every observation</p>

<h3 id="sample_weight"><code>sample_weight</code></h3>


<h2>Methods</h2>

<h3 id="__getitem__"><code>__getitem__</code></h3>


<p><code>python
__getitem__(idx)
</code></p>

<p>Gets batch at position <code>index</code>.</p>

<h4>Arguments:</h4>

<ul>
<li><b><code>index</code></b>: position of the batch in the Sequence.</li>
</ul>


<h4>Returns:</h4>

<p>A batch</p>

<h3 id="__iter__"><code>__iter__</code></h3>


<p><code>python
__iter__()
</code></p>

<p>Create a generator that iterate over the Sequence.</p>

<h3 id="__len__"><code>__len__</code></h3>


<p><code>python
__len__()
</code></p>

<p>Number of batch in the Sequence.</p>

<h4>Returns:</h4>

<p>The number of batches in the Sequence.</p>

<h3 id="next"><code>next</code></h3>


<p><code>python
next()
</code></p>

<p>For python 2.x.</p>

<h1>Returns</h1>

<pre><code>The next batch.
</code></pre>

<h3 id="on_epoch_end"><code>on_epoch_end</code></h3>


<p><code>python
on_epoch_end()
</code></p>

<p>Method called at the end of every epoch.</p>

<h3 id="reset"><code>reset</code></h3>


<p><code>python
reset()
</code></p>

<h3 id="set_processing_attrs"><code>set_processing_attrs</code></h3>


<p><code>python
set_processing_attrs(
    image_data_generator,
    target_size,
    color_mode,
    data_format,
    save_to_dir,
    save_prefix,
    save_format,
    subset,
    interpolation
)
</code></p>

<p>Sets attributes to use later for processing files into a batch.</p>

<h1>Arguments</h1>

<pre><code>image_data_generator: Instance of `ImageDataGenerator`
    to use for random transformations and normalization.
target_size: tuple of integers, dimensions to resize input images to.
color_mode: One of `"rgb"`, `"rgba"`, `"grayscale"`.
    Color mode to read images.
data_format: String, one of `channels_first`, `channels_last`.
save_to_dir: Optional directory where to save the pictures
    being yielded, in a viewable format. This is useful
    for visualizing the random transformations being
    applied, for debugging purposes.
save_prefix: String prefix to use for saving sample
    images (if `save_to_dir` is set).
save_format: Format to use for saving sample images
    (if `save_to_dir` is set).
subset: Subset of data (`"training"` or `"validation"`) if
    validation_split is set in ImageDataGenerator.
interpolation: Interpolation method used to resample the image if the
    target size is different from that of the loaded image.
    Supported methods are "nearest", "bilinear", and "bicubic".
    If PIL version 1.1.3 or newer is installed, "lanczos" is also
    supported. If PIL version 3.4.0 or newer is installed, "box" and
    "hamming" are also supported. By default, "nearest" is used.
</code></pre>

<h2>Class Members</h2>

<ul>
<li><code>allowed_class_modes</code> <a id="allowed_class_modes"></a></li>
<li><code>white_list_formats</code> <a id="white_list_formats"></a></li>
</ul>

