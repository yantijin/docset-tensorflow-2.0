<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.keras.preprocessing.sequence.make_sampling_table" />
<meta itemprop="path" content="Stable" />
</div>


<h1>tf.keras.preprocessing.sequence.make_sampling_table</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>




<!-- Start diff -->


<p>Generates a word rank-based probabilistic sampling table.</p>

<h3>Aliases:</h3>

<ul>
<li><code>tf.compat.v1.keras.preprocessing.sequence.make_sampling_table</code></li>
<li><code>tf.compat.v2.keras.preprocessing.sequence.make_sampling_table</code></li>
</ul>


<p><code>python
tf.keras.preprocessing.sequence.make_sampling_table(
    size,
    sampling_factor=1e-05
)
</code></p>

<!-- Placeholder for "Used in" -->


<p>Used for generating the <code>sampling_table</code> argument for <code>skipgrams</code>.
<code>sampling_table[i]</code> is the probability of sampling
the word i-th most common word in a dataset
(more common words should be sampled less frequently, for balance).</p>

<p>The sampling probabilities are generated according
to the sampling distribution used in word2vec:</p>

<p><code>
p(word) = (min(1, sqrt(word_frequency / sampling_factor) /
    (word_frequency / sampling_factor)))
</code></p>

<p>We assume that the word frequencies follow Zipf&rsquo;s law (s=1) to derive
a numerical approximation of frequency(rank):</p>

<p><code>frequency(rank) ~ 1/(rank * (log(rank) + gamma) + 1/2 - 1/(12*rank))</code>
where <code>gamma</code> is the Euler-Mascheroni constant.</p>

<h1>Arguments</h1>

<pre><code>size: Int, number of possible words to sample.
sampling_factor: The sampling factor in the word2vec formula.
</code></pre>

<h1>Returns</h1>

<pre><code>A 1D Numpy array of length `size` where the ith entry
is the probability that a word of rank i should be sampled.
</code></pre>
