
    <html lang="zh-cn">
    <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <link href=../../default.css" rel="stylesheet">
    <link href="
   ../../github.css" rel="stylesheet">
    </head>
    <body>
    <div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.bitcast" />
<meta itemprop="path" content="Stable" />
</div>

<h1 id="tfbitcast">tf.bitcast</h1>
<!-- Insert buttons -->

<table class="tfo-notebook-buttons tfo-api" align="left">
</table>

<p>Defined in generated file: <code>python/ops/gen_array_ops.py</code></p>
<!-- Start diff -->

<p>Bitcasts a tensor from one type to another without copying data.</p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li><code>tf.compat.v1.bitcast</code></li>
<li><code>tf.compat.v2.bitcast</code></li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">bitcast</span><span class="p">(</span>
    <span class="nb">input</span><span class="p">,</span>
    <span class="nb">type</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</pre></div>


<!-- Placeholder for "Used in" -->

<p>Given a tensor <code>input</code>, this operation returns a tensor that has the same buffer
data as <code>input</code> with datatype <code>type</code>.</p>
<p>If the input datatype <code>T</code> is larger than the output datatype <code>type</code> then the
shape changes from [...] to [..., sizeof(<code>T</code>)/sizeof(<code>type</code>)].</p>
<p>If <code>T</code> is smaller than <code>type</code>, the operator requires that the rightmost
dimension be equal to sizeof(<code>type</code>)/sizeof(<code>T</code>). The shape then goes from
[..., sizeof(<code>type</code>)/sizeof(<code>T</code>)] to [...].</p>
<p>tf.bitcast() and tf.cast() work differently when real dtype is casted as a complex dtype
(e.g. tf.complex64 or tf.complex128) as tf.cast() make imaginary part 0 while tf.bitcast()
gives module error.
For example,</p>
<h4 id="example-1">Example 1:</h4>
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">equality_bitcast</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">bitcast</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">tf</span><span class="o">.</span><span class="n">complex128</span><span class="p">)</span>
<span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">errors_impl</span><span class="o">.</span><span class="n">InvalidArgumentError</span><span class="p">:</span> <span class="n">Cannot</span> <span class="n">bitcast</span> <span class="kn">from</span> <span class="nn">float</span> <span class="n">to</span> <span class="n">complex128</span><span class="p">:</span> <span class="n">shape</span> <span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="p">[</span><span class="n">Op</span><span class="p">:</span><span class="n">Bitcast</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">equality_cast</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">tf</span><span class="o">.</span><span class="n">complex128</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">equality_cast</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">1.</span><span class="o">+</span><span class="mf">0.</span><span class="n">j</span> <span class="mf">2.</span><span class="o">+</span><span class="mf">0.</span><span class="n">j</span> <span class="mf">3.</span><span class="o">+</span><span class="mf">0.</span><span class="n">j</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">complex128</span><span class="p">)</span>
</pre></div>


<p>Example 2:</p>
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">bitcast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mh">0xffffffff</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">uint32</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="o">&lt;</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span> <span class="o">...</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">uint8</span><span class="p">,</span> <span class="n">numpy</span><span class="o">=</span><span class="n">array</span><span class="p">([</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">uint8</span><span class="p">)</span><span class="o">&gt;</span>
</pre></div>


<p>Example 3:</p>
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">equality</span><span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">equality_cast</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">equality</span><span class="p">,</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">equality_bitcast</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">bitcast</span><span class="p">(</span><span class="n">equality_cast</span><span class="p">,</span><span class="n">tf</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">equality</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="kc">False</span> <span class="kc">True</span> <span class="kc">True</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">equality_cast</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">0.</span> <span class="mf">1.</span> <span class="mf">1.</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">equality_bitcast</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span>
<span class="p">[[</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
 <span class="p">[</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">128</span> <span class="mi">63</span><span class="p">]</span>
 <span class="p">[</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">128</span> <span class="mi">63</span><span class="p">]],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">uint8</span><span class="p">)</span>
</pre></div>


<p><em>NOTE</em>: Bitcast is implemented as a low-level cast, so machines with different
endian orderings will give different results.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>input</code></b>: A <code>Tensor</code>. Must be one of the following types: <code>bfloat16</code>, <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>uint32</code>, <code>uint64</code>, <code>int8</code>, <code>int16</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint16</code>, <code>quint16</code>, <code>qint32</code>.</li>
<li><b><code>type</code></b>: A <a href="../tf/dtypes/DType.html"><code>tf.DType</code></a> from: <code>tf.bfloat16, tf.half, tf.float32, tf.float64, tf.int64, tf.int32, tf.uint8, tf.uint16, tf.uint32, tf.uint64, tf.int8, tf.int16, tf.complex64, tf.complex128, tf.qint8, tf.quint8, tf.qint16, tf.quint16, tf.qint32</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A <code>Tensor</code> of type <code>type</code>.</p>
    </body>
    </html>
   