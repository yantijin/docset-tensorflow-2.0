<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.data.experimental.bucket_by_sequence_length" />
<meta itemprop="path" content="Stable" />
</div>


<h1>tf.data.experimental.bucket_by_sequence_length</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p><a target="_blank" href="/code/stable/tensorflow/python/data/experimental/ops/grouping.py">View source</a></p>

<!-- Start diff -->


<p>A transformation that buckets elements in a <code>Dataset</code> by length.</p>

<h3>Aliases:</h3>

<ul>
<li><code>tf.compat.v1.data.experimental.bucket_by_sequence_length</code></li>
<li><code>tf.compat.v2.data.experimental.bucket_by_sequence_length</code></li>
</ul>


<p><code>python
tf.data.experimental.bucket_by_sequence_length(
    element_length_func,
    bucket_boundaries,
    bucket_batch_sizes,
    padded_shapes=None,
    padding_values=None,
    pad_to_bucket_boundary=False,
    no_padding=False,
    drop_remainder=False
)
</code></p>

<!-- Placeholder for "Used in" -->


<p>Elements of the <code>Dataset</code> are grouped together by length and then are padded
and batched.</p>

<p>This is useful for sequence tasks in which the elements have variable length.
Grouping together elements that have similar lengths reduces the total
fraction of padding in a batch which increases training step efficiency.</p>

<h4>Args:</h4>

<ul>
<li><b><code>element_length_func</code></b>: function from element in <code>Dataset</code> to <a href="../../../tf.html#int32"><code>tf.int32</code></a>,
determines the length of the element, which will determine the bucket it
goes into.</li>
<li><b><code>bucket_boundaries</code></b>: <code>list&lt;int&gt;</code>, upper length boundaries of the buckets.</li>
<li><b><code>bucket_batch_sizes</code></b>: <code>list&lt;int&gt;</code>, batch size per bucket. Length should be
<code>len(bucket_boundaries) + 1</code>.</li>
<li><b><code>padded_shapes</code></b>: Nested structure of <a href="../../../tf/TensorShape.html"><code>tf.TensorShape</code></a> to pass to
<a href="../../../tf/data/Dataset.html#padded_batch"><code>tf.data.Dataset.padded_batch</code></a>. If not provided, will use
<code>dataset.output_shapes</code>, which will result in variable length dimensions
being padded out to the maximum length in each batch.</li>
<li><b><code>padding_values</code></b>: Values to pad with, passed to
<a href="../../../tf/data/Dataset.html#padded_batch"><code>tf.data.Dataset.padded_batch</code></a>. Defaults to padding with 0.</li>
<li><b><code>pad_to_bucket_boundary</code></b>: bool, if <code>False</code>, will pad dimensions with unknown
size to maximum length in batch. If <code>True</code>, will pad dimensions with
unknown size to bucket boundary minus 1 (i.e., the maximum length in each
bucket), and caller must ensure that the source <code>Dataset</code> does not contain
any elements with length longer than <code>max(bucket_boundaries)</code>.</li>
<li><b><code>no_padding</code></b>: <code>bool</code>, indicates whether to pad the batch features (features
need to be either of type <a href="../../../tf/sparse/SparseTensor.html"><code>tf.SparseTensor</code></a> or of same shape).</li>
<li><b><code>drop_remainder</code></b>: (Optional.) A <a href="../../../tf.html#bool"><code>tf.bool</code></a> scalar <a href="../../../tf/Tensor.html"><code>tf.Tensor</code></a>, representing
whether the last batch should be dropped in the case it has fewer than
<code>batch_size</code> elements; the default behavior is not to drop the smaller
batch.</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Dataset</code> transformation function, which can be passed to
<a href="../../../tf/data/Dataset.html#apply"><code>tf.data.Dataset.apply</code></a>.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: if <code>len(bucket_batch_sizes) != len(bucket_boundaries) + 1</code>.</li>
</ul>

