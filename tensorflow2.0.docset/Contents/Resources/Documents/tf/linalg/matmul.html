<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.linalg.matmul" />
<meta itemprop="path" content="Stable" />
</div>


<h1>tf.linalg.matmul</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/math_ops.py">View source</a></p>

<!-- Start diff -->


<p>Multiplies matrix <code>a</code> by matrix <code>b</code>, producing <code>a</code> * <code>b</code>.</p>

<h3>Aliases:</h3>

<ul>
<li><code>tf.compat.v1.linalg.matmul</code></li>
<li><code>tf.compat.v1.matmul</code></li>
<li><code>tf.compat.v2.linalg.matmul</code></li>
<li><code>tf.compat.v2.matmul</code></li>
<li><code>tf.matmul</code></li>
</ul>


<p><code>python
tf.linalg.matmul(
    a,
    b,
    transpose_a=False,
    transpose_b=False,
    adjoint_a=False,
    adjoint_b=False,
    a_is_sparse=False,
    b_is_sparse=False,
    name=None
)
</code></p>

<!-- Placeholder for "Used in" -->


<p>The inputs must, following any transpositions, be tensors of rank >= 2
where the inner 2 dimensions specify valid matrix multiplication arguments,
and any further outer dimensions match.</p>

<p>Both matrices must be of the same type. The supported types are:
<code>float16</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>complex64</code>, <code>complex128</code>.</p>

<p>Either matrix can be transposed or adjointed (conjugated and transposed) on
the fly by setting one of the corresponding flag to <code>True</code>. These are <code>False</code>
by default.</p>

<p>If one or both of the matrices contain a lot of zeros, a more efficient
multiplication algorithm can be used by setting the corresponding
<code>a_is_sparse</code> or <code>b_is_sparse</code> flag to <code>True</code>. These are <code>False</code> by default.
This optimization is only available for plain matrices (rank-2 tensors) with
datatypes <code>bfloat16</code> or <code>float32</code>.</p>

<h4>For example:</h4>

<p>```python</p>

<h1>2-D tensor <code>a</code></h1>

<h1>[[1, 2, 3],</h1>

<h1>[4, 5, 6]]</h1>

<p>a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])</p>

<h1>2-D tensor <code>b</code></h1>

<h1>[[ 7,  8],</h1>

<h1>[ 9, 10],</h1>

<h1>[11, 12]]</h1>

<p>b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])</p>

<h1><code>a</code> * <code>b</code></h1>

<h1>[[ 58,  64],</h1>

<h1>[139, 154]]</h1>

<p>c = tf.matmul(a, b)</p>

<h1>3-D tensor <code>a</code></h1>

<h1>[[[ 1,  2,  3],</h1>

<h1>[ 4,  5,  6]],</h1>

<h1>[[ 7,  8,  9],</h1>

<h1>[10, 11, 12]]]</h1>

<p>a = tf.constant(np.arange(1, 13, dtype=np.int32),
                shape=[2, 2, 3])</p>

<h1>3-D tensor <code>b</code></h1>

<h1>[[[13, 14],</h1>

<h1>[15, 16],</h1>

<h1>[17, 18]],</h1>

<h1>[[19, 20],</h1>

<h1>[21, 22],</h1>

<h1>[23, 24]]]</h1>

<p>b = tf.constant(np.arange(13, 25, dtype=np.int32),
                shape=[2, 3, 2])</p>

<h1><code>a</code> * <code>b</code></h1>

<h1>[[[ 94, 100],</h1>

<h1>[229, 244]],</h1>

<h1>[[508, 532],</h1>

<h1>[697, 730]]]</h1>

<p>c = tf.matmul(a, b)</p>

<h1>Since python >= 3.5 the @ operator is supported (see PEP 465).</h1>

<h1>In TensorFlow, it simply calls the <code>tf.matmul()</code> function, so the</h1>

<h1>following lines are equivalent:</h1>

<p>d = a @ b @ [[10.], [11.]]
d = tf.matmul(tf.matmul(a, b), [[10.], [11.]])
```</p>

<h4>Args:</h4>

<ul>
<li><b><code>a</code></b>: <code>Tensor</code> of type <code>float16</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>complex64</code>,
<code>complex128</code> and rank > 1.</li>
<li><b><code>b</code></b>: <code>Tensor</code> with same type and rank as <code>a</code>.</li>
<li><b><code>transpose_a</code></b>: If <code>True</code>, <code>a</code> is transposed before multiplication.</li>
<li><b><code>transpose_b</code></b>: If <code>True</code>, <code>b</code> is transposed before multiplication.</li>
<li><b><code>adjoint_a</code></b>: If <code>True</code>, <code>a</code> is conjugated and transposed before
multiplication.</li>
<li><b><code>adjoint_b</code></b>: If <code>True</code>, <code>b</code> is conjugated and transposed before
multiplication.</li>
<li><b><code>a_is_sparse</code></b>: If <code>True</code>, <code>a</code> is treated as a sparse matrix.</li>
<li><b><code>b_is_sparse</code></b>: If <code>True</code>, <code>b</code> is treated as a sparse matrix.</li>
<li><b><code>name</code></b>: Name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code> of the same type as <code>a</code> and <code>b</code> where each inner-most matrix is
the product of the corresponding matrices in <code>a</code> and <code>b</code>, e.g. if all
transpose or adjoint attributes are <code>False</code>:</p>

<p><code>output</code>[&hellip;, i, j] = sum_k (<code>a</code>[&hellip;, i, k] * <code>b</code>[&hellip;, k, j]),
for all indices i, j.</p>

<ul>
<li><b><code>Note</code></b>: This is matrix product, not element-wise product.</li>
</ul>


<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: If transpose_a and adjoint_a, or transpose_b and adjoint_b
are both set to True.</li>
</ul>

