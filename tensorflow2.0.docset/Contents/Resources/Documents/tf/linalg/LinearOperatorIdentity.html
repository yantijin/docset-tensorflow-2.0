<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.linalg.LinearOperatorIdentity" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="H"/>
<meta itemprop="property" content="batch_shape"/>
<meta itemprop="property" content="domain_dimension"/>
<meta itemprop="property" content="dtype"/>
<meta itemprop="property" content="graph_parents"/>
<meta itemprop="property" content="is_non_singular"/>
<meta itemprop="property" content="is_positive_definite"/>
<meta itemprop="property" content="is_self_adjoint"/>
<meta itemprop="property" content="is_square"/>
<meta itemprop="property" content="range_dimension"/>
<meta itemprop="property" content="shape"/>
<meta itemprop="property" content="tensor_rank"/>
<meta itemprop="property" content="__init__"/>
<meta itemprop="property" content="add_to_tensor"/>
<meta itemprop="property" content="adjoint"/>
<meta itemprop="property" content="assert_non_singular"/>
<meta itemprop="property" content="assert_positive_definite"/>
<meta itemprop="property" content="assert_self_adjoint"/>
<meta itemprop="property" content="batch_shape_tensor"/>
<meta itemprop="property" content="cholesky"/>
<meta itemprop="property" content="determinant"/>
<meta itemprop="property" content="diag_part"/>
<meta itemprop="property" content="domain_dimension_tensor"/>
<meta itemprop="property" content="inverse"/>
<meta itemprop="property" content="log_abs_determinant"/>
<meta itemprop="property" content="matmul"/>
<meta itemprop="property" content="matvec"/>
<meta itemprop="property" content="range_dimension_tensor"/>
<meta itemprop="property" content="shape_tensor"/>
<meta itemprop="property" content="solve"/>
<meta itemprop="property" content="solvevec"/>
<meta itemprop="property" content="tensor_rank_tensor"/>
<meta itemprop="property" content="to_dense"/>
<meta itemprop="property" content="trace"/>
</div>


<h1>tf.linalg.LinearOperatorIdentity</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator_identity.py">View source</a></p>

<h2>Class <code>LinearOperatorIdentity</code></h2>

<!-- Start diff -->


<p><code>LinearOperator</code> acting like a [batch] square identity matrix.</p>

<h3>Aliases:</h3>

<ul>
<li>Class <code>tf.compat.v1.linalg.LinearOperatorIdentity</code></li>
<li>Class <code>tf.compat.v2.linalg.LinearOperatorIdentity</code></li>
</ul>


<!-- Placeholder for "Used in" -->


<p>This operator acts like a [batch] identity matrix <code>A</code> with shape
<code>[B1,...,Bb, N, N]</code> for some <code>b &gt;= 0</code>.  The first <code>b</code> indices index a
batch member.  For every batch index <code>(i1,...,ib)</code>, <code>A[i1,...,ib, : :]</code> is
an <code>N x N</code> matrix.  This matrix <code>A</code> is not materialized, but for
purposes of broadcasting this shape will be relevant.</p>

<p><code>LinearOperatorIdentity</code> is initialized with <code>num_rows</code>, and optionally
<code>batch_shape</code>, and <code>dtype</code> arguments.  If <code>batch_shape</code> is <code>None</code>, this
operator efficiently passes through all arguments.  If <code>batch_shape</code> is
provided, broadcasting may occur, which will require making copies.</p>

<p>```python</p>

<h1>Create a 2 x 2 identity matrix.</h1>

<p>operator = LinearOperatorIdentity(num_rows=2, dtype=tf.float32)</p>

<p>operator.to_dense()
==> [[1., 0.]
     [0., 1.]]</p>

<p>operator.shape
==> [2, 2]</p>

<p>operator.log_abs_determinant()
==> 0.</p>

<p>x = &hellip; Shape [2, 4] Tensor
operator.matmul(x)
==> Shape [2, 4] Tensor, same as x.</p>

<p>y = tf.random.normal(shape=[3, 2, 4])</p>

<h1>Note that y.shape is compatible with operator.shape because operator.shape</h1>

<h1>is broadcast to [3, 2, 2].</h1>

<h1>This broadcast does NOT require copying data, since we can infer that y</h1>

<h1>will be passed through without changing shape.  We are always able to infer</h1>

<h1>this if the operator has no batch_shape.</h1>

<p>x = operator.solve(y)
==> Shape [3, 2, 4] Tensor, same as y.</p>

<h1>Create a 2-batch of 2x2 identity matrices</h1>

<p>operator = LinearOperatorIdentity(num_rows=2, batch_shape=[2])
operator.to_dense()
==> [[[1., 0.]
      [0., 1.]],
     [[1., 0.]
      [0., 1.]]]</p>

<h1>Here, even though the operator has a batch shape, the input is the same as</h1>

<h1>the output, so x can be passed through without a copy.  The operator is able</h1>

<h1>to detect that no broadcast is necessary because both x and the operator</h1>

<h1>have statically defined shape.</h1>

<p>x = &hellip; Shape [2, 2, 3]
operator.matmul(x)
==> Shape [2, 2, 3] Tensor, same as x</p>

<h1>Here the operator and x have different batch_shape, and are broadcast.</h1>

<h1>This requires a copy, since the output is different size than the input.</h1>

<p>x = &hellip; Shape [1, 2, 3]
operator.matmul(x)
==> Shape [2, 2, 3] Tensor, equal to [x, x]
```</p>

<h3>Shape compatibility</h3>

<p>This operator acts on [batch] matrix with compatible shape.
<code>x</code> is a batch matrix with compatible shape for <code>matmul</code> and <code>solve</code> if</p>

<p><code>
operator.shape = [B1,...,Bb] + [N, N],  with b &gt;= 0
x.shape =   [C1,...,Cc] + [N, R],
and [C1,...,Cc] broadcasts with [B1,...,Bb] to [D1,...,Dd]
</code></p>

<h3>Performance</h3>

<p>If <code>batch_shape</code> initialization arg is <code>None</code>:</p>

<ul>
<li><code>operator.matmul(x)</code> is <code>O(1)</code></li>
<li><code>operator.solve(x)</code> is <code>O(1)</code></li>
<li><code>operator.determinant()</code> is <code>O(1)</code></li>
</ul>


<p>If <code>batch_shape</code> initialization arg is provided, and static checks cannot
rule out the need to broadcast:</p>

<ul>
<li><code>operator.matmul(x)</code> is <code>O(D1*...*Dd*N*R)</code></li>
<li><code>operator.solve(x)</code> is <code>O(D1*...*Dd*N*R)</code></li>
<li><code>operator.determinant()</code> is <code>O(B1*...*Bb)</code></li>
</ul>


<h4>Matrix property hints</h4>

<p>This <code>LinearOperator</code> is initialized with boolean flags of the form <code>is_X</code>,
for <code>X = non_singular, self_adjoint, positive_definite, square</code>.
These have the following meaning:</p>

<ul>
<li>If <code>is_X == True</code>, callers should expect the operator to have the
property <code>X</code>.  This is a promise that should be fulfilled, but is <em>not</em> a
runtime assert.  For example, finite floating point precision may result
in these promises being violated.</li>
<li>If <code>is_X == False</code>, callers should expect the operator to not have <code>X</code>.</li>
<li>If <code>is_X == None</code> (the default), callers should have no expectation either
way.</li>
</ul>


<h2 id="__init__"><code>__init__</code></h2>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator_identity.py">View source</a></p>

<p><code>python
__init__(
    num_rows,
    batch_shape=None,
    dtype=None,
    is_non_singular=True,
    is_self_adjoint=True,
    is_positive_definite=True,
    is_square=True,
    assert_proper_shapes=False,
    name='LinearOperatorIdentity'
)
</code></p>

<p>Initialize a <code>LinearOperatorIdentity</code>.</p>

<p>The <code>LinearOperatorIdentity</code> is initialized with arguments defining <code>dtype</code>
and shape.</p>

<p>This operator is able to broadcast the leading (batch) dimensions, which
sometimes requires copying data.  If <code>batch_shape</code> is <code>None</code>, the operator
can take arguments of any batch shape without copying.  See examples.</p>

<h4>Args:</h4>

<ul>
<li><b><code>num_rows</code></b>:  Scalar non-negative integer <code>Tensor</code>.  Number of rows in the
corresponding identity matrix.</li>
<li><b><code>batch_shape</code></b>:  Optional <code>1-D</code> integer <code>Tensor</code>.  The shape of the leading
dimensions.  If <code>None</code>, this operator has no leading dimensions.</li>
<li><b><code>dtype</code></b>:  Data type of the matrix that this operator represents.</li>
<li><b><code>is_non_singular</code></b>:  Expect that this operator is non-singular.</li>
<li><b><code>is_self_adjoint</code></b>:  Expect that this operator is equal to its hermitian
transpose.</li>
<li><b><code>is_positive_definite</code></b>:  Expect that this operator is positive definite,
meaning the quadratic form <code>x^H A x</code> has positive real part for all
nonzero <code>x</code>.  Note that we do not require the operator to be
self-adjoint to be positive-definite.  See:
https://en.wikipedia.org/wiki/Positive-definite_matrix#Extension_for_non-symmetric_matrices</li>
<li><b><code>is_square</code></b>:  Expect that this operator acts like square [batch] matrices.</li>
<li><b><code>assert_proper_shapes</code></b>:  Python <code>bool</code>.  If <code>False</code>, only perform static
checks that initialization and method arguments have proper shape.
If <code>True</code>, and static checks are inconclusive, add asserts to the graph.</li>
<li><b><code>name</code></b>: A name for this <code>LinearOperator</code></li>
</ul>


<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>:  If <code>num_rows</code> is determined statically to be non-scalar, or
negative.</li>
<li><b><code>ValueError</code></b>:  If <code>batch_shape</code> is determined statically to not be 1-D, or
negative.</li>
<li><b><code>ValueError</code></b>:  If any of the following is not <code>True</code>:
<code>{is_self_adjoint, is_non_singular, is_positive_definite}</code>.</li>
<li><b><code>TypeError</code></b>:  If <code>num_rows</code> or <code>batch_shape</code> is ref-type (e.g. Variable).</li>
</ul>


<h2>Properties</h2>

<h3 id="H"><code>H</code></h3>


<p>Returns the adjoint of the current <code>LinearOperator</code>.</p>

<p>Given <code>A</code> representing this <code>LinearOperator</code>, return <code>A*</code>.
Note that calling <code>self.adjoint()</code> and <code>self.H</code> are equivalent.</p>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>


<h4>Returns:</h4>

<p><code>LinearOperator</code> which represents the adjoint of this <code>LinearOperator</code>.</p>

<h3 id="batch_shape"><code>batch_shape</code></h3>


<p><code>TensorShape</code> of batch dimensions of this <code>LinearOperator</code>.</p>

<p>If this operator acts like the batch matrix <code>A</code> with
<code>A.shape = [B1,...,Bb, M, N]</code>, then this returns
<code>TensorShape([B1,...,Bb])</code>, equivalent to <code>A.get_shape()[:-2]</code></p>

<h4>Returns:</h4>

<p><code>TensorShape</code>, statically determined, may be undefined.</p>

<h3 id="domain_dimension"><code>domain_dimension</code></h3>


<p>Dimension (in the sense of vector spaces) of the domain of this operator.</p>

<p>If this operator acts like the batch matrix <code>A</code> with
<code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>N</code>.</p>

<h4>Returns:</h4>

<p><code>Dimension</code> object.</p>

<h3 id="dtype"><code>dtype</code></h3>


<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>LinearOperator</code>.</p>

<h3 id="graph_parents"><code>graph_parents</code></h3>


<p>List of graph dependencies of this <code>LinearOperator</code>.</p>

<h3 id="is_non_singular"><code>is_non_singular</code></h3>




<h3 id="is_positive_definite"><code>is_positive_definite</code></h3>




<h3 id="is_self_adjoint"><code>is_self_adjoint</code></h3>




<h3 id="is_square"><code>is_square</code></h3>


<p>Return <code>True/False</code> depending on if this operator is square.</p>

<h3 id="range_dimension"><code>range_dimension</code></h3>


<p>Dimension (in the sense of vector spaces) of the range of this operator.</p>

<p>If this operator acts like the batch matrix <code>A</code> with
<code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>M</code>.</p>

<h4>Returns:</h4>

<p><code>Dimension</code> object.</p>

<h3 id="shape"><code>shape</code></h3>


<p><code>TensorShape</code> of this <code>LinearOperator</code>.</p>

<p>If this operator acts like the batch matrix <code>A</code> with
<code>A.shape = [B1,...,Bb, M, N]</code>, then this returns
<code>TensorShape([B1,...,Bb, M, N])</code>, equivalent to <code>A.get_shape()</code>.</p>

<h4>Returns:</h4>

<p><code>TensorShape</code>, statically determined, may be undefined.</p>

<h3 id="tensor_rank"><code>tensor_rank</code></h3>


<p>Rank (in the sense of tensors) of matrix corresponding to this operator.</p>

<p>If this operator acts like the batch matrix <code>A</code> with
<code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>b + 2</code>.</p>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>


<h4>Returns:</h4>

<p>Python integer, or None if the tensor rank is undefined.</p>

<h2>Methods</h2>

<h3 id="add_to_tensor"><code>add_to_tensor</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator_identity.py">View source</a></p>

<p><code>python
add_to_tensor(
    mat,
    name='add_to_tensor'
)
</code></p>

<p>Add matrix represented by this operator to <code>mat</code>.  Equiv to <code>I + mat</code>.</p>

<h4>Args:</h4>

<ul>
<li><b><code>mat</code></b>:  <code>Tensor</code> with same <code>dtype</code> and shape broadcastable to <code>self</code>.</li>
<li><b><code>name</code></b>:  A name to give this <code>Op</code>.</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code> with broadcast shape and same <code>dtype</code> as <code>self</code>.</p>

<h3 id="adjoint"><code>adjoint</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>

<p><code>python
adjoint(name='adjoint')
</code></p>

<p>Returns the adjoint of the current <code>LinearOperator</code>.</p>

<p>Given <code>A</code> representing this <code>LinearOperator</code>, return <code>A*</code>.
Note that calling <code>self.adjoint()</code> and <code>self.H</code> are equivalent.</p>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>


<h4>Returns:</h4>

<p><code>LinearOperator</code> which represents the adjoint of this <code>LinearOperator</code>.</p>

<h3 id="assert_non_singular"><code>assert_non_singular</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>

<p><code>python
assert_non_singular(name='assert_non_singular')
</code></p>

<p>Returns an <code>Op</code> that asserts this operator is non singular.</p>

<p>This operator is considered non-singular if</p>

<p><code>
ConditionNumber &lt; max{100, range_dimension, domain_dimension} * eps,
eps := np.finfo(self.dtype.as_numpy_dtype).eps
</code></p>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>:  A string name to prepend to created ops.</li>
</ul>


<h4>Returns:</h4>

<p>An <code>Assert</code> <code>Op</code>, that, when run, will raise an <code>InvalidArgumentError</code> if
  the operator is singular.</p>

<h3 id="assert_positive_definite"><code>assert_positive_definite</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>

<p><code>python
assert_positive_definite(name='assert_positive_definite')
</code></p>

<p>Returns an <code>Op</code> that asserts this operator is positive definite.</p>

<p>Here, positive definite means that the quadratic form <code>x^H A x</code> has positive
real part for all nonzero <code>x</code>.  Note that we do not require the operator to
be self-adjoint to be positive definite.</p>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>:  A name to give this <code>Op</code>.</li>
</ul>


<h4>Returns:</h4>

<p>An <code>Assert</code> <code>Op</code>, that, when run, will raise an <code>InvalidArgumentError</code> if
  the operator is not positive definite.</p>

<h3 id="assert_self_adjoint"><code>assert_self_adjoint</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>

<p><code>python
assert_self_adjoint(name='assert_self_adjoint')
</code></p>

<p>Returns an <code>Op</code> that asserts this operator is self-adjoint.</p>

<p>Here we check that this operator is <em>exactly</em> equal to its hermitian
transpose.</p>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>:  A string name to prepend to created ops.</li>
</ul>


<h4>Returns:</h4>

<p>An <code>Assert</code> <code>Op</code>, that, when run, will raise an <code>InvalidArgumentError</code> if
  the operator is not self-adjoint.</p>

<h3 id="batch_shape_tensor"><code>batch_shape_tensor</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>

<p><code>python
batch_shape_tensor(name='batch_shape_tensor')
</code></p>

<p>Shape of batch dimensions of this operator, determined at runtime.</p>

<p>If this operator acts like the batch matrix <code>A</code> with
<code>A.shape = [B1,...,Bb, M, N]</code>, then this returns a <code>Tensor</code> holding
<code>[B1,...,Bb]</code>.</p>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>


<h4>Returns:</h4>

<p><code>int32</code> <code>Tensor</code></p>

<h3 id="cholesky"><code>cholesky</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>

<p><code>python
cholesky(name='cholesky')
</code></p>

<p>Returns a Cholesky factor as a <code>LinearOperator</code>.</p>

<p>Given <code>A</code> representing this <code>LinearOperator</code>, if <code>A</code> is positive definite
self-adjoint, return <code>L</code>, where <code>A = L L^T</code>, i.e. the cholesky
decomposition.</p>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>


<h4>Returns:</h4>

<p><code>LinearOperator</code> which represents the lower triangular matrix
in the Cholesky decomposition.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: When the <code>LinearOperator</code> is not hinted to be positive
definite and self adjoint.</li>
</ul>


<h3 id="determinant"><code>determinant</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>

<p><code>python
determinant(name='det')
</code></p>

<p>Determinant for every batch member.</p>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>


<h4>Returns:</h4>

<p><code>Tensor</code> with shape <code>self.batch_shape</code> and same <code>dtype</code> as <code>self</code>.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>NotImplementedError</code></b>:  If <code>self.is_square</code> is <code>False</code>.</li>
</ul>


<h3 id="diag_part"><code>diag_part</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>

<p><code>python
diag_part(name='diag_part')
</code></p>

<p>Efficiently get the [batch] diagonal part of this operator.</p>

<p>If this operator has shape <code>[B1,...,Bb, M, N]</code>, this returns a
<code>Tensor</code> <code>diagonal</code>, of shape <code>[B1,...,Bb, min(M, N)]</code>, where
<code>diagonal[b1,...,bb, i] = self.to_dense()[b1,...,bb, i, i]</code>.</p>

<p>```
my_operator = LinearOperatorDiag([1., 2.])</p>

<h1>Efficiently get the diagonal</h1>

<p>my_operator.diag_part()
==> [1., 2.]</p>

<h1>Equivalent, but inefficient method</h1>

<p>tf.linalg.diag_part(my_operator.to_dense())
==> [1., 2.]
```</p>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>


<h4>Returns:</h4>

<ul>
<li><b><code>diag_part</code></b>:  A <code>Tensor</code> of same <code>dtype</code> as self.</li>
</ul>


<h3 id="domain_dimension_tensor"><code>domain_dimension_tensor</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>

<p><code>python
domain_dimension_tensor(name='domain_dimension_tensor')
</code></p>

<p>Dimension (in the sense of vector spaces) of the domain of this operator.</p>

<p>Determined at runtime.</p>

<p>If this operator acts like the batch matrix <code>A</code> with
<code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>N</code>.</p>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>


<h4>Returns:</h4>

<p><code>int32</code> <code>Tensor</code></p>

<h3 id="inverse"><code>inverse</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>

<p><code>python
inverse(name='inverse')
</code></p>

<p>Returns the Inverse of this <code>LinearOperator</code>.</p>

<p>Given <code>A</code> representing this <code>LinearOperator</code>, return a <code>LinearOperator</code>
representing <code>A^-1</code>.</p>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>: A name scope to use for ops added by this method.</li>
</ul>


<h4>Returns:</h4>

<p><code>LinearOperator</code> representing inverse of this matrix.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: When the <code>LinearOperator</code> is not hinted to be <code>non_singular</code>.</li>
</ul>


<h3 id="log_abs_determinant"><code>log_abs_determinant</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>

<p><code>python
log_abs_determinant(name='log_abs_det')
</code></p>

<p>Log absolute value of determinant for every batch member.</p>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>


<h4>Returns:</h4>

<p><code>Tensor</code> with shape <code>self.batch_shape</code> and same <code>dtype</code> as <code>self</code>.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>NotImplementedError</code></b>:  If <code>self.is_square</code> is <code>False</code>.</li>
</ul>


<h3 id="matmul"><code>matmul</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>

<p><code>python
matmul(
    x,
    adjoint=False,
    adjoint_arg=False,
    name='matmul'
)
</code></p>

<p>Transform [batch] matrix <code>x</code> with left multiplication:  <code>x --&gt; Ax</code>.</p>

<p>```python</p>

<h1>Make an operator acting like batch matrix A.  Assume A.shape = [&hellip;, M, N]</h1>

<p>operator = LinearOperator(&hellip;)
operator.shape = [&hellip;, M, N]</p>

<p>X = &hellip; # shape [&hellip;, N, R], batch matrix, R > 0.</p>

<p>Y = operator.matmul(X)
Y.shape
==> [&hellip;, M, R]</p>

<p>Y[&hellip;, :, r] = sum_j A[&hellip;, :, j] X[j, r]
```</p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: <code>LinearOperator</code> or <code>Tensor</code> with compatible shape and same <code>dtype</code> as
<code>self</code>. See class docstring for definition of compatibility.</li>
<li><b><code>adjoint</code></b>: Python <code>bool</code>.  If <code>True</code>, left multiply by the adjoint: <code>A^H x</code>.</li>
<li><b><code>adjoint_arg</code></b>:  Python <code>bool</code>.  If <code>True</code>, compute <code>A x^H</code> where <code>x^H</code> is
the hermitian transpose (transposition and complex conjugation).</li>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>


<h4>Returns:</h4>

<p>A <code>LinearOperator</code> or <code>Tensor</code> with shape <code>[..., M, R]</code> and same <code>dtype</code>
  as <code>self</code>.</p>

<h3 id="matvec"><code>matvec</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>

<p><code>python
matvec(
    x,
    adjoint=False,
    name='matvec'
)
</code></p>

<p>Transform [batch] vector <code>x</code> with left multiplication:  <code>x --&gt; Ax</code>.</p>

<p>```python</p>

<h1>Make an operator acting like batch matric A.  Assume A.shape = [&hellip;, M, N]</h1>

<p>operator = LinearOperator(&hellip;)</p>

<p>X = &hellip; # shape [&hellip;, N], batch vector</p>

<p>Y = operator.matvec(X)
Y.shape
==> [&hellip;, M]</p>

<p>Y[&hellip;, :] = sum_j A[&hellip;, :, j] X[&hellip;, j]
```</p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: <code>Tensor</code> with compatible shape and same <code>dtype</code> as <code>self</code>.
<code>x</code> is treated as a [batch] vector meaning for every set of leading
dimensions, the last dimension defines a vector.
See class docstring for definition of compatibility.</li>
<li><b><code>adjoint</code></b>: Python <code>bool</code>.  If <code>True</code>, left multiply by the adjoint: <code>A^H x</code>.</li>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code> with shape <code>[..., M]</code> and same <code>dtype</code> as <code>self</code>.</p>

<h3 id="range_dimension_tensor"><code>range_dimension_tensor</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>

<p><code>python
range_dimension_tensor(name='range_dimension_tensor')
</code></p>

<p>Dimension (in the sense of vector spaces) of the range of this operator.</p>

<p>Determined at runtime.</p>

<p>If this operator acts like the batch matrix <code>A</code> with
<code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>M</code>.</p>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>


<h4>Returns:</h4>

<p><code>int32</code> <code>Tensor</code></p>

<h3 id="shape_tensor"><code>shape_tensor</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>

<p><code>python
shape_tensor(name='shape_tensor')
</code></p>

<p>Shape of this <code>LinearOperator</code>, determined at runtime.</p>

<p>If this operator acts like the batch matrix <code>A</code> with
<code>A.shape = [B1,...,Bb, M, N]</code>, then this returns a <code>Tensor</code> holding
<code>[B1,...,Bb, M, N]</code>, equivalent to <a href="../../tf/shape.html"><code>tf.shape(A)</code></a>.</p>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>


<h4>Returns:</h4>

<p><code>int32</code> <code>Tensor</code></p>

<h3 id="solve"><code>solve</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>

<p><code>python
solve(
    rhs,
    adjoint=False,
    adjoint_arg=False,
    name='solve'
)
</code></p>

<p>Solve (exact or approx) <code>R</code> (batch) systems of equations: <code>A X = rhs</code>.</p>

<p>The returned <code>Tensor</code> will be close to an exact solution if <code>A</code> is well
conditioned. Otherwise closeness will vary. See class docstring for details.</p>

<h4>Examples:</h4>

<p>```python</p>

<h1>Make an operator acting like batch matrix A.  Assume A.shape = [&hellip;, M, N]</h1>

<p>operator = LinearOperator(&hellip;)
operator.shape = [&hellip;, M, N]</p>

<h1>Solve R > 0 linear systems for every member of the batch.</h1>

<p>RHS = &hellip; # shape [&hellip;, M, R]</p>

<p>X = operator.solve(RHS)</p>

<h1>X[&hellip;, :, r] is the solution to the r'th linear system</h1>

<h1>sum_j A[&hellip;, :, j] X[&hellip;, j, r] = RHS[&hellip;, :, r]</h1>

<p>operator.matmul(X)
==> RHS
```</p>

<h4>Args:</h4>

<ul>
<li><b><code>rhs</code></b>: <code>Tensor</code> with same <code>dtype</code> as this operator and compatible shape.
<code>rhs</code> is treated like a [batch] matrix meaning for every set of leading
dimensions, the last two dimensions defines a matrix.
See class docstring for definition of compatibility.</li>
<li><b><code>adjoint</code></b>: Python <code>bool</code>.  If <code>True</code>, solve the system involving the adjoint
of this <code>LinearOperator</code>:  <code>A^H X = rhs</code>.</li>
<li><b><code>adjoint_arg</code></b>:  Python <code>bool</code>.  If <code>True</code>, solve <code>A X = rhs^H</code> where <code>rhs^H</code>
is the hermitian transpose (transposition and complex conjugation).</li>
<li><b><code>name</code></b>:  A name scope to use for ops added by this method.</li>
</ul>


<h4>Returns:</h4>

<p><code>Tensor</code> with shape <code>[...,N, R]</code> and same <code>dtype</code> as <code>rhs</code>.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>NotImplementedError</code></b>:  If <code>self.is_non_singular</code> or <code>is_square</code> is False.</li>
</ul>


<h3 id="solvevec"><code>solvevec</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>

<p><code>python
solvevec(
    rhs,
    adjoint=False,
    name='solve'
)
</code></p>

<p>Solve single equation with best effort: <code>A X = rhs</code>.</p>

<p>The returned <code>Tensor</code> will be close to an exact solution if <code>A</code> is well
conditioned. Otherwise closeness will vary. See class docstring for details.</p>

<h4>Examples:</h4>

<p>```python</p>

<h1>Make an operator acting like batch matrix A.  Assume A.shape = [&hellip;, M, N]</h1>

<p>operator = LinearOperator(&hellip;)
operator.shape = [&hellip;, M, N]</p>

<h1>Solve one linear system for every member of the batch.</h1>

<p>RHS = &hellip; # shape [&hellip;, M]</p>

<p>X = operator.solvevec(RHS)</p>

<h1>X is the solution to the linear system</h1>

<h1>sum_j A[&hellip;, :, j] X[&hellip;, j] = RHS[&hellip;, :]</h1>

<p>operator.matvec(X)
==> RHS
```</p>

<h4>Args:</h4>

<ul>
<li><b><code>rhs</code></b>: <code>Tensor</code> with same <code>dtype</code> as this operator.
<code>rhs</code> is treated like a [batch] vector meaning for every set of leading
dimensions, the last dimension defines a vector.  See class docstring
for definition of compatibility regarding batch dimensions.</li>
<li><b><code>adjoint</code></b>: Python <code>bool</code>.  If <code>True</code>, solve the system involving the adjoint
of this <code>LinearOperator</code>:  <code>A^H X = rhs</code>.</li>
<li><b><code>name</code></b>:  A name scope to use for ops added by this method.</li>
</ul>


<h4>Returns:</h4>

<p><code>Tensor</code> with shape <code>[...,N]</code> and same <code>dtype</code> as <code>rhs</code>.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>NotImplementedError</code></b>:  If <code>self.is_non_singular</code> or <code>is_square</code> is False.</li>
</ul>


<h3 id="tensor_rank_tensor"><code>tensor_rank_tensor</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>

<p><code>python
tensor_rank_tensor(name='tensor_rank_tensor')
</code></p>

<p>Rank (in the sense of tensors) of matrix corresponding to this operator.</p>

<p>If this operator acts like the batch matrix <code>A</code> with
<code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>b + 2</code>.</p>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>


<h4>Returns:</h4>

<p><code>int32</code> <code>Tensor</code>, determined at runtime.</p>

<h3 id="to_dense"><code>to_dense</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>

<p><code>python
to_dense(name='to_dense')
</code></p>

<p>Return a dense (batch) matrix representing this operator.</p>

<h3 id="trace"><code>trace</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>

<p><code>python
trace(name='trace')
</code></p>

<p>Trace of the linear operator, equal to sum of <code>self.diag_part()</code>.</p>

<p>If the operator is square, this is also the sum of the eigenvalues.</p>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>


<h4>Returns:</h4>

<p>Shape <code>[B1,...,Bb]</code> <code>Tensor</code> of same <code>dtype</code> as <code>self</code>.</p>
