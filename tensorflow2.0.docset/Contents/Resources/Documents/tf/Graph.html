
    <html lang="zh-cn">
    <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <link href=../../default.css" rel="stylesheet">
    <link href="
   ../../github.css" rel="stylesheet">
    </head>
    <body>
    <div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.Graph" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="building_function"/>
<meta itemprop="property" content="collections"/>
<meta itemprop="property" content="finalized"/>
<meta itemprop="property" content="graph_def_versions"/>
<meta itemprop="property" content="seed"/>
<meta itemprop="property" content="version"/>
<meta itemprop="property" content="__init__"/>
<meta itemprop="property" content="add_to_collection"/>
<meta itemprop="property" content="add_to_collections"/>
<meta itemprop="property" content="as_default"/>
<meta itemprop="property" content="as_graph_def"/>
<meta itemprop="property" content="as_graph_element"/>
<meta itemprop="property" content="clear_collection"/>
<meta itemprop="property" content="colocate_with"/>
<meta itemprop="property" content="container"/>
<meta itemprop="property" content="control_dependencies"/>
<meta itemprop="property" content="create_op"/>
<meta itemprop="property" content="device"/>
<meta itemprop="property" content="finalize"/>
<meta itemprop="property" content="get_all_collection_keys"/>
<meta itemprop="property" content="get_collection"/>
<meta itemprop="property" content="get_collection_ref"/>
<meta itemprop="property" content="get_name_scope"/>
<meta itemprop="property" content="get_operation_by_name"/>
<meta itemprop="property" content="get_operations"/>
<meta itemprop="property" content="get_tensor_by_name"/>
<meta itemprop="property" content="gradient_override_map"/>
<meta itemprop="property" content="is_feedable"/>
<meta itemprop="property" content="is_fetchable"/>
<meta itemprop="property" content="name_scope"/>
<meta itemprop="property" content="prevent_feeding"/>
<meta itemprop="property" content="prevent_fetching"/>
<meta itemprop="property" content="switch_to_thread_local"/>
<meta itemprop="property" content="unique_name"/>
</div>

<h1 id="tfgraph">tf.Graph</h1>
<!-- Insert buttons -->

<table class="tfo-notebook-buttons tfo-api" align="left">
</table>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<h2 id="class-graph">Class <code>Graph</code></h2>
<!-- Start diff -->

<p>A TensorFlow computation, represented as a dataflow graph.</p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li>Class <code>tf.compat.v1.Graph</code></li>
<li>Class <code>tf.compat.v2.Graph</code></li>
</ul>
<!-- Placeholder for "Used in" -->

<p>A <code>Graph</code> contains a set of
<a href="../tf/Operation.html"><code>tf.Operation</code></a> objects,
which represent units of computation; and
<a href="../tf/Tensor.html"><code>tf.Tensor</code></a> objects, which represent
the units of data that flow between operations.</p>
<p>A default <code>Graph</code> is always registered, and accessible by calling
<a href="../tf/compat/v1/get_default_graph.html"><code>tf.compat.v1.get_default_graph</code></a>.
To add an operation to the default graph, simply call one of the functions
that defines a new <code>Operation</code>:</p>
<div class="codehilite"><pre><span></span><span class="n">c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">4.0</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">c</span><span class="o">.</span><span class="n">graph</span> <span class="ow">is</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span>
</pre></div>


<p>Another typical usage involves the
<a href="../tf/Graph.html#as_default"><code>tf.Graph.as_default</code></a>
context manager, which overrides the current default graph for the
lifetime of the context:</p>
<div class="codehilite"><pre><span></span><span class="n">g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
  <span class="c1"># Define operations and tensors in `g`.</span>
  <span class="n">c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">30.0</span><span class="p">)</span>
  <span class="k">assert</span> <span class="n">c</span><span class="o">.</span><span class="n">graph</span> <span class="ow">is</span> <span class="n">g</span>
</pre></div>


<p>Important note: This class <em>is not</em> thread-safe for graph construction. All
operations should be created from a single thread, or external
synchronization must be provided. Unless otherwise specified, all methods
are not thread-safe.</p>
<p>A <code>Graph</code> instance supports an arbitrary number of "collections"
that are identified by name. For convenience when building a large
graph, collections can store groups of related objects: for
example, the <a href="../tf/Variable.html"><code>tf.Variable</code></a> uses a collection (named
<code>tf.GraphKeys.GLOBAL_VARIABLES</code>) for
all variables that are created during the construction of a graph. The caller
may define additional collections by specifying a new name.</p>
<h2 id="__init__"><code>__init__</code></h2>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="fm">__init__</span><span class="p">()</span>
</pre></div>


<p>Creates a new, empty Graph.</p>
<h2 id="properties">Properties</h2>
<h3 id="building_function"><code>building_function</code></h3>

<p>Returns True iff this graph represents a function.</p>
<h3 id="collections"><code>collections</code></h3>

<p>Returns the names of the collections known to this graph.</p>
<h3 id="finalized"><code>finalized</code></h3>

<p>True if this graph has been finalized.</p>
<h3 id="graph_def_versions"><code>graph_def_versions</code></h3>

<p>The GraphDef version information of this graph.</p>
<p>For details on the meaning of each version, see
<a href="https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto"><code>GraphDef</code></a>.</p>
<h4 id="returns">Returns:</h4>
<p>A <code>VersionDef</code>.</p>
<h3 id="seed"><code>seed</code></h3>

<p>The graph-level random seed of this graph.</p>
<h3 id="version"><code>version</code></h3>

<p>Returns a version number that increases as ops are added to the graph.</p>
<p>Note that this is unrelated to the
<a href="../tf/Graph.html#graph_def_versions"><code>tf.Graph.graph_def_versions</code></a>.</p>
<h4 id="returns_1">Returns:</h4>
<p>An integer version that increases as ops are added to the graph.</p>
<h2 id="methods">Methods</h2>
<h3 id="add_to_collection"><code>add_to_collection</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">add_to_collection</span><span class="p">(</span>
    <span class="n">name</span><span class="p">,</span>
    <span class="n">value</span>
<span class="p">)</span>
</pre></div>


<p>Stores <code>value</code> in the collection with the given <code>name</code>.</p>
<p>Note that collections are not sets, so it is possible to add a value to
a collection several times.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>name</code></b>: The key for the collection. The <code>GraphKeys</code> class contains many
  standard names for collections.</li>
<li><b><code>value</code></b>: The value to add to the collection.</li>
</ul>
<h3 id="add_to_collections"><code>add_to_collections</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">add_to_collections</span><span class="p">(</span>
    <span class="n">names</span><span class="p">,</span>
    <span class="n">value</span>
<span class="p">)</span>
</pre></div>


<p>Stores <code>value</code> in the collections given by <code>names</code>.</p>
<p>Note that collections are not sets, so it is possible to add a value to
a collection several times. This function makes sure that duplicates in
<code>names</code> are ignored, but it will not check for pre-existing membership of
<code>value</code> in any of the collections in <code>names</code>.</p>
<p><code>names</code> can be any iterable, but if <code>names</code> is a string, it is treated as a
single collection name.</p>
<h4 id="args_1">Args:</h4>
<ul>
<li><b><code>names</code></b>: The keys for the collections to add to. The <code>GraphKeys</code> class
  contains many standard names for collections.</li>
<li><b><code>value</code></b>: The value to add to the collections.</li>
</ul>
<h3 id="as_default"><code>as_default</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">as_default</span><span class="p">()</span>
</pre></div>


<p>Returns a context manager that makes this <code>Graph</code> the default graph.</p>
<p>This method should be used if you want to create multiple graphs
in the same process. For convenience, a global default graph is
provided, and all ops will be added to this graph if you do not
create a new graph explicitly.</p>
<p>Use this method with the <code>with</code> keyword to specify that ops created within
the scope of a block should be added to this graph. In this case, once
the scope of the <code>with</code> is exited, the previous default graph is set again
as default. There is a stack, so it's ok to have multiple nested levels
of <code>as_default</code> calls.</p>
<p>The default graph is a property of the current thread. If you
create a new thread, and wish to use the default graph in that
thread, you must explicitly add a <code>with g.as_default():</code> in that
thread's function.</p>
<p>The following code examples are equivalent:</p>
<div class="codehilite"><pre><span></span><span class="c1"># 1. Using Graph.as_default():</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
  <span class="n">c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">5.0</span><span class="p">)</span>
  <span class="k">assert</span> <span class="n">c</span><span class="o">.</span><span class="n">graph</span> <span class="ow">is</span> <span class="n">g</span>

<span class="c1"># 2. Constructing and making default:</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">()</span> <span class="k">as</span> <span class="n">g</span><span class="p">:</span>
  <span class="n">c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">5.0</span><span class="p">)</span>
  <span class="k">assert</span> <span class="n">c</span><span class="o">.</span><span class="n">graph</span> <span class="ow">is</span> <span class="n">g</span>
</pre></div>


<p>If eager execution is enabled ops created under this context manager will be
added to the graph instead of executed eagerly.</p>
<h4 id="returns_2">Returns:</h4>
<p>A context manager for using this graph as the default graph.</p>
<h3 id="as_graph_def"><code>as_graph_def</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">as_graph_def</span><span class="p">(</span>
    <span class="n">from_version</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">add_shapes</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>


<p>Returns a serialized <code>GraphDef</code> representation of this graph.</p>
<p>The serialized <code>GraphDef</code> can be imported into another <code>Graph</code>
(using <a href="../tf/graph_util/import_graph_def.html"><code>tf.import_graph_def</code></a>) or used with the
<a href="../../api_docs/cc/index.html">C++ Session API</a>.</p>
<p>This method is thread-safe.</p>
<h4 id="args_2">Args:</h4>
<ul>
<li><b><code>from_version</code></b>: Optional.  If this is set, returns a <code>GraphDef</code> containing
  only the nodes that were added to this graph since its <code>version</code>
  property had the given value.</li>
<li><b><code>add_shapes</code></b>: If true, adds an "_output_shapes" list attr to each node with
  the inferred shapes of each of its outputs.</li>
</ul>
<h4 id="returns_3">Returns:</h4>
<p>A
<a href="https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto"><code>GraphDef</code></a>
protocol buffer.</p>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: If the <code>graph_def</code> would be too large.</li>
</ul>
<h3 id="as_graph_element"><code>as_graph_element</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">as_graph_element</span><span class="p">(</span>
    <span class="n">obj</span><span class="p">,</span>
    <span class="n">allow_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">allow_operation</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>


<p>Returns the object referred to by <code>obj</code>, as an <code>Operation</code> or <code>Tensor</code>.</p>
<p>This function validates that <code>obj</code> represents an element of this
graph, and gives an informative error message if it is not.</p>
<p>This function is the canonical way to get/validate an object of
one of the allowed types from an external argument reference in the
Session API.</p>
<p>This method may be called concurrently from multiple threads.</p>
<h4 id="args_3">Args:</h4>
<ul>
<li><b><code>obj</code></b>: A <code>Tensor</code>, an <code>Operation</code>, or the name of a tensor or operation. Can
  also be any object with an <code>_as_graph_element()</code> method that returns a
  value of one of these types. Note: <code>_as_graph_element</code> will be called
  inside the graph's lock and so may not modify the graph.</li>
<li><b><code>allow_tensor</code></b>: If true, <code>obj</code> may refer to a <code>Tensor</code>.</li>
<li><b><code>allow_operation</code></b>: If true, <code>obj</code> may refer to an <code>Operation</code>.</li>
</ul>
<h4 id="returns_4">Returns:</h4>
<p>The <code>Tensor</code> or <code>Operation</code> in the Graph corresponding to <code>obj</code>.</p>
<h4 id="raises_1">Raises:</h4>
<ul>
<li><b><code>TypeError</code></b>: If <code>obj</code> is not a type we support attempting to convert
  to types.</li>
<li><b><code>ValueError</code></b>: If <code>obj</code> is of an appropriate type but invalid. For
  example, an invalid string.</li>
<li><b><code>KeyError</code></b>: If <code>obj</code> is not an object in the graph.</li>
</ul>
<h3 id="clear_collection"><code>clear_collection</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">clear_collection</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
</pre></div>


<p>Clears all values in a collection.</p>
<h4 id="args_4">Args:</h4>
<ul>
<li><b><code>name</code></b>: The key for the collection. The <code>GraphKeys</code> class contains many
  standard names for collections.</li>
</ul>
<h3 id="colocate_with"><code>colocate_with</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">colocate_with</span><span class="p">(</span>
    <span class="n">op</span><span class="p">,</span>
    <span class="n">ignore_existing</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>


<p>Returns a context manager that specifies an op to colocate with.</p>
<p>Note: this function is not for public use, only for internal libraries.</p>
<h4 id="for-example">For example:</h4>
<div class="codehilite"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">([</span><span class="mf">1.0</span><span class="p">])</span>
<span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">colocate_with</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
  <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
  <span class="n">c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</pre></div>


<p><code>b</code> and <code>c</code> will always be colocated with <code>a</code>, no matter where <code>a</code>
is eventually placed.</p>
<p><strong>NOTE</strong> Using a colocation scope resets any existing device constraints.</p>
<p>If <code>op</code> is <code>None</code> then <code>ignore_existing</code> must be <code>True</code> and the new
scope resets all colocation and device constraints.</p>
<h4 id="args_5">Args:</h4>
<ul>
<li><b><code>op</code></b>: The op to colocate all created ops with, or <code>None</code>.</li>
<li><b><code>ignore_existing</code></b>: If true, only applies colocation of this op within the
  context, rather than applying all colocation properties on the stack.
  If <code>op</code> is <code>None</code>, this value must be <code>True</code>.</li>
</ul>
<h4 id="raises_2">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: if op is None but ignore_existing is False.</li>
</ul>
<h4 id="yields">Yields:</h4>
<p>A context manager that specifies the op with which to colocate
newly created ops.</p>
<h3 id="container"><code>container</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">container</span><span class="p">(</span><span class="n">container_name</span><span class="p">)</span>
</pre></div>


<p>Returns a context manager that specifies the resource container to use.</p>
<p>Stateful operations, such as variables and queues, can maintain their
states on devices so that they can be shared by multiple processes.
A resource container is a string name under which these stateful
operations are tracked. These resources can be released or cleared
with <code>tf.Session.reset()</code>.</p>
<h4 id="for-example_1">For example:</h4>
<div class="codehilite"><pre><span></span><span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">container</span><span class="p">(</span><span class="s1">&#39;experiment0&#39;</span><span class="p">):</span>
  <span class="c1"># All stateful Operations constructed in this context will be placed</span>
  <span class="c1"># in resource container &quot;experiment0&quot;.</span>
  <span class="n">v1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">([</span><span class="mf">1.0</span><span class="p">])</span>
  <span class="n">v2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">([</span><span class="mf">2.0</span><span class="p">])</span>
  <span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">container</span><span class="p">(</span><span class="s2">&quot;experiment1&quot;</span><span class="p">):</span>
    <span class="c1"># All stateful Operations constructed in this context will be</span>
    <span class="c1"># placed in resource container &quot;experiment1&quot;.</span>
    <span class="n">v3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">([</span><span class="mf">3.0</span><span class="p">])</span>
    <span class="n">q1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">queue</span><span class="o">.</span><span class="n">FIFOQueue</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="c1"># All stateful Operations constructed in this context will be</span>
  <span class="c1"># be created in the &quot;experiment0&quot;.</span>
  <span class="n">v4</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">([</span><span class="mf">4.0</span><span class="p">])</span>
  <span class="n">q1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">queue</span><span class="o">.</span><span class="n">FIFOQueue</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">container</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
    <span class="c1"># All stateful Operations constructed in this context will be</span>
    <span class="c1"># be placed in the default resource container.</span>
    <span class="n">v5</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">([</span><span class="mf">5.0</span><span class="p">])</span>
    <span class="n">q3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">queue</span><span class="o">.</span><span class="n">FIFOQueue</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Resets container &quot;experiment0&quot;, after which the state of v1, v2, v4, q1</span>
<span class="c1"># will become undefined (such as uninitialized).</span>
<span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;experiment0&quot;</span><span class="p">])</span>
</pre></div>


<h4 id="args_6">Args:</h4>
<ul>
<li><b><code>container_name</code></b>: container name string.</li>
</ul>
<h4 id="returns_5">Returns:</h4>
<p>A context manager for defining resource containers for stateful ops,
  yields the container name.</p>
<h3 id="control_dependencies"><code>control_dependencies</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">control_inputs</span><span class="p">)</span>
</pre></div>


<p>Returns a context manager that specifies control dependencies.</p>
<p>Use with the <code>with</code> keyword to specify that all operations constructed
within the context should have control dependencies on
<code>control_inputs</code>. For example:</p>
<div class="codehilite"><pre><span></span><span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">]):</span>
  <span class="c1"># `d` and `e` will only run after `a`, `b`, and `c` have executed.</span>
  <span class="n">d</span> <span class="o">=</span> <span class="o">...</span>
  <span class="n">e</span> <span class="o">=</span> <span class="o">...</span>
</pre></div>


<p>Multiple calls to <code>control_dependencies()</code> can be nested, and in
that case a new <code>Operation</code> will have control dependencies on the union
of <code>control_inputs</code> from all active contexts.</p>
<div class="codehilite"><pre><span></span><span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">]):</span>
  <span class="c1"># Ops constructed here run after `a` and `b`.</span>
  <span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">]):</span>
    <span class="c1"># Ops constructed here run after `a`, `b`, `c`, and `d`.</span>
</pre></div>


<p>You can pass None to clear the control dependencies:</p>
<div class="codehilite"><pre><span></span><span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">]):</span>
  <span class="c1"># Ops constructed here run after `a` and `b`.</span>
  <span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># Ops constructed here run normally, not waiting for either `a` or `b`.</span>
    <span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">]):</span>
      <span class="c1"># Ops constructed here run after `c` and `d`, also not waiting</span>
      <span class="c1"># for either `a` or `b`.</span>
</pre></div>


<p><em>N.B.</em> The control dependencies context applies <em>only</em> to ops that
are constructed within the context. Merely using an op or tensor
in the context does not add a control dependency. The following
example illustrates this point:</p>
<div class="codehilite"><pre><span></span><span class="c1"># WRONG</span>
<span class="k">def</span> <span class="nf">my_func</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
  <span class="n">t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">pred</span><span class="p">]):</span>
    <span class="c1"># The matmul op is created outside the context, so no control</span>
    <span class="c1"># dependency will be added.</span>
    <span class="k">return</span> <span class="n">t</span>

<span class="c1"># RIGHT</span>
<span class="k">def</span> <span class="nf">my_func</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">pred</span><span class="p">]):</span>
    <span class="c1"># The matmul op is created in the context, so a control dependency</span>
    <span class="c1"># will be added.</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
</pre></div>


<p>Also note that though execution of ops created under this scope will trigger
execution of the dependencies, the ops created under this scope might still
be pruned from a normal tensorflow graph. For example, in the following
snippet of code the dependencies are never executed:</p>
<div class="codehilite"><pre><span></span>  <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">loss</span><span class="p">()</span>
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># note: dependencies ignored in the</span>
                                  <span class="c1"># backward pass</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span>
</pre></div>


<p>This is because evaluating the gradient graph does not require evaluating
the constant(1) op created in the forward pass.</p>
<h4 id="args_7">Args:</h4>
<ul>
<li><b><code>control_inputs</code></b>: A list of <code>Operation</code> or <code>Tensor</code> objects which must be
  executed or computed before running the operations defined in the
  context.  Can also be <code>None</code> to clear the control dependencies.</li>
</ul>
<h4 id="returns_6">Returns:</h4>
<p>A context manager that specifies control dependencies for all
operations constructed within the context.</p>
<h4 id="raises_3">Raises:</h4>
<ul>
<li><b><code>TypeError</code></b>: If <code>control_inputs</code> is not a list of <code>Operation</code> or
  <code>Tensor</code> objects.</li>
</ul>
<h3 id="create_op"><code>create_op</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">create_op</span><span class="p">(</span>
    <span class="n">op_type</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">,</span>
    <span class="n">dtypes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">input_types</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">attrs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">op_def</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">compute_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">compute_device</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>


<p>Creates an <code>Operation</code> in this graph. (deprecated arguments)</p>
<p>Warning: SOME ARGUMENTS ARE DEPRECATED: <code>(compute_shapes)</code>. They will be removed in a future version.
Instructions for updating:
Shapes are always computed; don't use the compute_shapes as it has no effect.</p>
<p>This is a low-level interface for creating an <code>Operation</code>. Most
programs will not call this method directly, and instead use the
Python op constructors, such as <a href="../tf/constant.html"><code>tf.constant()</code></a>, which add ops to
the default graph.</p>
<h4 id="args_8">Args:</h4>
<ul>
<li><b><code>op_type</code></b>: The <code>Operation</code> type to create. This corresponds to the
  <code>OpDef.name</code> field for the proto that defines the operation.</li>
<li><b><code>inputs</code></b>: A list of <code>Tensor</code> objects that will be inputs to the <code>Operation</code>.</li>
<li><b><code>dtypes</code></b>: (Optional) A list of <code>DType</code> objects that will be the types of the
  tensors that the operation produces.</li>
<li><b><code>input_types</code></b>: (Optional.) A list of <code>DType</code>s that will be the types of the
  tensors that the operation consumes. By default, uses the base <code>DType</code>
  of each input in <code>inputs</code>. Operations that expect reference-typed inputs
  must specify <code>input_types</code> explicitly.</li>
<li><b><code>name</code></b>: (Optional.) A string name for the operation. If not specified, a
  name is generated based on <code>op_type</code>.</li>
<li><b><code>attrs</code></b>: (Optional.) A dictionary where the key is the attribute name (a
  string) and the value is the respective <code>attr</code> attribute of the
  <code>NodeDef</code> proto that will represent the operation (an <code>AttrValue</code>
  proto).</li>
<li><b><code>op_def</code></b>: (Optional.) The <code>OpDef</code> proto that describes the <code>op_type</code> that
  the operation will have.</li>
<li><b><code>compute_shapes</code></b>: (Optional.) Deprecated. Has no effect (shapes are always
  computed).</li>
<li><b><code>compute_device</code></b>: (Optional.) If True, device functions will be executed to
  compute the device property of the Operation.</li>
</ul>
<h4 id="raises_4">Raises:</h4>
<ul>
<li><b><code>TypeError</code></b>: if any of the inputs is not a <code>Tensor</code>.</li>
<li><b><code>ValueError</code></b>: if colocation conflicts with existing device assignment.</li>
</ul>
<h4 id="returns_7">Returns:</h4>
<p>An <code>Operation</code> object.</p>
<h3 id="device"><code>device</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">device</span><span class="p">(</span><span class="n">device_name_or_function</span><span class="p">)</span>
</pre></div>


<p>Returns a context manager that specifies the default device to use.</p>
<p>The <code>device_name_or_function</code> argument may either be a device name
string, a device function, or None:</p>
<ul>
<li>If it is a device name string, all operations constructed in
  this context will be assigned to the device with that name, unless
  overridden by a nested <code>device()</code> context.</li>
<li>If it is a function, it will be treated as a function from
  Operation objects to device name strings, and invoked each time
  a new Operation is created. The Operation will be assigned to
  the device with the returned name.</li>
<li>If it is None, all <code>device()</code> invocations from the enclosing context
  will be ignored.</li>
</ul>
<p>For information about the valid syntax of device name strings, see
the documentation in
<a href="https://www.tensorflow.org/code/tensorflow/core/util/device_name_utils.h"><code>DeviceNameUtils</code></a>.</p>
<h4 id="for-example_2">For example:</h4>
<div class="codehilite"><pre><span></span><span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;/device:GPU:0&#39;</span><span class="p">):</span>
  <span class="c1"># All operations constructed in this context will be placed</span>
  <span class="c1"># on GPU 0.</span>
  <span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># All operations constructed in this context will have no</span>
    <span class="c1"># assigned device.</span>

<span class="c1"># Defines a function from `Operation` to device string.</span>
<span class="k">def</span> <span class="nf">matmul_on_gpu</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">n</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;MatMul&quot;</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;/device:GPU:0&quot;</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;/cpu:0&quot;</span>

<span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">matmul_on_gpu</span><span class="p">):</span>
  <span class="c1"># All operations of type &quot;MatMul&quot; constructed in this context</span>
  <span class="c1"># will be placed on GPU 0; all other operations will be placed</span>
  <span class="c1"># on CPU 0.</span>
</pre></div>


<p><strong>N.B.</strong> The device scope may be overridden by op wrappers or
other library code. For example, a variable assignment op
<code>v.assign()</code> must be colocated with the <a href="../tf/Variable.html"><code>tf.Variable</code></a> <code>v</code>, and
incompatible device scopes will be ignored.</p>
<h4 id="args_9">Args:</h4>
<ul>
<li><b><code>device_name_or_function</code></b>: The device name or function to use in the
  context.</li>
</ul>
<h4 id="yields_1">Yields:</h4>
<p>A context manager that specifies the default device to use for newly
created ops.</p>
<h4 id="raises_5">Raises:</h4>
<ul>
<li><b><code>RuntimeError</code></b>: If device scopes are not properly nested.</li>
</ul>
<h3 id="finalize"><code>finalize</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">finalize</span><span class="p">()</span>
</pre></div>


<p>Finalizes this graph, making it read-only.</p>
<p>After calling <code>g.finalize()</code>, no new operations can be added to
<code>g</code>.  This method is used to ensure that no operations are added
to a graph when it is shared between multiple threads, for example
when using a <a href="../tf/compat/v1/train/QueueRunner.html"><code>tf.compat.v1.train.QueueRunner</code></a>.</p>
<h3 id="get_all_collection_keys"><code>get_all_collection_keys</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">get_all_collection_keys</span><span class="p">()</span>
</pre></div>


<p>Returns a list of collections used in this graph.</p>
<h3 id="get_collection"><code>get_collection</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">get_collection</span><span class="p">(</span>
    <span class="n">name</span><span class="p">,</span>
    <span class="n">scope</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</pre></div>


<p>Returns a list of values in the collection with the given <code>name</code>.</p>
<p>This is different from <code>get_collection_ref()</code> which always returns the
actual collection list if it exists in that it returns a new list each time
it is called.</p>
<h4 id="args_10">Args:</h4>
<ul>
<li><b><code>name</code></b>: The key for the collection. For example, the <code>GraphKeys</code> class
  contains many standard names for collections.</li>
<li><b><code>scope</code></b>: (Optional.) A string. If supplied, the resulting list is filtered
  to include only items whose <code>name</code> attribute matches <code>scope</code> using
  <code>re.match</code>. Items without a <code>name</code> attribute are never returned if a
  scope is supplied. The choice of <code>re.match</code> means that a <code>scope</code> without
  special tokens filters by prefix.</li>
</ul>
<h4 id="returns_8">Returns:</h4>
<p>The list of values in the collection with the given <code>name</code>, or
an empty list if no value has been added to that collection. The
list contains the values in the order under which they were
collected.</p>
<h3 id="get_collection_ref"><code>get_collection_ref</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">get_collection_ref</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
</pre></div>


<p>Returns a list of values in the collection with the given <code>name</code>.</p>
<p>If the collection exists, this returns the list itself, which can
be modified in place to change the collection.  If the collection does
not exist, it is created as an empty list and the list is returned.</p>
<p>This is different from <code>get_collection()</code> which always returns a copy of
the collection list if it exists and never creates an empty collection.</p>
<h4 id="args_11">Args:</h4>
<ul>
<li><b><code>name</code></b>: The key for the collection. For example, the <code>GraphKeys</code> class
  contains many standard names for collections.</li>
</ul>
<h4 id="returns_9">Returns:</h4>
<p>The list of values in the collection with the given <code>name</code>, or an empty
list if no value has been added to that collection.</p>
<h3 id="get_name_scope"><code>get_name_scope</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">get_name_scope</span><span class="p">()</span>
</pre></div>


<p>Returns the current name scope.</p>
<h4 id="for-example_3">For example:</h4>
<div class="codehilite"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;scope1&#39;</span><span class="p">):</span>
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;scope2&#39;</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span><span class="o">.</span><span class="n">get_name_scope</span><span class="p">())</span>
</pre></div>


<p>would print the string <code>scope1/scope2</code>.</p>
<h4 id="returns_10">Returns:</h4>
<p>A string representing the current name scope.</p>
<h3 id="get_operation_by_name"><code>get_operation_by_name</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">get_operation_by_name</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
</pre></div>


<p>Returns the <code>Operation</code> with the given <code>name</code>.</p>
<p>This method may be called concurrently from multiple threads.</p>
<h4 id="args_12">Args:</h4>
<ul>
<li><b><code>name</code></b>: The name of the <code>Operation</code> to return.</li>
</ul>
<h4 id="returns_11">Returns:</h4>
<p>The <code>Operation</code> with the given <code>name</code>.</p>
<h4 id="raises_6">Raises:</h4>
<ul>
<li><b><code>TypeError</code></b>: If <code>name</code> is not a string.</li>
<li><b><code>KeyError</code></b>: If <code>name</code> does not correspond to an operation in this graph.</li>
</ul>
<h3 id="get_operations"><code>get_operations</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">get_operations</span><span class="p">()</span>
</pre></div>


<p>Return the list of operations in the graph.</p>
<p>You can modify the operations in place, but modifications
to the list such as inserts/delete have no effect on the
list of operations known to the graph.</p>
<p>This method may be called concurrently from multiple threads.</p>
<h4 id="returns_12">Returns:</h4>
<p>A list of Operations.</p>
<h3 id="get_tensor_by_name"><code>get_tensor_by_name</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
</pre></div>


<p>Returns the <code>Tensor</code> with the given <code>name</code>.</p>
<p>This method may be called concurrently from multiple threads.</p>
<h4 id="args_13">Args:</h4>
<ul>
<li><b><code>name</code></b>: The name of the <code>Tensor</code> to return.</li>
</ul>
<h4 id="returns_13">Returns:</h4>
<p>The <code>Tensor</code> with the given <code>name</code>.</p>
<h4 id="raises_7">Raises:</h4>
<ul>
<li><b><code>TypeError</code></b>: If <code>name</code> is not a string.</li>
<li><b><code>KeyError</code></b>: If <code>name</code> does not correspond to a tensor in this graph.</li>
</ul>
<h3 id="gradient_override_map"><code>gradient_override_map</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">gradient_override_map</span><span class="p">(</span><span class="n">op_type_map</span><span class="p">)</span>
</pre></div>


<p>EXPERIMENTAL: A context manager for overriding gradient functions.</p>
<p>This context manager can be used to override the gradient function
that will be used for ops within the scope of the context.</p>
<h4 id="for-example_4">For example:</h4>
<div class="codehilite"><pre><span></span><span class="nd">@tf</span><span class="o">.</span><span class="n">RegisterGradient</span><span class="p">(</span><span class="s2">&quot;CustomSquare&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">_custom_square_grad</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">grad</span><span class="p">):</span>
  <span class="c1"># ...</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">()</span> <span class="k">as</span> <span class="n">g</span><span class="p">:</span>
  <span class="n">c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">5.0</span><span class="p">)</span>
  <span class="n">s_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>  <span class="c1"># Uses the default gradient for tf.square.</span>
  <span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">gradient_override_map</span><span class="p">({</span><span class="s2">&quot;Square&quot;</span><span class="p">:</span> <span class="s2">&quot;CustomSquare&quot;</span><span class="p">}):</span>
    <span class="n">s_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">s_2</span><span class="p">)</span>  <span class="c1"># Uses _custom_square_grad to compute the</span>
                          <span class="c1"># gradient of s_2.</span>
</pre></div>


<h4 id="args_14">Args:</h4>
<ul>
<li><b><code>op_type_map</code></b>: A dictionary mapping op type strings to alternative op type
  strings.</li>
</ul>
<h4 id="returns_14">Returns:</h4>
<p>A context manager that sets the alternative op type to be used for one
or more ops created in that context.</p>
<h4 id="raises_8">Raises:</h4>
<ul>
<li><b><code>TypeError</code></b>: If <code>op_type_map</code> is not a dictionary mapping strings to
  strings.</li>
</ul>
<h3 id="is_feedable"><code>is_feedable</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">is_feedable</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
</pre></div>


<p>Returns <code>True</code> if and only if <code>tensor</code> is feedable.</p>
<h3 id="is_fetchable"><code>is_fetchable</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">is_fetchable</span><span class="p">(</span><span class="n">tensor_or_op</span><span class="p">)</span>
</pre></div>


<p>Returns <code>True</code> if and only if <code>tensor_or_op</code> is fetchable.</p>
<h3 id="name_scope"><code>name_scope</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
</pre></div>


<p>Returns a context manager that creates hierarchical names for operations.</p>
<p>A graph maintains a stack of name scopes. A <code>with name_scope(...):</code>
statement pushes a new name onto the stack for the lifetime of the context.</p>
<p>The <code>name</code> argument will be interpreted as follows:</p>
<ul>
<li>A string (not ending with '/') will create a new name scope, in which
  <code>name</code> is appended to the prefix of all operations created in the
  context. If <code>name</code> has been used before, it will be made unique by
  calling <code>self.unique_name(name)</code>.</li>
<li>A scope previously captured from a <code>with g.name_scope(...) as
  scope:</code> statement will be treated as an "absolute" name scope, which
  makes it possible to re-enter existing scopes.</li>
<li>A value of <code>None</code> or the empty string will reset the current name scope
  to the top-level (empty) name scope.</li>
</ul>
<h4 id="for-example_5">For example:</h4>
<div class="codehilite"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">()</span> <span class="k">as</span> <span class="n">g</span><span class="p">:</span>
  <span class="n">c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">5.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;c&quot;</span><span class="p">)</span>
  <span class="k">assert</span> <span class="n">c</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;c&quot;</span>
  <span class="n">c_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">6.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;c&quot;</span><span class="p">)</span>
  <span class="k">assert</span> <span class="n">c_1</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;c_1&quot;</span>

  <span class="c1"># Creates a scope called &quot;nested&quot;</span>
  <span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;nested&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>
    <span class="n">nested_c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;c&quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">nested_c</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;nested/c&quot;</span>

    <span class="c1"># Creates a nested scope called &quot;inner&quot;.</span>
    <span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;inner&quot;</span><span class="p">):</span>
      <span class="n">nested_inner_c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">20.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;c&quot;</span><span class="p">)</span>
      <span class="k">assert</span> <span class="n">nested_inner_c</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;nested/inner/c&quot;</span>

    <span class="c1"># Create a nested scope called &quot;inner_1&quot;.</span>
    <span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;inner&quot;</span><span class="p">):</span>
      <span class="n">nested_inner_1_c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">30.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;c&quot;</span><span class="p">)</span>
      <span class="k">assert</span> <span class="n">nested_inner_1_c</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;nested/inner_1/c&quot;</span>

      <span class="c1"># Treats `scope` as an absolute name scope, and</span>
      <span class="c1"># switches to the &quot;nested/&quot; scope.</span>
      <span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">scope</span><span class="p">):</span>
        <span class="n">nested_d</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">40.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">nested_d</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;nested/d&quot;</span>

        <span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
          <span class="n">e</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">50.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;e&quot;</span><span class="p">)</span>
          <span class="k">assert</span> <span class="n">e</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;e&quot;</span>
</pre></div>


<p>The name of the scope itself can be captured by <code>with
g.name_scope(...) as scope:</code>, which stores the name of the scope
in the variable <code>scope</code>. This value can be used to name an
operation that represents the overall result of executing the ops
in a scope. For example:</p>
<div class="codehilite"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;my_layer&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>
  <span class="n">weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span>
  <span class="n">biases</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;biases&quot;</span><span class="p">)</span>
  <span class="n">affine</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span> <span class="o">+</span> <span class="n">biases</span>
  <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">affine</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">scope</span><span class="p">)</span>
</pre></div>


<p>NOTE: This constructor validates the given <code>name</code>. Valid scope
names match one of the following regular expressions:</p>
<div class="codehilite"><pre><span></span><span class="err">[A-Za-z0-9.][A-Za-z0-9_.\-/]* (for scopes at the root)</span>
<span class="err">[A-Za-z0-9_.\-/]* (for other scopes)</span>
</pre></div>


<h4 id="args_15">Args:</h4>
<ul>
<li><b><code>name</code></b>: A name for the scope.</li>
</ul>
<h4 id="returns_15">Returns:</h4>
<p>A context manager that installs <code>name</code> as a new name scope.</p>
<h4 id="raises_9">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: If <code>name</code> is not a valid scope name, according to the rules
  above.</li>
</ul>
<h3 id="prevent_feeding"><code>prevent_feeding</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">prevent_feeding</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
</pre></div>


<p>Marks the given <code>tensor</code> as unfeedable in this graph.</p>
<h3 id="prevent_fetching"><code>prevent_fetching</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">prevent_fetching</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
</pre></div>


<p>Marks the given <code>op</code> as unfetchable in this graph.</p>
<h3 id="switch_to_thread_local"><code>switch_to_thread_local</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">switch_to_thread_local</span><span class="p">()</span>
</pre></div>


<p>Make device, colocation and dependencies stacks thread-local.</p>
<p>Device, colocation and dependencies stacks are not thread-local be default.
If multiple threads access them, then the state is shared.  This means that
one thread may affect the behavior of another thread.</p>
<p>After this method is called, the stacks become thread-local.  If multiple
threads access them, then the state is not shared.  Each thread uses its own
value; a thread doesn't affect other threads by mutating such a stack.</p>
<p>The initial value for every thread's stack is set to the current value
of the stack when <code>switch_to_thread_local()</code> was first called.</p>
<h3 id="unique_name"><code>unique_name</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/framework/ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">unique_name</span><span class="p">(</span>
    <span class="n">name</span><span class="p">,</span>
    <span class="n">mark_as_used</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>


<p>Return a unique operation name for <code>name</code>.</p>
<p>Note: You rarely need to call <code>unique_name()</code> directly.  Most of
the time you just need to create <code>with g.name_scope()</code> blocks to
generate structured names.</p>
<p><code>unique_name</code> is used to generate structured names, separated by
<code>"/"</code>, to help identify operations when debugging a graph.
Operation names are displayed in error messages reported by the
TensorFlow runtime, and in various visualization tools such as
TensorBoard.</p>
<p>If <code>mark_as_used</code> is set to <code>True</code>, which is the default, a new
unique name is created and marked as in use. If it's set to <code>False</code>,
the unique name is returned without actually being marked as used.
This is useful when the caller simply wants to know what the name
to be created will be.</p>
<h4 id="args_16">Args:</h4>
<ul>
<li><b><code>name</code></b>: The name for an operation.</li>
<li><b><code>mark_as_used</code></b>: Whether to mark this name as being used.</li>
</ul>
<h4 id="returns_16">Returns:</h4>
<p>A string to be passed to <code>create_op()</code> that will be used
to name the operation being created.</p>
    </body>
    </html>
   