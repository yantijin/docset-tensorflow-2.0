<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.RaggedTensor" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="dtype"/>
<meta itemprop="property" content="flat_values"/>
<meta itemprop="property" content="nested_row_splits"/>
<meta itemprop="property" content="ragged_rank"/>
<meta itemprop="property" content="row_splits"/>
<meta itemprop="property" content="shape"/>
<meta itemprop="property" content="values"/>
<meta itemprop="property" content="__abs__"/>
<meta itemprop="property" content="__add__"/>
<meta itemprop="property" content="__and__"/>
<meta itemprop="property" content="__bool__"/>
<meta itemprop="property" content="__div__"/>
<meta itemprop="property" content="__floordiv__"/>
<meta itemprop="property" content="__ge__"/>
<meta itemprop="property" content="__getitem__"/>
<meta itemprop="property" content="__gt__"/>
<meta itemprop="property" content="__init__"/>
<meta itemprop="property" content="__invert__"/>
<meta itemprop="property" content="__le__"/>
<meta itemprop="property" content="__lt__"/>
<meta itemprop="property" content="__mod__"/>
<meta itemprop="property" content="__mul__"/>
<meta itemprop="property" content="__neg__"/>
<meta itemprop="property" content="__nonzero__"/>
<meta itemprop="property" content="__or__"/>
<meta itemprop="property" content="__pow__"/>
<meta itemprop="property" content="__radd__"/>
<meta itemprop="property" content="__rand__"/>
<meta itemprop="property" content="__rdiv__"/>
<meta itemprop="property" content="__rfloordiv__"/>
<meta itemprop="property" content="__rmod__"/>
<meta itemprop="property" content="__rmul__"/>
<meta itemprop="property" content="__ror__"/>
<meta itemprop="property" content="__rpow__"/>
<meta itemprop="property" content="__rsub__"/>
<meta itemprop="property" content="__rtruediv__"/>
<meta itemprop="property" content="__rxor__"/>
<meta itemprop="property" content="__sub__"/>
<meta itemprop="property" content="__truediv__"/>
<meta itemprop="property" content="__xor__"/>
<meta itemprop="property" content="bounding_shape"/>
<meta itemprop="property" content="consumers"/>
<meta itemprop="property" content="from_nested_row_lengths"/>
<meta itemprop="property" content="from_nested_row_splits"/>
<meta itemprop="property" content="from_nested_value_rowids"/>
<meta itemprop="property" content="from_row_lengths"/>
<meta itemprop="property" content="from_row_limits"/>
<meta itemprop="property" content="from_row_splits"/>
<meta itemprop="property" content="from_row_starts"/>
<meta itemprop="property" content="from_sparse"/>
<meta itemprop="property" content="from_tensor"/>
<meta itemprop="property" content="from_value_rowids"/>
<meta itemprop="property" content="nested_row_lengths"/>
<meta itemprop="property" content="nested_value_rowids"/>
<meta itemprop="property" content="nrows"/>
<meta itemprop="property" content="row_lengths"/>
<meta itemprop="property" content="row_limits"/>
<meta itemprop="property" content="row_starts"/>
<meta itemprop="property" content="to_list"/>
<meta itemprop="property" content="to_sparse"/>
<meta itemprop="property" content="to_tensor"/>
<meta itemprop="property" content="value_rowids"/>
<meta itemprop="property" content="with_flat_values"/>
<meta itemprop="property" content="with_row_splits_dtype"/>
<meta itemprop="property" content="with_values"/>
</div>


<h1>tf.RaggedTensor</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<h2>Class <code>RaggedTensor</code></h2>

<!-- Start diff -->


<p>Represents a ragged tensor.</p>

<h3>Aliases:</h3>

<ul>
<li>Class <code>tf.compat.v1.RaggedTensor</code></li>
<li>Class <code>tf.compat.v2.RaggedTensor</code></li>
</ul>


<!-- Placeholder for "Used in" -->


<p>A <code>RaggedTensor</code> is a tensor with one or more <em>ragged dimensions</em>, which are
dimensions whose slices may have different lengths.  For example, the inner
(column) dimension of <code>rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []]</code> is ragged,
since the column slices (<code>rt[0, :]</code>, &hellip;, <code>rt[4, :]</code>) have different lengths.
Dimensions whose slices all have the same length are called <em>uniform
dimensions</em>.  The outermost dimension of a <code>RaggedTensor</code> is always uniform,
since it consists of a single slice (and so there is no possibility for
differing slice lengths).</p>

<p>The total number of dimensions in a <code>RaggedTensor</code> is called its <em>rank</em>,
and the number of ragged dimensions in a <code>RaggedTensor</code> is called its
<em>ragged-rank</em>.  A <code>RaggedTensor</code>&rsquo;s ragged-rank is fixed at graph creation
time: it can&rsquo;t depend on the runtime values of <code>Tensor</code>s, and can&rsquo;t vary
dynamically for different session runs.</p>

<p> ```</p>

<h3>Potentially Ragged Tensors</h3>

<p>Many ops support both <code>Tensor</code>s and <code>RaggedTensor</code>s.  The term &ldquo;potentially
ragged tensor&rdquo; may be used to refer to a tensor that might be either a
<code>Tensor</code> or a <code>RaggedTensor</code>.  The ragged-rank of a <code>Tensor</code> is zero.</p>

<h3>Documenting RaggedTensor Shapes</h3>

<p>When documenting the shape of a RaggedTensor, ragged dimensions can be
indicated by enclosing them in parentheses.  For example, the shape of
a 3-D <code>RaggedTensor</code> that stores the fixed-size word embedding for each
word in a sentence, for each sentence in a batch, could be written as
<code>[num_sentences, (num_words), embedding_size]</code>.  The parentheses around
<code>(num_words)</code> indicate that dimension is ragged, and that the length
of each element list in that dimension may vary for each item.</p>

<h3>Component Tensors</h3>

<p>Internally, a <code>RaggedTensor</code> consists of a concatenated list of values that
are partitioned into variable-length rows.  In particular, each <code>RaggedTensor</code>
consists of:</p>

<ul>
<li><p>A <code>values</code> tensor, which concatenates the variable-length rows into a
flattened list.  For example, the <code>values</code> tensor for
<code>[[3, 1, 4, 1], [], [5, 9, 2], [6], []]</code> is <code>[3, 1, 4, 1, 5, 9, 2, 6]</code>.</p></li>
<li><p>A <code>row_splits</code> vector, which indicates how those flattened values are
divided into rows.  In particular, the values for row <code>rt[i]</code> are stored
in the slice <code>rt.values[rt.row_splits[i]:rt.row_splits[i+1]]</code>.</p></li>
</ul>


<h4>Example:</h4>

<p>```python</p>

<blockquote><blockquote><blockquote><p>print(tf.RaggedTensor.from_row_splits(
&hellip;     values=[3, 1, 4, 1, 5, 9, 2, 6],
&hellip;     row_splits=[0, 4, 4, 7, 8, 8]))
&lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>
```</p></blockquote></blockquote></blockquote>

<h3>Alternative Row-Partitioning Schemes</h3>

<p>In addition to <code>row_splits</code>, ragged tensors provide support for four other
row-partitioning schemes:</p>

<ul>
<li><p><code>row_lengths</code>: a vector with shape <code>[nrows]</code>, which specifies the length
of each row.</p></li>
<li><p><code>value_rowids</code> and <code>nrows</code>: <code>value_rowids</code> is a vector with shape
<code>[nvals]</code>, corresponding one-to-one with <code>values</code>, which specifies
each value&rsquo;s row index.  In particular, the row <code>rt[row]</code> consists of the
values <code>rt.values[j]</code> where <code>value_rowids[j]==row</code>.  <code>nrows</code> is an
integer scalar that specifies the number of rows in the
<code>RaggedTensor</code>. (<code>nrows</code> is used to indicate trailing empty rows.)</p></li>
<li><p><code>row_starts</code>: a vector with shape <code>[nrows]</code>, which specifies the start
offset of each row.  Equivalent to <code>row_splits[:-1]</code>.</p></li>
<li><p><code>row_limits</code>: a vector with shape <code>[nrows]</code>, which specifies the stop
offset of each row.  Equivalent to <code>row_splits[1:]</code>.</p></li>
</ul>


<p>Example: The following ragged tensors are equivalent, and all represent the
nested list <code>[[3, 1, 4, 1], [], [5, 9, 2], [6], []]</code>.</p>

<p>```python</p>

<blockquote><blockquote><blockquote><p>values = [3, 1, 4, 1, 5, 9, 2, 6]
rt1 = RaggedTensor.from_row_splits(values, row_splits=[0, 4, 4, 7, 8, 8])
rt2 = RaggedTensor.from_row_lengths(values, row_lengths=[4, 0, 3, 1, 0])
rt3 = RaggedTensor.from_value_rowids(
&hellip;     values, value_rowids=[0, 0, 0, 0, 2, 2, 2, 3], nrows=5)
rt4 = RaggedTensor.from_row_starts(values, row_starts=[0, 4, 4, 7, 8])
rt5 = RaggedTensor.from_row_limits(values, row_limits=[4, 4, 7, 8, 8])
```</p></blockquote></blockquote></blockquote>

<h3>Multiple Ragged Dimensions</h3>

<p><code>RaggedTensor</code>s with multiple ragged dimensions can be defined by using
a nested <code>RaggedTensor</code> for the <code>values</code> tensor.  Each nested <code>RaggedTensor</code>
adds a single ragged dimension.</p>

<p>```python</p>

<blockquote><blockquote><blockquote><p>inner_rt = RaggedTensor.from_row_splits(  # =rt1 from above
&hellip;     values=[3, 1, 4, 1, 5, 9, 2, 6], row_splits=[0, 4, 4, 7, 8, 8])
outer_rt = RaggedTensor.from_row_splits(
&hellip;     values=inner_rt, row_splits=[0, 3, 3, 5])
print outer_rt.to_list()
[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]
print outer_rt.ragged_rank
2
```</p></blockquote></blockquote></blockquote>

<p>The factory function <code>RaggedTensor.from_nested_row_splits</code> may be used to
construct a <code>RaggedTensor</code> with multiple ragged dimensions directly, by
providing a list of <code>row_splits</code> tensors:</p>

<p>```python</p>

<blockquote><blockquote><blockquote><p>RaggedTensor.from_nested_row_splits(
&hellip;     flat_values=[3, 1, 4, 1, 5, 9, 2, 6],
&hellip;     nested_row_splits=([0, 3, 3, 5], [0, 4, 4, 7, 8, 8])).to_list()
[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]
```</p></blockquote></blockquote></blockquote>

<h3>Uniform Inner Dimensions</h3>

<p><code>RaggedTensor</code>s with uniform inner dimensions can be defined
by using a multidimensional <code>Tensor</code> for <code>values</code>.</p>

<p>```python</p>

<blockquote><blockquote><blockquote><p>rt = RaggedTensor.from_row_splits(values=tf.ones([5, 3]),
..                                    row_splits=[0, 2, 5])
print rt.to_list()
[[[1, 1, 1], [1, 1, 1]],
 [[1, 1, 1], [1, 1, 1], [1, 1, 1]]]
print rt.shape
 (2, ?, 3)
<code>
</code></p></blockquote></blockquote></blockquote>

<h3>RaggedTensor Shape Restrictions</h3>

<p>The shape of a RaggedTensor is currently restricted to have the following
form:</p>

<ul>
<li>A single uniform dimension</li>
<li>Followed by one or more ragged dimensions</li>
<li>Followed by zero or more uniform dimensions.</li>
</ul>


<p>This restriction follows from the fact that each nested <code>RaggedTensor</code>
replaces the uniform outermost dimension of its <code>values</code> with a uniform
dimension followed by a ragged dimension.</p>

<h2 id="__init__"><code>__init__</code></h2>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
__init__(
    values,
    row_splits,
    cached_row_lengths=None,
    cached_value_rowids=None,
    cached_nrows=None,
    internal=False
)
</code></p>

<p>Creates a <code>RaggedTensor</code> with a specified partitioning for <code>values</code>.</p>

<p>This constructor is private &ndash; please use one of the following ops to
build <code>RaggedTensor</code>s:</p>

<ul>
<li><a href="../tf/RaggedTensor.html#from_row_lengths"><code>tf.RaggedTensor.from_row_lengths</code></a></li>
<li><a href="../tf/RaggedTensor.html#from_value_rowids"><code>tf.RaggedTensor.from_value_rowids</code></a></li>
<li><a href="../tf/RaggedTensor.html#from_row_splits"><code>tf.RaggedTensor.from_row_splits</code></a></li>
<li><a href="../tf/RaggedTensor.html#from_row_starts"><code>tf.RaggedTensor.from_row_starts</code></a></li>
<li><a href="../tf/RaggedTensor.html#from_row_limits"><code>tf.RaggedTensor.from_row_limits</code></a></li>
<li><a href="../tf/RaggedTensor.html#from_nested_row_splits"><code>tf.RaggedTensor.from_nested_row_splits</code></a></li>
<li><a href="../tf/RaggedTensor.html#from_nested_row_lengths"><code>tf.RaggedTensor.from_nested_row_lengths</code></a></li>
<li><a href="../tf/RaggedTensor.html#from_nested_value_rowids"><code>tf.RaggedTensor.from_nested_value_rowids</code></a></li>
</ul>


<h4>Args:</h4>

<ul>
<li><b><code>values</code></b>: A potentially ragged tensor of any dtype and shape <code>[nvals, ...]</code>.</li>
<li><b><code>row_splits</code></b>: A 1-D integer tensor with shape <code>[nrows+1]</code>.</li>
<li><b><code>cached_row_lengths</code></b>: A 1-D integer tensor with shape <code>[nrows]</code></li>
<li><b><code>cached_value_rowids</code></b>: A 1-D integer tensor with shape <code>[nvals]</code>.</li>
<li><b><code>cached_nrows</code></b>: A 1-D integer scalar tensor.</li>
<li><b><code>internal</code></b>: True if the constructor is being called by one of the factory
methods.  If false, an exception will be raised.</li>
</ul>


<h4>Raises:</h4>

<ul>
<li><b><code>TypeError</code></b>: If a row partitioning tensor has an inappropriate dtype.</li>
<li><b><code>TypeError</code></b>: If exactly one row partitioning argument was not specified.</li>
<li><b><code>ValueError</code></b>: If a row partitioning tensor has an inappropriate shape.</li>
<li><b><code>ValueError</code></b>: If multiple partitioning arguments are specified.</li>
<li><b><code>ValueError</code></b>: If nrows is specified but value_rowids is not None.</li>
</ul>


<h2>Properties</h2>

<h3 id="dtype"><code>dtype</code></h3>


<p>The <code>DType</code> of values in this tensor.</p>

<h3 id="flat_values"><code>flat_values</code></h3>


<p>The innermost <code>values</code> tensor for this ragged tensor.</p>

<p>Concretely, if <code>rt.values</code> is a <code>Tensor</code>, then <code>rt.flat_values</code> is
<code>rt.values</code>; otherwise, <code>rt.flat_values</code> is <code>rt.values.flat_values</code>.</p>

<p>Conceptually, <code>flat_values</code> is the tensor formed by flattening the
outermost dimension and all of the ragged dimensions into a single
dimension.</p>

<p><code>rt.flat_values.shape = [nvals] + rt.shape[rt.ragged_rank + 1:]</code>
(where <code>nvals</code> is the number of items in the flattened dimensions).</p>

<h4>Returns:</h4>

<p>A <code>Tensor</code>.</p>

<h4>Example:</h4>

<p>  ```python</p>

<blockquote><blockquote><blockquote><p>rt = ragged.constant([[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]])
print rt.flat_values()
  tf.Tensor([3, 1, 4, 1, 5, 9, 2, 6])
  ```</p></blockquote></blockquote></blockquote>

<h3 id="nested_row_splits"><code>nested_row_splits</code></h3>


<p>A tuple containing the row_splits for all ragged dimensions.</p>

<p><code>rt.nested_row_splits</code> is a tuple containing the <code>row_splits</code> tensors for
all ragged dimensions in <code>rt</code>, ordered from outermost to innermost.  In
particular, <code>rt.nested_row_splits = (rt.row_splits,) + value_splits</code> where:</p>

<pre><code>* `value_splits = ()` if `rt.values` is a `Tensor`.
* `value_splits = rt.values.nested_row_splits` otherwise.
</code></pre>

<h4>Returns:</h4>

<p>A <code>tuple</code> of 1-D integer <code>Tensor</code>s.</p>

<h4>Example:</h4>

<p>  ```python</p>

<blockquote><blockquote><blockquote><p>rt = ragged.constant([[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]])
for i, splits in enumerate(rt.nested_row_splits()):
  &hellip;   print(&lsquo;Splits for dimension %d: %s&rsquo; % (i+1, splits))
  Splits for dimension 1: [0, 1]
  Splits for dimension 2: [0, 3, 3, 5]
  Splits for dimension 3: [0, 4, 4, 7, 8, 8]
  ```</p></blockquote></blockquote></blockquote>

<h3 id="ragged_rank"><code>ragged_rank</code></h3>


<p>The number of ragged dimensions in this ragged tensor.</p>

<h4>Returns:</h4>

<p>A Python <code>int</code> indicating the number of ragged dimensions in this ragged
tensor.  The outermost dimension is not considered ragged.</p>

<h3 id="row_splits"><code>row_splits</code></h3>


<p>The row-split indices for this ragged tensor&rsquo;s <code>values</code>.</p>

<p><code>rt.row_splits</code> specifies where the values for each row begin and end in
<code>rt.values</code>.  In particular, the values for row <code>rt[i]</code> are stored in
the slice <code>rt.values[rt.row_splits[i]:rt.row_splits[i+1]]</code>.</p>

<h4>Returns:</h4>

<p>A 1-D integer <code>Tensor</code> with shape <code>[self.nrows+1]</code>.
The returned tensor is non-empty, and is sorted in ascending order.
<code>self.row_splits[0]</code> is zero, and <code>self.row_splits[-1]</code> is equal to
<code>self.values.shape[0]</code>.</p>

<h4>Example:</h4>

<p>  ```python</p>

<blockquote><blockquote><blockquote><p>rt = ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])
print rt.row_splits  # indices of row splits in rt.values
  tf.Tensor([0, 4, 4, 7, 8, 8])
  ```</p></blockquote></blockquote></blockquote>

<h3 id="shape"><code>shape</code></h3>


<p>The statically known shape of this ragged tensor.</p>

<h4>Returns:</h4>

<p>A <code>TensorShape</code> containing the statically known shape of this ragged
tensor.  Ragged dimensions have a size of <code>None</code>.</p>

<h4>Examples:</h4>

<p>```python</p>

<blockquote><blockquote><blockquote><p>ragged.constant([[0], [1, 2]]).shape
TensorShape([Dimension(2), Dimension(None)])</p>

<p>ragged.constant([[[0, 1]], [[1, 2], [3, 4]]], ragged_rank=1).shape
TensorShape([Dimension(2), Dimension(None), Dimension(2)
```</p></blockquote></blockquote></blockquote>

<h3 id="values"><code>values</code></h3>


<p>The concatenated rows for this ragged tensor.</p>

<p><code>rt.values</code> is a potentially ragged tensor formed by flattening the two
outermost dimensions of <code>rt</code> into a single dimension.</p>

<p><code>rt.values.shape = [nvals] + rt.shape[2:]</code> (where <code>nvals</code> is the
number of items in the outer two dimensions of <code>rt</code>).</p>

<p><code>rt.ragged_rank = self.ragged_rank - 1</code></p>

<h4>Returns:</h4>

<p>A potentially ragged tensor.</p>

<h4>Example:</h4>

<p>  ```python</p>

<blockquote><blockquote><blockquote><p>rt = ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])
print rt.values
  tf.Tensor([3, 1, 4, 1, 5, 9, 2, 6])
  ```</p></blockquote></blockquote></blockquote>

<h2>Methods</h2>

<h3 id="__abs__"><code>__abs__</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/math_ops.py">View source</a></p>

<p><code>python
__abs__(
    x,
    name=None
)
</code></p>

<p>Computes the absolute value of a tensor.</p>

<p>Given a tensor of integer or floating-point values, this operation returns a
tensor of the same type, where each element contains the absolute value of the
corresponding element in the input.</p>

<p>Given a tensor <code>x</code> of complex numbers, this operation returns a tensor of type
<code>float32</code> or <code>float64</code> that is the absolute value of each element in <code>x</code>. All
elements in <code>x</code> must be complex numbers of the form \(a + bj\). The
absolute value is computed as \( \sqrt{a<sup>2</sup> + b<sup>2</sup>}\).  For example:
<code>python
x = tf.constant([[-2.25 + 4.75j], [-3.25 + 5.75j]])
tf.abs(x)  # [5.25594902, 6.60492229]
</code></p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code> or <code>SparseTensor</code> of type <code>float16</code>, <code>float32</code>, <code>float64</code>,
<code>int32</code>, <code>int64</code>, <code>complex64</code> or <code>complex128</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code> or <code>SparseTensor</code> the same size, type, and sparsity as <code>x</code> with
  absolute values.
Note, for <code>complex64</code> or <code>complex128</code> input, the returned <code>Tensor</code> will be
  of type <code>float32</code> or <code>float64</code>, respectively.</p>

<p>If <code>x</code> is a <code>SparseTensor</code>, returns
<code>SparseTensor(x.indices, tf.math.abs(x.values, ...), x.dense_shape)</code></p>

<h3 id="__add__"><code>__add__</code></h3>


<p>Defined in generated file: <code>python/ops/gen_math_ops.py</code></p>

<p><code>python
__add__(
    x,
    y,
    name=None
)
</code></p>

<p>Returns x + y element-wise.</p>

<p><em>NOTE</em>: <a href="../tf/math/add.html"><code>math.add</code></a> supports broadcasting. <code>AddN</code> does not. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code>. Must be one of the following types: <code>bfloat16</code>, <code>half</code>, <code>float32</code>, <code>float64</code>, <code>uint8</code>, <code>int8</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>, <code>string</code>.</li>
<li><b><code>y</code></b>: A <code>Tensor</code>. Must have the same type as <code>x</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code>. Has the same type as <code>x</code>.</p>

<h3 id="__and__"><code>__and__</code></h3>


<p>Defined in generated file: <code>python/ops/gen_math_ops.py</code></p>

<p><code>python
__and__(
    x,
    y,
    name=None
)
</code></p>

<p>Returns the truth value of x AND y element-wise.</p>

<p><em>NOTE</em>: <a href="../tf/math/logical_and.html"><code>math.logical_and</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code> of type <code>bool</code>.</li>
<li><b><code>y</code></b>: A <code>Tensor</code> of type <code>bool</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code> of type <code>bool</code>.</p>

<h3 id="__bool__"><code>__bool__</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_operators.py">View source</a></p>

<p><code>python
__bool__(_)
</code></p>

<p>Dummy method to prevent a RaggedTensor from being used as a Python bool.</p>

<h3 id="__div__"><code>__div__</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/math_ops.py">View source</a></p>

<p><code>python
__div__(
    x,
    y,
    name=None
)
</code></p>

<p>Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)</p>

<p>Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.</p>

<p>NOTE: Prefer using the Tensor division operator or tf.divide which obey Python
3 division operator semantics.</p>

<p>This function divides <code>x</code> and <code>y</code>, forcing Python 2 semantics. That is, if <code>x</code>
and <code>y</code> are both integers then the result will be an integer. This is in
contrast to Python 3, where division with <code>/</code> is always a float while division
with <code>//</code> is always an integer.</p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: <code>Tensor</code> numerator of real numeric type.</li>
<li><b><code>y</code></b>: <code>Tensor</code> denominator of real numeric type.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p><code>x / y</code> returns the quotient of x and y.</p>

<h3 id="__floordiv__"><code>__floordiv__</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/math_ops.py">View source</a></p>

<p><code>python
__floordiv__(
    x,
    y,
    name=None
)
</code></p>

<p>Divides <code>x / y</code> elementwise, rounding toward the most negative integer.</p>

<p>The same as <a href="../tf/RaggedTensor.html#__div__"><code>tf.compat.v1.div(x,y)</code></a> for integers, but uses
<code>tf.floor(tf.compat.v1.div(x,y))</code> for
floating point arguments so that the result is always an integer (though
possibly an integer represented as floating point).  This op is generated by
<code>x // y</code> floor division in Python 3 and in Python 2.7 with
<code>from __future__ import division</code>.</p>

<p><code>x</code> and <code>y</code> must have the same type, and the result will have the same type
as well.</p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: <code>Tensor</code> numerator of real numeric type.</li>
<li><b><code>y</code></b>: <code>Tensor</code> denominator of real numeric type.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p><code>x / y</code> rounded down.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>TypeError</code></b>: If the inputs are complex.</li>
</ul>


<h3 id="__ge__"><code>__ge__</code></h3>


<p>Defined in generated file: <code>python/ops/gen_math_ops.py</code></p>

<p><code>python
__ge__(
    x,
    y,
    name=None
)
</code></p>

<p>Returns the truth value of (x >= y) element-wise.</p>

<p><em>NOTE</em>: <a href="../tf/math/greater_equal.html"><code>math.greater_equal</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>int64</code>, <code>bfloat16</code>, <code>uint16</code>, <code>half</code>, <code>uint32</code>, <code>uint64</code>.</li>
<li><b><code>y</code></b>: A <code>Tensor</code>. Must have the same type as <code>x</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code> of type <code>bool</code>.</p>

<h3 id="__getitem__"><code>__getitem__</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_getitem.py">View source</a></p>

<p><code>python
__getitem__(key)
</code></p>

<p>Returns the specified piece of this RaggedTensor.</p>

<p>Supports multidimensional indexing and slicing, with one restriction:
indexing into a ragged inner dimension is not allowed.  This case is
problematic because the indicated value may exist in some rows but not
others.  In such cases, it&rsquo;s not obvious whether we should (1) report an
IndexError; (2) use a default value; or (3) skip that value and return a
tensor with fewer rows than we started with.  Following the guiding
principles of Python (&ldquo;In the face of ambiguity, refuse the temptation to
guess&rdquo;), we simply disallow this operation.</p>

<p>Any dimensions added by <code>array_ops.newaxis</code> will be ragged if the following
dimension is ragged.</p>

<h4>Args:</h4>

<ul>
<li><b><code>self</code></b>: The RaggedTensor to slice.</li>
<li><p><b><code>key</code></b>: Indicates which piece of the RaggedTensor to return, using standard
Python semantics (e.g., negative values index from the end).  <code>key</code>
may have any of the following types:</p>

<ul>
<li><code>int</code> constant</li>
<li>Scalar integer <code>Tensor</code></li>
<li><code>slice</code> containing integer constants and/or scalar integer
<code>Tensor</code>s</li>
<li><code>Ellipsis</code></li>
<li><code>tf.newaxis</code></li>
<li><code>tuple</code> containing any of the above (for multidimentional indexing)</li>
</ul>
</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code> or <code>RaggedTensor</code> object.  Values that include at least one
ragged dimension are returned as <code>RaggedTensor</code>.  Values that include no
ragged dimensions are returned as <code>Tensor</code>.  See above for examples of
expressions that return <code>Tensor</code>s vs <code>RaggedTensor</code>s.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: If <code>key</code> is out of bounds.</li>
<li><b><code>ValueError</code></b>: If <code>key</code> is not supported.</li>
<li><b><code>TypeError</code></b>: If the indices in <code>key</code> have an unsupported type.</li>
</ul>


<h4>Examples:</h4>

<p>```python</p>

<blockquote><blockquote><blockquote><h1>A 2-D ragged tensor with 1 ragged dimension.</h1>

<p>rt = ragged.constant([[&lsquo;a&rsquo;, &lsquo;b&rsquo;, &lsquo;c&rsquo;], [&rsquo;d', &lsquo;e&rsquo;], [&lsquo;f&rsquo;], [&lsquo;g&rsquo;]])
rt[0].eval().tolist()       # First row (1-D <code>Tensor</code>)
[&lsquo;a&rsquo;, &lsquo;b&rsquo;, &lsquo;c&rsquo;]
rt[:3].eval().tolist()      # First three rows (2-D RaggedTensor)
[[&lsquo;a&rsquo;, &lsquo;b&rsquo;, &lsquo;c&rsquo;], [&rsquo;d', &lsquo;e&rsquo;], &lsquo;[f&rsquo;], [g']]
rt[3, 0].eval().tolist()    # 1st element of 4th row (scalar)
&lsquo;g&rsquo;</p>

<h1>A 3-D ragged tensor with 2 ragged dimensions.</h1>

<p>rt = ragged.constant([[[1, 2, 3], [4]],
&hellip;                    [[5], [], [6]],
&hellip;                    [[7]],
&hellip;                    [[8, 9], [10]]])
rt[1].eval().tolist()       # Second row (2-D RaggedTensor)
[[5], [], [6]]
rt[3, 0].eval().tolist()    # First element of fourth row (1-D Tensor)
[8, 9]
rt[:, 1:3].eval().tolist()  # Items 1-3 of each row (3-D RaggedTensor)
[[[4]], [[], [6]], [], [[10]]]
rt[:, -1:].eval().tolist()  # Last item of each row (3-D RaggedTensor)
[[[4]], [[6]], [[7]], [[10]]]
```</p></blockquote></blockquote></blockquote>

<h3 id="__gt__"><code>__gt__</code></h3>


<p>Defined in generated file: <code>python/ops/gen_math_ops.py</code></p>

<p><code>python
__gt__(
    x,
    y,
    name=None
)
</code></p>

<p>Returns the truth value of (x > y) element-wise.</p>

<p><em>NOTE</em>: <a href="../tf/math/greater.html"><code>math.greater</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>int64</code>, <code>bfloat16</code>, <code>uint16</code>, <code>half</code>, <code>uint32</code>, <code>uint64</code>.</li>
<li><b><code>y</code></b>: A <code>Tensor</code>. Must have the same type as <code>x</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code> of type <code>bool</code>.</p>

<h3 id="__invert__"><code>__invert__</code></h3>


<p>Defined in generated file: <code>python/ops/gen_math_ops.py</code></p>

<p><code>python
__invert__(
    x,
    name=None
)
</code></p>

<p>Returns the truth value of NOT x element-wise.</p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code> of type <code>bool</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code> of type <code>bool</code>.</p>

<h3 id="__le__"><code>__le__</code></h3>


<p>Defined in generated file: <code>python/ops/gen_math_ops.py</code></p>

<p><code>python
__le__(
    x,
    y,
    name=None
)
</code></p>

<p>Returns the truth value of (x &lt;= y) element-wise.</p>

<p><em>NOTE</em>: <a href="../tf/math/less_equal.html"><code>math.less_equal</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>int64</code>, <code>bfloat16</code>, <code>uint16</code>, <code>half</code>, <code>uint32</code>, <code>uint64</code>.</li>
<li><b><code>y</code></b>: A <code>Tensor</code>. Must have the same type as <code>x</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code> of type <code>bool</code>.</p>

<h3 id="__lt__"><code>__lt__</code></h3>


<p>Defined in generated file: <code>python/ops/gen_math_ops.py</code></p>

<p><code>python
__lt__(
    x,
    y,
    name=None
)
</code></p>

<p>Returns the truth value of (x &lt; y) element-wise.</p>

<p><em>NOTE</em>: <a href="../tf/math/less.html"><code>math.less</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>int64</code>, <code>bfloat16</code>, <code>uint16</code>, <code>half</code>, <code>uint32</code>, <code>uint64</code>.</li>
<li><b><code>y</code></b>: A <code>Tensor</code>. Must have the same type as <code>x</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code> of type <code>bool</code>.</p>

<h3 id="__mod__"><code>__mod__</code></h3>


<p>Defined in generated file: <code>python/ops/gen_math_ops.py</code></p>

<p><code>python
__mod__(
    x,
    y,
    name=None
)
</code></p>

<p>Returns element-wise remainder of division. When <code>x &lt; 0</code> xor <code>y &lt; 0</code> is</p>

<p>true, this follows Python semantics in that the result here is consistent
with a flooring divide. E.g. <code>floor(x / y) * y + mod(x, y) = x</code>.</p>

<p><em>NOTE</em>: <a href="../tf/math/floormod.html"><code>math.floormod</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>, <code>bfloat16</code>, <code>half</code>, <code>float32</code>, <code>float64</code>.</li>
<li><b><code>y</code></b>: A <code>Tensor</code>. Must have the same type as <code>x</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code>. Has the same type as <code>x</code>.</p>

<h3 id="__mul__"><code>__mul__</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/math_ops.py">View source</a></p>

<p><code>python
__mul__(
    x,
    y,
    name=None
)
</code></p>

<p>Returns x * y element-wise.</p>

<p><em>NOTE</em>: <a href="../tf/math/multiply.html"><code>tf.multiply</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code>. Must be one of the following types: <code>bfloat16</code>, <code>half</code>, <code>float32</code>, <code>float64</code>, <code>uint8</code>, <code>int8</code>, <code>uint16</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.</li>
<li><b><code>y</code></b>: A <code>Tensor</code>. Must have the same type as <code>x</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code>. Has the same type as <code>x</code>.</p>

<h3 id="__neg__"><code>__neg__</code></h3>


<p>Defined in generated file: <code>python/ops/gen_math_ops.py</code></p>

<p><code>python
__neg__(
    x,
    name=None
)
</code></p>

<p>Computes numerical negative value element-wise.</p>

<p>I.e., \(y = -x\).</p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code>. Must be one of the following types: <code>bfloat16</code>, <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code>. Has the same type as <code>x</code>.</p>

<p>If <code>x</code> is a <code>SparseTensor</code>, returns
<code>SparseTensor(x.indices, tf.math.negative(x.values, ...), x.dense_shape)</code></p>

<h3 id="__nonzero__"><code>__nonzero__</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_operators.py">View source</a></p>

<p><code>python
__nonzero__(_)
</code></p>

<p>Dummy method to prevent a RaggedTensor from being used as a Python bool.</p>

<h3 id="__or__"><code>__or__</code></h3>


<p>Defined in generated file: <code>python/ops/gen_math_ops.py</code></p>

<p><code>python
__or__(
    x,
    y,
    name=None
)
</code></p>

<p>Returns the truth value of x OR y element-wise.</p>

<p><em>NOTE</em>: <a href="../tf/math/logical_or.html"><code>math.logical_or</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code> of type <code>bool</code>.</li>
<li><b><code>y</code></b>: A <code>Tensor</code> of type <code>bool</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code> of type <code>bool</code>.</p>

<h3 id="__pow__"><code>__pow__</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/math_ops.py">View source</a></p>

<p><code>python
__pow__(
    x,
    y,
    name=None
)
</code></p>

<p>Computes the power of one value to another.</p>

<p>Given a tensor <code>x</code> and a tensor <code>y</code>, this operation computes \(x<sup>y</sup>\) for
corresponding elements in <code>x</code> and <code>y</code>. For example:</p>

<p><code>python
x = tf.constant([[2, 2], [3, 3]])
y = tf.constant([[8, 16], [2, 3]])
tf.pow(x, y)  # [[256, 65536], [9, 27]]
</code></p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code> of type <code>float16</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>,
<code>complex64</code>, or <code>complex128</code>.</li>
<li><b><code>y</code></b>: A <code>Tensor</code> of type <code>float16</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>,
<code>complex64</code>, or <code>complex128</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code>.</p>

<h3 id="__radd__"><code>__radd__</code></h3>


<p>Defined in generated file: <code>python/ops/gen_math_ops.py</code></p>

<p><code>python
__radd__(
    x,
    y,
    name=None
)
</code></p>

<p>Returns x + y element-wise.</p>

<p><em>NOTE</em>: <a href="../tf/math/add.html"><code>math.add</code></a> supports broadcasting. <code>AddN</code> does not. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code>. Must be one of the following types: <code>bfloat16</code>, <code>half</code>, <code>float32</code>, <code>float64</code>, <code>uint8</code>, <code>int8</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>, <code>string</code>.</li>
<li><b><code>y</code></b>: A <code>Tensor</code>. Must have the same type as <code>x</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code>. Has the same type as <code>x</code>.</p>

<h3 id="__rand__"><code>__rand__</code></h3>


<p>Defined in generated file: <code>python/ops/gen_math_ops.py</code></p>

<p><code>python
__rand__(
    x,
    y,
    name=None
)
</code></p>

<p>Returns the truth value of x AND y element-wise.</p>

<p><em>NOTE</em>: <a href="../tf/math/logical_and.html"><code>math.logical_and</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code> of type <code>bool</code>.</li>
<li><b><code>y</code></b>: A <code>Tensor</code> of type <code>bool</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code> of type <code>bool</code>.</p>

<h3 id="__rdiv__"><code>__rdiv__</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/math_ops.py">View source</a></p>

<p><code>python
__rdiv__(
    x,
    y,
    name=None
)
</code></p>

<p>Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)</p>

<p>Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.</p>

<p>NOTE: Prefer using the Tensor division operator or tf.divide which obey Python
3 division operator semantics.</p>

<p>This function divides <code>x</code> and <code>y</code>, forcing Python 2 semantics. That is, if <code>x</code>
and <code>y</code> are both integers then the result will be an integer. This is in
contrast to Python 3, where division with <code>/</code> is always a float while division
with <code>//</code> is always an integer.</p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: <code>Tensor</code> numerator of real numeric type.</li>
<li><b><code>y</code></b>: <code>Tensor</code> denominator of real numeric type.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p><code>x / y</code> returns the quotient of x and y.</p>

<h3 id="__rfloordiv__"><code>__rfloordiv__</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/math_ops.py">View source</a></p>

<p><code>python
__rfloordiv__(
    x,
    y,
    name=None
)
</code></p>

<p>Divides <code>x / y</code> elementwise, rounding toward the most negative integer.</p>

<p>The same as <a href="../tf/RaggedTensor.html#__div__"><code>tf.compat.v1.div(x,y)</code></a> for integers, but uses
<code>tf.floor(tf.compat.v1.div(x,y))</code> for
floating point arguments so that the result is always an integer (though
possibly an integer represented as floating point).  This op is generated by
<code>x // y</code> floor division in Python 3 and in Python 2.7 with
<code>from __future__ import division</code>.</p>

<p><code>x</code> and <code>y</code> must have the same type, and the result will have the same type
as well.</p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: <code>Tensor</code> numerator of real numeric type.</li>
<li><b><code>y</code></b>: <code>Tensor</code> denominator of real numeric type.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p><code>x / y</code> rounded down.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>TypeError</code></b>: If the inputs are complex.</li>
</ul>


<h3 id="__rmod__"><code>__rmod__</code></h3>


<p>Defined in generated file: <code>python/ops/gen_math_ops.py</code></p>

<p><code>python
__rmod__(
    x,
    y,
    name=None
)
</code></p>

<p>Returns element-wise remainder of division. When <code>x &lt; 0</code> xor <code>y &lt; 0</code> is</p>

<p>true, this follows Python semantics in that the result here is consistent
with a flooring divide. E.g. <code>floor(x / y) * y + mod(x, y) = x</code>.</p>

<p><em>NOTE</em>: <a href="../tf/math/floormod.html"><code>math.floormod</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>, <code>bfloat16</code>, <code>half</code>, <code>float32</code>, <code>float64</code>.</li>
<li><b><code>y</code></b>: A <code>Tensor</code>. Must have the same type as <code>x</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code>. Has the same type as <code>x</code>.</p>

<h3 id="__rmul__"><code>__rmul__</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/math_ops.py">View source</a></p>

<p><code>python
__rmul__(
    x,
    y,
    name=None
)
</code></p>

<p>Returns x * y element-wise.</p>

<p><em>NOTE</em>: <a href="../tf/math/multiply.html"><code>tf.multiply</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code>. Must be one of the following types: <code>bfloat16</code>, <code>half</code>, <code>float32</code>, <code>float64</code>, <code>uint8</code>, <code>int8</code>, <code>uint16</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.</li>
<li><b><code>y</code></b>: A <code>Tensor</code>. Must have the same type as <code>x</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code>. Has the same type as <code>x</code>.</p>

<h3 id="__ror__"><code>__ror__</code></h3>


<p>Defined in generated file: <code>python/ops/gen_math_ops.py</code></p>

<p><code>python
__ror__(
    x,
    y,
    name=None
)
</code></p>

<p>Returns the truth value of x OR y element-wise.</p>

<p><em>NOTE</em>: <a href="../tf/math/logical_or.html"><code>math.logical_or</code></a> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code> of type <code>bool</code>.</li>
<li><b><code>y</code></b>: A <code>Tensor</code> of type <code>bool</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code> of type <code>bool</code>.</p>

<h3 id="__rpow__"><code>__rpow__</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/math_ops.py">View source</a></p>

<p><code>python
__rpow__(
    x,
    y,
    name=None
)
</code></p>

<p>Computes the power of one value to another.</p>

<p>Given a tensor <code>x</code> and a tensor <code>y</code>, this operation computes \(x<sup>y</sup>\) for
corresponding elements in <code>x</code> and <code>y</code>. For example:</p>

<p><code>python
x = tf.constant([[2, 2], [3, 3]])
y = tf.constant([[8, 16], [2, 3]])
tf.pow(x, y)  # [[256, 65536], [9, 27]]
</code></p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code> of type <code>float16</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>,
<code>complex64</code>, or <code>complex128</code>.</li>
<li><b><code>y</code></b>: A <code>Tensor</code> of type <code>float16</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>,
<code>complex64</code>, or <code>complex128</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code>.</p>

<h3 id="__rsub__"><code>__rsub__</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/math_ops.py">View source</a></p>

<p><code>python
__rsub__(
    x,
    y,
    name=None
)
</code></p>

<p>Returns x - y element-wise.</p>

<p><em>NOTE</em>: <code>Subtract</code> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code>. Must be one of the following types: <code>bfloat16</code>, <code>half</code>, <code>float32</code>, <code>float64</code>, <code>uint8</code>, <code>int8</code>, <code>uint16</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.</li>
<li><b><code>y</code></b>: A <code>Tensor</code>. Must have the same type as <code>x</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code>. Has the same type as <code>x</code>.</p>

<h3 id="__rtruediv__"><code>__rtruediv__</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/math_ops.py">View source</a></p>

<p><code>python
__rtruediv__(
    x,
    y,
    name=None
)
</code></p>

<p>Divides x / y elementwise (using Python 3 division operator semantics).</p>

<p>NOTE: Prefer using the Tensor operator or tf.divide which obey Python
division operator semantics.</p>

<p>This function forces Python 3 division operator semantics where all integer
arguments are cast to floating types first.   This op is generated by normal
<code>x / y</code> division in Python 3 and in Python 2.7 with
<code>from __future__ import division</code>.  If you want integer division that rounds
down, use <code>x // y</code> or <code>tf.math.floordiv</code>.</p>

<p><code>x</code> and <code>y</code> must have the same numeric type.  If the inputs are floating
point, the output will have the same type.  If the inputs are integral, the
inputs are cast to <code>float32</code> for <code>int8</code> and <code>int16</code> and <code>float64</code> for <code>int32</code>
and <code>int64</code> (matching the behavior of Numpy).</p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: <code>Tensor</code> numerator of numeric type.</li>
<li><b><code>y</code></b>: <code>Tensor</code> denominator of numeric type.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p><code>x / y</code> evaluated in floating point.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>TypeError</code></b>: If <code>x</code> and <code>y</code> have different dtypes.</li>
</ul>


<h3 id="__rxor__"><code>__rxor__</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/math_ops.py">View source</a></p>

<p><code>python
__rxor__(
    x,
    y,
    name='LogicalXor'
)
</code></p>

<p>Logical XOR function.</p>

<p>x ^ y = (x | y) &amp; ~(x &amp; y)</p>

<p>Inputs are tensor and if the tensors contains more than one element, an
element-wise logical XOR is computed.</p>

<h4>Usage:</h4>

<p>```python
x = tf.constant([False, False, True, True], dtype = tf.bool)
y = tf.constant([False, True, False, True], dtype = tf.bool)
z = tf.logical_xor(x, y, name=&ldquo;LogicalXor&rdquo;)</p>

<h1>here z = [False  True  True False]</h1>

<p>```</p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code> type bool.</li>
<li><b><code>y</code></b>: A <code>Tensor</code> of type bool.</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code> of type bool with the same size as that of x or y.</p>

<h3 id="__sub__"><code>__sub__</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/math_ops.py">View source</a></p>

<p><code>python
__sub__(
    x,
    y,
    name=None
)
</code></p>

<p>Returns x - y element-wise.</p>

<p><em>NOTE</em>: <code>Subtract</code> supports broadcasting. More about broadcasting
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">here</a></p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code>. Must be one of the following types: <code>bfloat16</code>, <code>half</code>, <code>float32</code>, <code>float64</code>, <code>uint8</code>, <code>int8</code>, <code>uint16</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.</li>
<li><b><code>y</code></b>: A <code>Tensor</code>. Must have the same type as <code>x</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code>. Has the same type as <code>x</code>.</p>

<h3 id="__truediv__"><code>__truediv__</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/math_ops.py">View source</a></p>

<p><code>python
__truediv__(
    x,
    y,
    name=None
)
</code></p>

<p>Divides x / y elementwise (using Python 3 division operator semantics).</p>

<p>NOTE: Prefer using the Tensor operator or tf.divide which obey Python
division operator semantics.</p>

<p>This function forces Python 3 division operator semantics where all integer
arguments are cast to floating types first.   This op is generated by normal
<code>x / y</code> division in Python 3 and in Python 2.7 with
<code>from __future__ import division</code>.  If you want integer division that rounds
down, use <code>x // y</code> or <code>tf.math.floordiv</code>.</p>

<p><code>x</code> and <code>y</code> must have the same numeric type.  If the inputs are floating
point, the output will have the same type.  If the inputs are integral, the
inputs are cast to <code>float32</code> for <code>int8</code> and <code>int16</code> and <code>float64</code> for <code>int32</code>
and <code>int64</code> (matching the behavior of Numpy).</p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: <code>Tensor</code> numerator of numeric type.</li>
<li><b><code>y</code></b>: <code>Tensor</code> denominator of numeric type.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p><code>x / y</code> evaluated in floating point.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>TypeError</code></b>: If <code>x</code> and <code>y</code> have different dtypes.</li>
</ul>


<h3 id="__xor__"><code>__xor__</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/math_ops.py">View source</a></p>

<p><code>python
__xor__(
    x,
    y,
    name='LogicalXor'
)
</code></p>

<p>Logical XOR function.</p>

<p>x ^ y = (x | y) &amp; ~(x &amp; y)</p>

<p>Inputs are tensor and if the tensors contains more than one element, an
element-wise logical XOR is computed.</p>

<h4>Usage:</h4>

<p>```python
x = tf.constant([False, False, True, True], dtype = tf.bool)
y = tf.constant([False, True, False, True], dtype = tf.bool)
z = tf.logical_xor(x, y, name=&ldquo;LogicalXor&rdquo;)</p>

<h1>here z = [False  True  True False]</h1>

<p>```</p>

<h4>Args:</h4>

<ul>
<li><b><code>x</code></b>: A <code>Tensor</code> type bool.</li>
<li><b><code>y</code></b>: A <code>Tensor</code> of type bool.</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code> of type bool with the same size as that of x or y.</p>

<h3 id="bounding_shape"><code>bounding_shape</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
bounding_shape(
    axis=None,
    name=None,
    out_type=None
)
</code></p>

<p>Returns the tight bounding box shape for this <code>RaggedTensor</code>.</p>

<h4>Args:</h4>

<ul>
<li><b><code>axis</code></b>: An integer scalar or vector indicating which axes to return the
bounding box for.  If not specified, then the full bounding box is
returned.</li>
<li><b><code>name</code></b>: A name prefix for the returned tensor (optional).</li>
<li><b><code>out_type</code></b>: <code>dtype</code> for the returned tensor.  Defaults to
<code>self.row_splits.dtype</code>.</li>
</ul>


<h4>Returns:</h4>

<p>An integer <code>Tensor</code> (<code>dtype=self.row_splits.dtype</code>).  If <code>axis</code> is not
specified, then <code>output</code> is a vector with
<code>output.shape=[self.shape.ndims]</code>.  If <code>axis</code> is a scalar, then the
<code>output</code> is a scalar.  If <code>axis</code> is a vector, then <code>output</code> is a vector,
where <code>output[i]</code> is the bounding size for dimension <code>axis[i]</code>.</p>

<h4>Example:</h4>

<p>  ```python</p>

<blockquote><blockquote><blockquote><p>rt = ragged.constant([[1, 2, 3, 4], [5], [], [6, 7, 8, 9], [10]])
rt.bounding_shape()
  [5, 4]
  ```</p></blockquote></blockquote></blockquote>

<h3 id="consumers"><code>consumers</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
consumers()
</code></p>

<h3 id="from_nested_row_lengths"><code>from_nested_row_lengths</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
@classmethod
from_nested_row_lengths(
    cls,
    flat_values,
    nested_row_lengths,
    name=None,
    validate=True
)
</code></p>

<p>Creates a <code>RaggedTensor</code> from a nested list of <code>row_lengths</code> tensors.</p>

<h4>Equivalent to:</h4>

<p><code>python
result = flat_values
for row_lengths in reversed(nested_row_lengths):
  result = from_row_lengths(result, row_lengths)
</code></p>

<h4>Args:</h4>

<ul>
<li><b><code>flat_values</code></b>: A potentially ragged tensor.</li>
<li><b><code>nested_row_lengths</code></b>: A list of 1-D integer tensors.  The <code>i</code>th tensor is
used as the <code>row_lengths</code> for the <code>i</code>th ragged dimension.</li>
<li><b><code>name</code></b>: A name prefix for the RaggedTensor (optional).</li>
<li><b><code>validate</code></b>: If true, then use assertions to check that the arguments form
a valid <code>RaggedTensor</code>.</li>
</ul>


<h4>Returns:</h4>

<p>A <code>RaggedTensor</code> (or <code>flat_values</code> if <code>nested_row_lengths</code> is empty).</p>

<h3 id="from_nested_row_splits"><code>from_nested_row_splits</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
@classmethod
from_nested_row_splits(
    cls,
    flat_values,
    nested_row_splits,
    name=None,
    validate=True
)
</code></p>

<p>Creates a <code>RaggedTensor</code> from a nested list of <code>row_splits</code> tensors.</p>

<h4>Equivalent to:</h4>

<p><code>python
result = flat_values
for row_splits in reversed(nested_row_splits):
  result = from_row_splits(result, row_splits)
</code></p>

<h4>Args:</h4>

<ul>
<li><b><code>flat_values</code></b>: A potentially ragged tensor.</li>
<li><b><code>nested_row_splits</code></b>: A list of 1-D integer tensors.  The <code>i</code>th tensor is
used as the <code>row_splits</code> for the <code>i</code>th ragged dimension.</li>
<li><b><code>name</code></b>: A name prefix for the RaggedTensor (optional).</li>
<li><b><code>validate</code></b>: If true, then use assertions to check that the arguments form a
valid <code>RaggedTensor</code>.</li>
</ul>


<h4>Returns:</h4>

<p>A <code>RaggedTensor</code> (or <code>flat_values</code> if <code>nested_row_splits</code> is empty).</p>

<h3 id="from_nested_value_rowids"><code>from_nested_value_rowids</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
@classmethod
from_nested_value_rowids(
    cls,
    flat_values,
    nested_value_rowids,
    nested_nrows=None,
    name=None,
    validate=True
)
</code></p>

<p>Creates a <code>RaggedTensor</code> from a nested list of <code>value_rowids</code> tensors.</p>

<h4>Equivalent to:</h4>

<p><code>python
result = flat_values
for (rowids, nrows) in reversed(zip(nested_value_rowids, nested_nrows)):
  result = from_value_rowids(result, rowids, nrows)
</code></p>

<h4>Args:</h4>

<ul>
<li><b><code>flat_values</code></b>: A potentially ragged tensor.</li>
<li><b><code>nested_value_rowids</code></b>: A list of 1-D integer tensors.  The <code>i</code>th tensor is
used as the <code>value_rowids</code> for the <code>i</code>th ragged dimension.</li>
<li><b><code>nested_nrows</code></b>: A list of integer scalars.  The <code>i</code>th scalar is used as the
<code>nrows</code> for the <code>i</code>th ragged dimension.</li>
<li><b><code>name</code></b>: A name prefix for the RaggedTensor (optional).</li>
<li><b><code>validate</code></b>: If true, then use assertions to check that the arguments form
a valid <code>RaggedTensor</code>.</li>
</ul>


<h4>Returns:</h4>

<p>A <code>RaggedTensor</code> (or <code>flat_values</code> if <code>nested_value_rowids</code> is empty).</p>

<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: If <code>len(nested_values_rowids) != len(nested_nrows)</code>.</li>
</ul>


<h3 id="from_row_lengths"><code>from_row_lengths</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
@classmethod
from_row_lengths(
    cls,
    values,
    row_lengths,
    name=None,
    validate=True
)
</code></p>

<p>Creates a <code>RaggedTensor</code> with rows partitioned by <code>row_lengths</code>.</p>

<p>The returned <code>RaggedTensor</code> corresponds with the python list defined by:</p>

<p><code>python
result = [[values.pop(0) for i in range(length)]
          for length in row_lengths]
</code></p>

<h4>Args:</h4>

<ul>
<li><b><code>values</code></b>: A potentially ragged tensor with shape <code>[nvals, ...]</code>.</li>
<li><b><code>row_lengths</code></b>: A 1-D integer tensor with shape <code>[nrows]</code>.  Must be
nonnegative.  <code>sum(row_lengths)</code> must be <code>nvals</code>.</li>
<li><b><code>name</code></b>: A name prefix for the RaggedTensor (optional).</li>
<li><b><code>validate</code></b>: If true, then use assertions to check that the arguments form
a valid <code>RaggedTensor</code>.</li>
</ul>


<h4>Returns:</h4>

<p>A <code>RaggedTensor</code>.  <code>result.rank = values.rank + 1</code>.
<code>result.ragged_rank = values.ragged_rank + 1</code>.</p>

<h4>Example:</h4>

<p>  ```python</p>

<blockquote><blockquote><blockquote><p>print(tf.RaggedTensor.from_row_lengths(
  &hellip;     values=[3, 1, 4, 1, 5, 9, 2, 6],
  &hellip;     row_lengths=[4, 0, 3, 1, 0]))
  &lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []])>
  ```</p></blockquote></blockquote></blockquote>

<h3 id="from_row_limits"><code>from_row_limits</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
@classmethod
from_row_limits(
    cls,
    values,
    row_limits,
    name=None,
    validate=True
)
</code></p>

<p>Creates a <code>RaggedTensor</code> with rows partitioned by <code>row_limits</code>.</p>

<p>Equivalent to: <code>from_row_splits(values, concat([0, row_limits]))</code>.</p>

<h4>Args:</h4>

<ul>
<li><b><code>values</code></b>: A potentially ragged tensor with shape <code>[nvals, ...]</code>.</li>
<li><b><code>row_limits</code></b>: A 1-D integer tensor with shape <code>[nrows]</code>.  Must be sorted in
ascending order.  If <code>nrows&gt;0</code>, then <code>row_limits[-1]</code> must be <code>nvals</code>.</li>
<li><b><code>name</code></b>: A name prefix for the RaggedTensor (optional).</li>
<li><b><code>validate</code></b>: If true, then use assertions to check that the arguments form
a valid <code>RaggedTensor</code>.</li>
</ul>


<h4>Returns:</h4>

<p>A <code>RaggedTensor</code>.  <code>result.rank = values.rank + 1</code>.
<code>result.ragged_rank = values.ragged_rank + 1</code>.</p>

<h4>Example:</h4>

<p>  ```python</p>

<blockquote><blockquote><blockquote><p>print(tf.RaggedTensor.from_row_limits(
  &hellip;     values=[3, 1, 4, 1, 5, 9, 2, 6],
  &hellip;     row_limits=[4, 4, 7, 8, 8]))
  &lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>
  ```</p></blockquote></blockquote></blockquote>

<h3 id="from_row_splits"><code>from_row_splits</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
@classmethod
from_row_splits(
    cls,
    values,
    row_splits,
    name=None,
    validate=True
)
</code></p>

<p>Creates a <code>RaggedTensor</code> with rows partitioned by <code>row_splits</code>.</p>

<p>The returned <code>RaggedTensor</code> corresponds with the python list defined by:</p>

<p><code>python
result = [values[row_splits[i]:row_splits[i + 1]]
          for i in range(len(row_splits) - 1)]
</code></p>

<h4>Args:</h4>

<ul>
<li><b><code>values</code></b>: A potentially ragged tensor with shape <code>[nvals, ...]</code>.</li>
<li><b><code>row_splits</code></b>: A 1-D integer tensor with shape <code>[nrows+1]</code>.  Must not be
empty, and must be sorted in ascending order.  <code>row_splits[0]</code> must be
zero and <code>row_splits[-1]</code> must be <code>nvals</code>.</li>
<li><b><code>name</code></b>: A name prefix for the RaggedTensor (optional).</li>
<li><b><code>validate</code></b>: If true, then use assertions to check that the arguments form
a valid <code>RaggedTensor</code>.</li>
</ul>


<h4>Returns:</h4>

<p>A <code>RaggedTensor</code>.  <code>result.rank = values.rank + 1</code>.
<code>result.ragged_rank = values.ragged_rank + 1</code>.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: If <code>row_splits</code> is an empty list.</li>
</ul>


<h4>Example:</h4>

<p>  ```python</p>

<blockquote><blockquote><blockquote><p>print(tf.RaggedTensor.from_row_splits(
  &hellip;     values=[3, 1, 4, 1, 5, 9, 2, 6],
  &hellip;     row_splits=[0, 4, 4, 7, 8, 8]))
  &lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>
  ```</p></blockquote></blockquote></blockquote>

<h3 id="from_row_starts"><code>from_row_starts</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
@classmethod
from_row_starts(
    cls,
    values,
    row_starts,
    name=None,
    validate=True
)
</code></p>

<p>Creates a <code>RaggedTensor</code> with rows partitioned by <code>row_starts</code>.</p>

<p>Equivalent to: <code>from_row_splits(values, concat([row_starts, nvals]))</code>.</p>

<h4>Args:</h4>

<ul>
<li><b><code>values</code></b>: A potentially ragged tensor with shape <code>[nvals, ...]</code>.</li>
<li><b><code>row_starts</code></b>: A 1-D integer tensor with shape <code>[nrows]</code>.  Must be
nonnegative and sorted in ascending order.  If <code>nrows&gt;0</code>, then
<code>row_starts[0]</code> must be zero.</li>
<li><b><code>name</code></b>: A name prefix for the RaggedTensor (optional).</li>
<li><b><code>validate</code></b>: If true, then use assertions to check that the arguments form
a valid <code>RaggedTensor</code>.</li>
</ul>


<h4>Returns:</h4>

<p>A <code>RaggedTensor</code>.  <code>result.rank = values.rank + 1</code>.
<code>result.ragged_rank = values.ragged_rank + 1</code>.</p>

<h4>Example:</h4>

<p>  ```python</p>

<blockquote><blockquote><blockquote><p>print(tf.RaggedTensor.from_row_starts(
  &hellip;     values=[3, 1, 4, 1, 5, 9, 2, 6],
  &hellip;     row_starts=[0, 4, 4, 7, 8]))
  &lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>
  ```</p></blockquote></blockquote></blockquote>

<h3 id="from_sparse"><code>from_sparse</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
@classmethod
from_sparse(
    cls,
    st_input,
    name=None,
    row_splits_dtype=tf.dtypes.int64
)
</code></p>

<p>Converts a 2D <a href="../tf/sparse/SparseTensor.html"><code>tf.SparseTensor</code></a> to a <code>RaggedTensor</code>.</p>

<p>Each row of the <code>output</code> <code>RaggedTensor</code> will contain the explicit values
from the same row in <code>st_input</code>.  <code>st_input</code> must be ragged-right.  If not
it is not ragged-right, then an error will be generated.</p>

<h4>Example:</h4>

<p>```python</p>

<blockquote><blockquote><blockquote><p>st = SparseTensor(indices=[[0, 1], [0, 2], [0, 3], [1, 0], [3, 0]],
&hellip;                   values=[1, 2, 3, 4, 5],
&hellip;                   dense_shape=[4, 3])
rt.RaggedTensor.from_sparse(st).eval().tolist()
[[1, 2, 3], [4], [], [5]]
```</p></blockquote></blockquote></blockquote>

<p>Currently, only two-dimensional <code>SparseTensors</code> are supported.</p>

<h4>Args:</h4>

<ul>
<li><b><code>st_input</code></b>: The sparse tensor to convert.  Must have rank 2.</li>
<li><b><code>name</code></b>: A name prefix for the returned tensors (optional).</li>
<li><b><code>row_splits_dtype</code></b>: <code>dtype</code> for the returned <code>RaggedTensor</code>&rsquo;s <code>row_splits</code>
tensor.  One of <a href="../tf.html#int32"><code>tf.int32</code></a> or <a href="../tf.html#int64"><code>tf.int64</code></a>.</li>
</ul>


<h4>Returns:</h4>

<p>A <code>RaggedTensor</code> with the same values as <code>st_input</code>.
<code>output.ragged_rank = rank(st_input) - 1</code>.
<code>output.shape = [st_input.dense_shape[0], None]</code>.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: If the number of dimensions in <code>st_input</code> is not known
statically, or is not two.</li>
</ul>


<h3 id="from_tensor"><code>from_tensor</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
@classmethod
from_tensor(
    cls,
    tensor,
    lengths=None,
    padding=None,
    ragged_rank=1,
    name=None,
    row_splits_dtype=tf.dtypes.int64
)
</code></p>

<p>Converts a <a href="../tf/Tensor.html"><code>tf.Tensor</code></a> into a <code>RaggedTensor</code>.</p>

<p>The set of absent/default values may be specified using a vector of lengths
or a padding value (but not both).  If <code>lengths</code> is specified, then the
output tensor will satisfy <code>output[row] = tensor[row][:lengths[row]]</code>. If
&lsquo;lengths&rsquo; is a list of lists or tuple of lists, those lists will be used
as nested row lengths. If <code>padding</code> is specified, then any row <em>suffix</em>
consisting entirely of <code>padding</code> will be excluded from the returned
<code>RaggedTensor</code>.  If neither <code>lengths</code> nor <code>padding</code> is specified, then the
returned <code>RaggedTensor</code> will have no absent/default values.</p>

<h4>Examples:</h4>

<p>```python</p>

<blockquote><blockquote><blockquote><p>dt = tf.constant([[5, 7, 0], [0, 3, 0], [6, 0, 0]])
tf.RaggedTensor.from_tensor(dt)
&lt;tf.RaggedTensor [[5, 7, 0], [0, 3, 0], [6, 0, 0]]>
tf.RaggedTensor.from_tensor(dt, lengths=[1, 0, 3])
&lt;tf.RaggedTensor [[5], [], [6, 0, 0]]></p></blockquote></blockquote></blockquote>

<p>```</p>

<blockquote><blockquote><blockquote><p>tf.RaggedTensor.from_tensor(dt, padding=0)
&lt;tf.RaggedTensor [[5, 7], [0, 3], [6]]>
```</p></blockquote></blockquote></blockquote>

<p>```</p>

<blockquote><blockquote><blockquote><p>dt = tf.constant([[[5, 0], [7, 0], [0, 0]],
                      [[0, 0], [3, 0], [0, 0]],
                      [[6, 0], [0, 0], [0, 0]]])
tf.RaggedTensor.from_tensor(dt, lengths=([2, 0, 3], [1, 1, 2, 0, 1]))
&lt;tf.RaggedTensor [[[5], [7]], [], [[6, 0], [], [0]]]>
<code>
</code></p></blockquote></blockquote></blockquote>

<h4>Args:</h4>

<ul>
<li><b><code>tensor</code></b>: The <code>Tensor</code> to convert.  Must have rank <code>ragged_rank + 1</code> or
higher.</li>
<li><b><code>lengths</code></b>: An optional set of row lengths, specified using a 1-D integer
<code>Tensor</code> whose length is equal to <code>tensor.shape[0]</code> (the number of rows
in <code>tensor</code>).  If specified, then <code>output[row]</code> will contain
<code>tensor[row][:lengths[row]]</code>.  Negative lengths are treated as zero. You
may optionally pass a list or tuple of lengths to this argument, which
will be used as nested row lengths to construct a ragged tensor with
multiple ragged dimensions.</li>
<li><b><code>padding</code></b>: An optional padding value.  If specified, then any row suffix
consisting entirely of <code>padding</code> will be excluded from the returned
RaggedTensor.  <code>padding</code> is a <code>Tensor</code> with the same dtype as <code>tensor</code>
and with <code>shape=tensor.shape[ragged_rank + 1:]</code>.</li>
<li><b><code>ragged_rank</code></b>: Integer specifying the ragged rank for the returned
<code>RaggedTensor</code>.  Must be greater than zero.</li>
<li><b><code>name</code></b>: A name prefix for the returned tensors (optional).</li>
<li><b><code>row_splits_dtype</code></b>: <code>dtype</code> for the returned <code>RaggedTensor</code>&rsquo;s <code>row_splits</code>
tensor.  One of <a href="../tf.html#int32"><code>tf.int32</code></a> or <a href="../tf.html#int64"><code>tf.int64</code></a>.</li>
</ul>


<h4>Returns:</h4>

<p>A <code>RaggedTensor</code> with the specified <code>ragged_rank</code>.  The shape of the
returned ragged tensor is compatible with the shape of <code>tensor</code>.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: If both <code>lengths</code> and <code>padding</code> are specified.</li>
</ul>


<h3 id="from_value_rowids"><code>from_value_rowids</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
@classmethod
from_value_rowids(
    cls,
    values,
    value_rowids,
    nrows=None,
    name=None,
    validate=True
)
</code></p>

<p>Creates a <code>RaggedTensor</code> with rows partitioned by <code>value_rowids</code>.</p>

<p>The returned <code>RaggedTensor</code> corresponds with the python list defined by:</p>

<p><code>python
result = [[values[i] for i in range(len(values)) if value_rowids[i] == row]
          for row in range(nrows)]
</code></p>

<h4>Args:</h4>

<ul>
<li><b><code>values</code></b>: A potentially ragged tensor with shape <code>[nvals, ...]</code>.</li>
<li><b><code>value_rowids</code></b>: A 1-D integer tensor with shape <code>[nvals]</code>, which corresponds
one-to-one with <code>values</code>, and specifies each value&rsquo;s row index.  Must be
nonnegative, and must be sorted in ascending order.</li>
<li><b><code>nrows</code></b>: An integer scalar specifying the number of rows.  This should be
specified if the <code>RaggedTensor</code> may containing empty training rows. Must
be greater than <code>value_rowids[-1]</code> (or zero if <code>value_rowids</code> is empty).
Defaults to <code>value_rowids[-1]</code> (or zero if <code>value_rowids</code> is empty).</li>
<li><b><code>name</code></b>: A name prefix for the RaggedTensor (optional).</li>
<li><b><code>validate</code></b>: If true, then use assertions to check that the arguments form
a valid <code>RaggedTensor</code>.</li>
</ul>


<h4>Returns:</h4>

<p>A <code>RaggedTensor</code>.  <code>result.rank = values.rank + 1</code>.
<code>result.ragged_rank = values.ragged_rank + 1</code>.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: If <code>nrows</code> is incompatible with <code>value_rowids</code>.</li>
</ul>


<h4>Example:</h4>

<p>  ```python</p>

<blockquote><blockquote><blockquote><p>print(tf.RaggedTensor.from_value_rowids(
  &hellip;     values=[3, 1, 4, 1, 5, 9, 2, 6],
  &hellip;     value_rowids=[0, 0, 0, 0, 2, 2, 2, 3],
  &hellip;     nrows=5))
  &lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>
  ```</p></blockquote></blockquote></blockquote>

<h3 id="nested_row_lengths"><code>nested_row_lengths</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
nested_row_lengths(name=None)
</code></p>

<p>Returns a tuple containing the row_lengths for all ragged dimensions.</p>

<p><code>rt.nested_row_lengths()</code> is a tuple containing the <code>row_lengths</code> tensors
for all ragged dimensions in <code>rt</code>, ordered from outermost to innermost.</p>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>: A name prefix for the returned tensors (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>tuple</code> of 1-D integer <code>Tensors</code>.  The length of the tuple is equal to
<code>self.ragged_rank</code>.</p>

<h3 id="nested_value_rowids"><code>nested_value_rowids</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
nested_value_rowids(name=None)
</code></p>

<p>Returns a tuple containing the value_rowids for all ragged dimensions.</p>

<p><code>rt.nested_value_rowids</code> is a tuple containing the <code>value_rowids</code> tensors
for
all ragged dimensions in <code>rt</code>, ordered from outermost to innermost.  In
particular, <code>rt.nested_value_rowids = (rt.value_rowids(),) + value_ids</code>
where:</p>

<pre><code>* `value_ids = ()` if `rt.values` is a `Tensor`.
* `value_ids = rt.values.nested_value_rowids` otherwise.
</code></pre>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>: A name prefix for the returned tensors (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>tuple</code> of 1-D integer <code>Tensor</code>s.</p>

<h4>Example:</h4>

<p>  ```python</p>

<blockquote><blockquote><blockquote><p>rt = ragged.constant([[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]])
for i, ids in enumerate(rt.nested_value_rowids()):
  &hellip;   print(&lsquo;row ids for dimension %d: %s&rsquo; % (i+1, ids))
  row ids for dimension 1: [0]
  row ids for dimension 2: [0, 0, 0, 2, 2]
  row ids for dimension 3: [0, 0, 0, 0, 2, 2, 2, 3]
  ```</p></blockquote></blockquote></blockquote>

<h3 id="nrows"><code>nrows</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
nrows(
    out_type=None,
    name=None
)
</code></p>

<p>Returns the number of rows in this ragged tensor.</p>

<p>I.e., the size of the outermost dimension of the tensor.</p>

<h4>Args:</h4>

<ul>
<li><b><code>out_type</code></b>: <code>dtype</code> for the returned tensor.  Defaults to
<code>self.row_splits.dtype</code>.</li>
<li><b><code>name</code></b>: A name prefix for the returned tensor (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A scalar <code>Tensor</code> with dtype <code>out_type</code>.</p>

<h4>Example:</h4>

<p>  ```python</p>

<blockquote><blockquote><blockquote><p>rt = ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])
rt.nrows()  # rt has 5 rows.
  5
  ```</p></blockquote></blockquote></blockquote>

<h3 id="row_lengths"><code>row_lengths</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
row_lengths(
    axis=1,
    name=None
)
</code></p>

<p>Returns the lengths of the rows in this ragged tensor.</p>

<p><code>rt.row_lengths()[i]</code> indicates the number of values in the
<code>i</code>th row of <code>rt</code>.</p>

<h4>Args:</h4>

<ul>
<li><b><code>axis</code></b>: An integer constant indicating the axis whose row lengths should be
returned.</li>
<li><b><code>name</code></b>: A name prefix for the returned tensor (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A potentially ragged integer Tensor with shape <code>self.shape[:axis]</code>.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: If <code>axis</code> is out of bounds.</li>
</ul>


<h4>Example:</h4>

<p>  ```python</p>

<blockquote><blockquote><blockquote><p>rt = ragged.constant([[[3, 1, 4], [1]], [], [[5, 9], [2]], [[6]], []])
rt.row_lengths(rt)  # lengths of rows in rt
  tf.Tensor([2, 0, 2, 1, 0])
rt.row_lengths(axis=2)  # lengths of axis=2 rows.
  &lt;tf.RaggedTensor [[3, 1], [], [2, 1], [1], []]>
  ```</p></blockquote></blockquote></blockquote>

<h3 id="row_limits"><code>row_limits</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
row_limits(name=None)
</code></p>

<p>Returns the limit indices for rows in this ragged tensor.</p>

<p>These indices specify where the values for each row end in
<code>self.values</code>.  <code>rt.row_limits(self)</code> is equal to <code>rt.row_splits[:-1]</code>.</p>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>: A name prefix for the returned tensor (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A 1-D integer Tensor with shape <code>[nrows]</code>.
The returned tensor is nonnegative, and is sorted in ascending order.</p>

<h4>Example:</h4>

<p>  ```python</p>

<blockquote><blockquote><blockquote><p>rt = ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])
rt.values
  tf.Tensor([3, 1, 4, 1, 5, 9, 2, 6])
rt.row_limits()  # indices of row limits in rt.values
  tf.Tensor([4, 4, 7, 8, 8])
  ```</p></blockquote></blockquote></blockquote>

<h3 id="row_starts"><code>row_starts</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
row_starts(name=None)
</code></p>

<p>Returns the start indices for rows in this ragged tensor.</p>

<p>These indices specify where the values for each row begin in
<code>self.values</code>.  <code>rt.row_starts()</code> is equal to <code>rt.row_splits[:-1]</code>.</p>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>: A name prefix for the returned tensor (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A 1-D integer Tensor with shape <code>[nrows]</code>.
The returned tensor is nonnegative, and is sorted in ascending order.</p>

<h4>Example:</h4>

<p>  ```python</p>

<blockquote><blockquote><blockquote><p>rt = ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])
rt.values
  tf.Tensor([3, 1, 4, 1, 5, 9, 2, 6])
rt.row_starts()  # indices of row starts in rt.values
  tf.Tensor([0, 4, 4, 7, 8])
  ```</p></blockquote></blockquote></blockquote>

<h3 id="to_list"><code>to_list</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
to_list()
</code></p>

<p>Returns a nested Python <code>list</code> with the values for this <code>RaggedTensor</code>.</p>

<p>Requires that <code>rt</code> was constructed in eager execution mode.</p>

<h4>Returns:</h4>

<p>A nested Python <code>list</code>.</p>

<h3 id="to_sparse"><code>to_sparse</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
to_sparse(name=None)
</code></p>

<p>Converts this <code>RaggedTensor</code> into a <a href="../tf/sparse/SparseTensor.html"><code>tf.SparseTensor</code></a>.</p>

<h4>Example:</h4>

<p>```python</p>

<blockquote><blockquote><blockquote><p>rt = ragged.constant([[1, 2, 3], [4], [], [5, 6]])
rt.to_sparse().eval()
SparseTensorValue(indices=[[0, 0], [0, 1], [0, 2], [1, 0], [3, 0], [3, 1]],
                  values=[1, 2, 3, 4, 5, 6],
                  dense_shape=[4, 3])
```</p></blockquote></blockquote></blockquote>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>: A name prefix for the returned tensors (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A SparseTensor with the same values as <code>self</code>.</p>

<h3 id="to_tensor"><code>to_tensor</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
to_tensor(
    default_value=None,
    name=None
)
</code></p>

<p>Converts this <code>RaggedTensor</code> into a <a href="../tf/Tensor.html"><code>tf.Tensor</code></a>.</p>

<h4>Example:</h4>

<p>```python</p>

<blockquote><blockquote><blockquote><p>rt = ragged.constant([[9, 8, 7], [], [6, 5], [4]])
print rt.to_tensor()
[[9 8 7]
 [0 0 0]
 [6 5 0]
 [4 0 0]]
```</p></blockquote></blockquote></blockquote>

<h4>Args:</h4>

<ul>
<li><b><code>default_value</code></b>: Value to set for indices not specified in <code>self</code>. Defaults
to zero.  <code>default_value</code> must be broadcastable to
<code>self.shape[self.ragged_rank + 1:]</code>.</li>
<li><b><code>name</code></b>: A name prefix for the returned tensors (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code> with shape <code>ragged.bounding_shape(self)</code> and the
values specified by the non-empty values in <code>self</code>.  Empty values are
assigned <code>default_value</code>.</p>

<h3 id="value_rowids"><code>value_rowids</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
value_rowids(name=None)
</code></p>

<p>Returns the row indices for the <code>values</code> in this ragged tensor.</p>

<p><code>rt.value_rowids()</code> corresponds one-to-one with the outermost dimension of
<code>rt.values</code>, and specifies the row containing each value.  In particular,
the row <code>rt[row]</code> consists of the values <code>rt.values[j]</code> where
<code>rt.value_rowids()[j] == row</code>.</p>

<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>: A name prefix for the returned tensor (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A 1-D integer <code>Tensor</code> with shape <code>self.values.shape[:1]</code>.
The returned tensor is nonnegative, and is sorted in ascending order.</p>

<h4>Example:</h4>

<p>  ```python</p>

<blockquote><blockquote><blockquote><p>rt = ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])
rt.values
  tf.Tensor([3, 1, 4, 1, 5, 9, 2, 6])
rt.value_rowids()
  tf.Tensor([0, 0, 0, 0, 2, 2, 2, 3])  # corresponds 1:1 with rt.values
  ```</p></blockquote></blockquote></blockquote>

<h3 id="with_flat_values"><code>with_flat_values</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
with_flat_values(new_values)
</code></p>

<p>Returns a copy of <code>self</code> with <code>flat_values</code> replaced by <code>new_value</code>.</p>

<p>Preserves cached row-partitioning tensors such as <code>self.cached_nrows</code> and
<code>self.cached_value_rowids</code> if they have values.</p>

<h4>Args:</h4>

<ul>
<li><b><code>new_values</code></b>: Potentially ragged tensor that should replace
<code>self.flat_values</code>.  Must have <code>rank &gt; 0</code>, and must have the same
number of rows as <code>self.flat_values</code>.</li>
</ul>


<h4>Returns:</h4>

<p>A <code>RaggedTensor</code>.
<code>result.rank = self.ragged_rank + new_values.rank</code>.
<code>result.ragged_rank = self.ragged_rank + new_values.ragged_rank</code>.</p>

<h3 id="with_row_splits_dtype"><code>with_row_splits_dtype</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
with_row_splits_dtype(dtype)
</code></p>

<p>Returns a copy of this RaggedTensor with the given <code>row_splits</code> dtype.</p>

<p>For RaggedTensors with multiple ragged dimensions, the <code>row_splits</code> for all
nested <code>RaggedTensor</code> objects are cast to the given dtype.</p>

<h4>Args:</h4>

<ul>
<li><b><code>dtype</code></b>: The dtype for <code>row_splits</code>.  One of <a href="../tf.html#int32"><code>tf.int32</code></a> or <a href="../tf.html#int64"><code>tf.int64</code></a>.</li>
</ul>


<h4>Returns:</h4>

<p>A copy of this RaggedTensor, with the <code>row_splits</code> cast to the given
type.</p>

<h3 id="with_values"><code>with_values</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/ragged/ragged_tensor.py">View source</a></p>

<p><code>python
with_values(new_values)
</code></p>

<p>Returns a copy of <code>self</code> with <code>values</code> replaced by <code>new_value</code>.</p>

<p>Preserves cached row-partitioning tensors such as <code>self.cached_nrows</code> and
<code>self.cached_value_rowids</code> if they have values.</p>

<h4>Args:</h4>

<ul>
<li><b><code>new_values</code></b>: Potentially ragged tensor to use as the <code>values</code> for the
returned <code>RaggedTensor</code>.  Must have <code>rank &gt; 0</code>, and must have the same
number of rows as <code>self.values</code>.</li>
</ul>


<h4>Returns:</h4>

<p>A <code>RaggedTensor</code>.  <code>result.rank = 1 + new_values.rank</code>.
<code>result.ragged_rank = 1 + new_values.ragged_rank</code></p>
