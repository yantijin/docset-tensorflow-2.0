<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.dynamic_stitch" />
<meta itemprop="path" content="Stable" />
</div>


<h1>tf.dynamic_stitch</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p>Defined in generated file: <code>python/ops/gen_data_flow_ops.py</code></p>

<!-- Start diff -->


<p>Interleave the values from the <code>data</code> tensors into a single tensor.</p>

<h3>Aliases:</h3>

<ul>
<li><code>tf.compat.v1.dynamic_stitch</code></li>
<li><code>tf.compat.v2.dynamic_stitch</code></li>
</ul>


<p><code>python
tf.dynamic_stitch(
    indices,
    data,
    name=None
)
</code></p>

<!-- Placeholder for "Used in" -->


<p>Builds a merged tensor such that</p>

<p><code>python
    merged[indices[m][i, ..., j], ...] = data[m][i, ..., j, ...]
</code></p>

<p>For example, if each <code>indices[m]</code> is scalar or vector, we have</p>

<p>```python
    # Scalar indices:
    merged[indices[m], &hellip;] = data[m][&hellip;]</p>

<pre><code># Vector indices:
merged[indices[m][i], ...] = data[m][i, ...]
</code></pre>

<p>```</p>

<p>Each <code>data[i].shape</code> must start with the corresponding <code>indices[i].shape</code>,
and the rest of <code>data[i].shape</code> must be constant w.r.t. <code>i</code>.  That is, we
must have <code>data[i].shape = indices[i].shape + constant</code>.  In terms of this
<code>constant</code>, the output shape is</p>

<pre><code>merged.shape = [max(indices)] + constant
</code></pre>

<p>Values are merged in order, so if an index appears in both <code>indices[m][i]</code> and
<code>indices[n][j]</code> for <code>(m,i) &lt; (n,j)</code> the slice <code>data[n][j]</code> will appear in the
merged result. If you do not need this guarantee, ParallelDynamicStitch might
perform better on some devices.</p>

<h4>For example:</h4>

<p><code>python
    indices[0] = 6
    indices[1] = [4, 1]
    indices[2] = [[5, 2], [0, 3]]
    data[0] = [61, 62]
    data[1] = [[41, 42], [11, 12]]
    data[2] = [[[51, 52], [21, 22]], [[1, 2], [31, 32]]]
    merged = [[1, 2], [11, 12], [21, 22], [31, 32], [41, 42],
              [51, 52], [61, 62]]
</code></p>

<p>This method can be used to merge partitions created by <code>dynamic_partition</code>
as illustrated on the following example:</p>

<p><code>python
    # Apply function (increments x_i) on elements for which a certain condition
    # apply (x_i != -1 in this example).
    x=tf.constant([0.1, -1., 5.2, 4.3, -1., 7.4])
    condition_mask=tf.not_equal(x,tf.constant(-1.))
    partitioned_data = tf.dynamic_partition(
        x, tf.cast(condition_mask, tf.int32) , 2)
    partitioned_data[1] = partitioned_data[1] + 1.0
    condition_indices = tf.dynamic_partition(
        tf.range(tf.shape(x)[0]), tf.cast(condition_mask, tf.int32) , 2)
    x = tf.dynamic_stitch(condition_indices, partitioned_data)
    # Here x=[1.1, -1., 6.2, 5.3, -1, 8.4], the -1. values remain
    # unchanged.
</code></p>

<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="https://www.tensorflow.org/images/DynamicStitch.png" alt>
</div>


<h4>Args:</h4>

<ul>
<li><b><code>indices</code></b>: A list of at least 1 <code>Tensor</code> objects with type <code>int32</code>.</li>
<li><b><code>data</code></b>: A list with the same length as <code>indices</code> of <code>Tensor</code> objects with the same type.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code>. Has the same type as <code>data</code>.</p>
