<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.compat.v1.summary.image" />
<meta itemprop="path" content="Stable" />
</div>


<h1>tf.compat.v1.summary.image</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p><a target="_blank" href="/code/stable/tensorflow/python/summary/summary.py">View source</a></p>

<!-- Start diff -->


<p>Outputs a <code>Summary</code> protocol buffer with images.</p>

<p><code>python
tf.compat.v1.summary.image(
    name,
    tensor,
    max_outputs=3,
    collections=None,
    family=None
)
</code></p>

<!-- Placeholder for "Used in" -->


<p>The summary has up to <code>max_outputs</code> summary values containing images. The
images are built from <code>tensor</code> which must be 4-D with shape <code>[batch_size,
height, width, channels]</code> and where <code>channels</code> can be:</p>

<ul>
<li>1: <code>tensor</code> is interpreted as Grayscale.</li>
<li>3: <code>tensor</code> is interpreted as RGB.</li>
<li>4: <code>tensor</code> is interpreted as RGBA.</li>
</ul>


<p>The images have the same number of channels as the input tensor. For float
input, the values are normalized one image at a time to fit in the range
<code>[0, 255]</code>.  <code>uint8</code> values are unchanged.  The op uses two different
normalization algorithms:</p>

<ul>
<li><p>If the input values are all positive, they are rescaled so the largest one
is 255.</p></li>
<li><p>If any input value is negative, the values are shifted so input value 0.0
is at 127.  They are then rescaled so that either the smallest value is 0,
or the largest one is 255.</p></li>
</ul>


<p>The <code>tag</code> in the outputted Summary.Value protobufs is generated based on the
name, with a suffix depending on the max_outputs setting:</p>

<ul>
<li>If <code>max_outputs</code> is 1, the summary value tag is &lsquo;<em>name</em>/image&rsquo;.</li>
<li>If <code>max_outputs</code> is greater than 1, the summary value tags are
generated sequentially as &lsquo;<em>name</em>/image/0&rsquo;, &lsquo;<em>name</em>/image/1&rsquo;, etc.</li>
</ul>


<h4>Args:</h4>

<ul>
<li><b><code>name</code></b>: A name for the generated node. Will also serve as a series name in
TensorBoard.</li>
<li><b><code>tensor</code></b>: A 4-D <code>uint8</code> or <code>float32</code> <code>Tensor</code> of shape <code>[batch_size, height,
width, channels]</code> where <code>channels</code> is 1, 3, or 4.</li>
<li><b><code>max_outputs</code></b>: Max number of batch elements to generate images for.</li>
<li><b><code>collections</code></b>: Optional list of ops.GraphKeys.  The collections to add the
summary to.  Defaults to [_ops.GraphKeys.SUMMARIES]</li>
<li><b><code>family</code></b>: Optional; if provided, used as the prefix of the summary tag name,
which controls the tab name used for display on Tensorboard.</li>
</ul>


<h4>Returns:</h4>

<p>A scalar <code>Tensor</code> of type <code>string</code>. The serialized <code>Summary</code> protocol
buffer.</p>
