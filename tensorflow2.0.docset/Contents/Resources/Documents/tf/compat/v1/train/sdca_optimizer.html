
    <html lang="zh-cn">
    <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <link href=../../../../../default.css" rel="stylesheet">
    <link href="
   ../../../../../github.css" rel="stylesheet">
    </head>
    <body>
    <div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.compat.v1.train.sdca_optimizer" />
<meta itemprop="path" content="Stable" />
</div>

<h1 id="tfcompatv1trainsdca_optimizer">tf.compat.v1.train.sdca_optimizer</h1>
<!-- Insert buttons -->

<table class="tfo-notebook-buttons tfo-api" align="left">
</table>

<p>Defined in generated file: <code>python/ops/gen_sdca_ops.py</code></p>
<!-- Start diff -->

<p>Distributed version of Stochastic Dual Coordinate Ascent (SDCA) optimizer for</p>
<div class="codehilite"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">sdca_optimizer</span><span class="p">(</span>
    <span class="n">sparse_example_indices</span><span class="p">,</span>
    <span class="n">sparse_feature_indices</span><span class="p">,</span>
    <span class="n">sparse_feature_values</span><span class="p">,</span>
    <span class="n">dense_features</span><span class="p">,</span>
    <span class="n">example_weights</span><span class="p">,</span>
    <span class="n">example_labels</span><span class="p">,</span>
    <span class="n">sparse_indices</span><span class="p">,</span>
    <span class="n">sparse_weights</span><span class="p">,</span>
    <span class="n">dense_weights</span><span class="p">,</span>
    <span class="n">example_state_data</span><span class="p">,</span>
    <span class="n">loss_type</span><span class="p">,</span>
    <span class="n">l1</span><span class="p">,</span>
    <span class="n">l2</span><span class="p">,</span>
    <span class="n">num_loss_partitions</span><span class="p">,</span>
    <span class="n">num_inner_iterations</span><span class="p">,</span>
    <span class="n">adaptative</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</pre></div>


<!-- Placeholder for "Used in" -->

<p>linear models with L1 + L2 regularization. As global optimization objective is
strongly-convex, the optimizer optimizes the dual objective at each step. The
optimizer applies each update one example at a time. Examples are sampled
uniformly, and the optimizer is learning rate free and enjoys linear convergence
rate.</p>
<p><a href="http://arxiv.org/pdf/1211.2717v1.pdf">Proximal Stochastic Dual Coordinate Ascent</a>.<br>
Shai Shalev-Shwartz, Tong Zhang. 2012</p>
<p>$$Loss Objective = \sum f_{i} (wx_{i}) + (l2 / 2) * |w|^2 + l1 * |w|$$</p>
<p><a href="http://arxiv.org/abs/1502.03508">Adding vs. Averaging in Distributed Primal-Dual Optimization</a>.<br>
Chenxin Ma, Virginia Smith, Martin Jaggi, Michael I. Jordan,
Peter Richtarik, Martin Takac. 2015</p>
<p><a href="https://arxiv.org/abs/1502.08053">Stochastic Dual Coordinate Ascent with Adaptive Probabilities</a>.<br>
Dominik Csiba, Zheng Qu, Peter Richtarik. 2015</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>sparse_example_indices</code></b>: A list of <code>Tensor</code> objects with type <code>int64</code>.
  a list of vectors which contain example indices.</li>
<li><b><code>sparse_feature_indices</code></b>: A list with the same length as <code>sparse_example_indices</code> of <code>Tensor</code> objects with type <code>int64</code>.
  a list of vectors which contain feature indices.</li>
<li><b><code>sparse_feature_values</code></b>: A list of <code>Tensor</code> objects with type <code>float32</code>.
  a list of vectors which contains feature value
  associated with each feature group.</li>
<li><b><code>dense_features</code></b>: A list of <code>Tensor</code> objects with type <code>float32</code>.
  a list of matrices which contains the dense feature values.</li>
<li><b><code>example_weights</code></b>: A <code>Tensor</code> of type <code>float32</code>.
  a vector which contains the weight associated with each
  example.</li>
<li><b><code>example_labels</code></b>: A <code>Tensor</code> of type <code>float32</code>.
  a vector which contains the label/target associated with each
  example.</li>
<li><b><code>sparse_indices</code></b>: A list with the same length as <code>sparse_example_indices</code> of <code>Tensor</code> objects with type <code>int64</code>.
  a list of vectors where each value is the indices which has
  corresponding weights in sparse_weights. This field maybe omitted for the
  dense approach.</li>
<li><b><code>sparse_weights</code></b>: A list with the same length as <code>sparse_example_indices</code> of <code>Tensor</code> objects with type <code>float32</code>.
  a list of vectors where each value is the weight associated with
  a sparse feature group.</li>
<li><b><code>dense_weights</code></b>: A list with the same length as <code>dense_features</code> of <code>Tensor</code> objects with type <code>float32</code>.
  a list of vectors where the values are the weights associated
  with a dense feature group.</li>
<li><b><code>example_state_data</code></b>: A <code>Tensor</code> of type <code>float32</code>.
  a list of vectors containing the example state data.</li>
<li><b><code>loss_type</code></b>: A <code>string</code> from: <code>"logistic_loss", "squared_loss", "hinge_loss", "smooth_hinge_loss", "poisson_loss"</code>.
  Type of the primal loss. Currently SdcaSolver supports logistic,
  squared and hinge losses.</li>
<li><b><code>l1</code></b>: A <code>float</code>. Symmetric l1 regularization strength.</li>
<li><b><code>l2</code></b>: A <code>float</code>. Symmetric l2 regularization strength.</li>
<li><b><code>num_loss_partitions</code></b>: An <code>int</code> that is <code>&gt;= 1</code>.
  Number of partitions of the global loss function.</li>
<li><b><code>num_inner_iterations</code></b>: An <code>int</code> that is <code>&gt;= 1</code>.
  Number of iterations per mini-batch.</li>
<li><b><code>adaptative</code></b>: An optional <code>bool</code>. Defaults to <code>True</code>.
  Whether to use Adaptive SDCA for the inner loop.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A tuple of <code>Tensor</code> objects (out_example_state_data, out_delta_sparse_weights, out_delta_dense_weights).</p>
<ul>
<li><b><code>out_example_state_data</code></b>: A <code>Tensor</code> of type <code>float32</code>.</li>
<li><b><code>out_delta_sparse_weights</code></b>: A list with the same length as <code>sparse_example_indices</code> of <code>Tensor</code> objects with type <code>float32</code>.</li>
<li><b><code>out_delta_dense_weights</code></b>: A list with the same length as <code>dense_features</code> of <code>Tensor</code> objects with type <code>float32</code>.</li>
</ul>
    </body>
    </html>
   