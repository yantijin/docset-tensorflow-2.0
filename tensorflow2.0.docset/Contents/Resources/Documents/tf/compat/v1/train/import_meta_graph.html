<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.compat.v1.train.import_meta_graph" />
<meta itemprop="path" content="Stable" />
</div>


<h1>tf.compat.v1.train.import_meta_graph</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/saver.py">View source</a></p>

<!-- Start diff -->


<p>Recreates a Graph saved in a <code>MetaGraphDef</code> proto.</p>

<p><code>python
tf.compat.v1.train.import_meta_graph(
    meta_graph_or_file,
    clear_devices=False,
    import_scope=None,
    **kwargs
)
</code></p>

<!-- Placeholder for "Used in" -->


<p>This function takes a <code>MetaGraphDef</code> protocol buffer as input. If
the argument is a file containing a <code>MetaGraphDef</code> protocol buffer ,
it constructs a protocol buffer from the file content. The function
then adds all the nodes from the <code>graph_def</code> field to the
current graph, recreates all the collections, and returns a saver
constructed from the <code>saver_def</code> field.</p>

<p>In combination with <code>export_meta_graph()</code>, this function can be used to</p>

<ul>
<li><p>Serialize a graph along with other Python objects such as <code>QueueRunner</code>,
<code>Variable</code> into a <code>MetaGraphDef</code>.</p></li>
<li><p>Restart training from a saved graph and checkpoints.</p></li>
<li><p>Run inference from a saved graph and checkpoints.</p></li>
</ul>


<p>```Python
&hellip;</p>

<h1>Create a saver.</h1>

<p>saver = tf.compat.v1.train.Saver(&hellip;variables&hellip;)</p>

<h1>Remember the training_op we want to run by adding it to a collection.</h1>

<p>tf.compat.v1.add_to_collection(&lsquo;train_op&rsquo;, train_op)
sess = tf.compat.v1.Session()
for step in xrange(1000000):
    sess.run(train_op)
    if step % 1000 == 0:
        # Saves checkpoint, which by default also exports a meta_graph
        # named &lsquo;my-model-global_step.meta&rsquo;.
        saver.save(sess, &lsquo;my-model&rsquo;, global_step=step)
```</p>

<p>Later we can continue training from this saved <code>meta_graph</code> without building
the model from scratch.</p>

<p><code>Python
with tf.Session() as sess:
  new_saver =
  tf.train.import_meta_graph('my-save-dir/my-model-10000.meta')
  new_saver.restore(sess, 'my-save-dir/my-model-10000')
  # tf.get_collection() returns a list. In this example we only want
  # the first one.
  train_op = tf.get_collection('train_op')[0]
  for step in xrange(1000000):
    sess.run(train_op)
</code></p>

<p>NOTE: Restarting training from saved <code>meta_graph</code> only works if the
device assignments have not changed.</p>

<h4>Example:</h4>

<p>Variables, placeholders, and independent operations can also be stored, as
shown in the following example.</p>

<p>```Python</p>

<h1>Saving contents and operations.</h1>

<p>v1 = tf.placeholder(tf.float32, name=&ldquo;v1&rdquo;)
v2 = tf.placeholder(tf.float32, name=&ldquo;v2&rdquo;)
v3 = tf.math.multiply(v1, v2)
vx = tf.Variable(10.0, name=&ldquo;vx&rdquo;)
v4 = tf.add(v3, vx, name=&ldquo;v4&rdquo;)
saver = tf.train.Saver([vx])
sess = tf.Session()
sess.run(tf.global_variables_initializer())
sess.run(vx.assign(tf.add(vx, vx)))
result = sess.run(v4, feed_dict={v1:12.0, v2:3.3})
print(result)
saver.save(sess, &ldquo;./model_ex1&rdquo;)
```</p>

<p>Later this model can be restored and contents loaded.</p>

<p>```Python</p>

<h1>Restoring variables and running operations.</h1>

<p>saver = tf.train.import_meta_graph(&ldquo;./model_ex1.meta&rdquo;)
sess = tf.Session()
saver.restore(sess, &ldquo;./model_ex1&rdquo;)
result = sess.run(&ldquo;v4:0&rdquo;, feed_dict={&ldquo;v1:0&rdquo;: 12.0, &ldquo;v2:0&rdquo;: 3.3})
print(result)
```</p>

<h4>Args:</h4>

<ul>
<li><b><code>meta_graph_or_file</code></b>: <code>MetaGraphDef</code> protocol buffer or filename (including
the path) containing a <code>MetaGraphDef</code>.</li>
<li><b><code>clear_devices</code></b>: Whether or not to clear the device field for an <code>Operation</code>
or <code>Tensor</code> during import.</li>
<li><b><code>import_scope</code></b>: Optional <code>string</code>. Name scope to add. Only used when
initializing from protocol buffer.</li>
<li><b><code>**kwargs</code></b>: Optional keyed arguments.</li>
</ul>


<h4>Returns:</h4>

<p>A saver constructed from <code>saver_def</code> in <code>MetaGraphDef</code> or None.</p>

<p>A None value is returned if no variables exist in the <code>MetaGraphDef</code>
(i.e., there are no variables to restore).</p>

<h4>Raises:</h4>

<ul>
<li><b><code>RuntimeError</code></b>: If called with eager execution enabled.</li>
</ul>


<h4>Eager Compatibility</h4>

<p>Exporting/importing meta graphs is not supported. No graph exists when eager
execution is enabled.</p>
