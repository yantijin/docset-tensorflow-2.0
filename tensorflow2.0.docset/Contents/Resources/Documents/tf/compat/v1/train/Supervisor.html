<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.compat.v1.train.Supervisor" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="coord"/>
<meta itemprop="property" content="global_step"/>
<meta itemprop="property" content="init_feed_dict"/>
<meta itemprop="property" content="init_op"/>
<meta itemprop="property" content="is_chief"/>
<meta itemprop="property" content="ready_for_local_init_op"/>
<meta itemprop="property" content="ready_op"/>
<meta itemprop="property" content="save_model_secs"/>
<meta itemprop="property" content="save_path"/>
<meta itemprop="property" content="save_summaries_secs"/>
<meta itemprop="property" content="saver"/>
<meta itemprop="property" content="session_manager"/>
<meta itemprop="property" content="summary_op"/>
<meta itemprop="property" content="summary_writer"/>
<meta itemprop="property" content="Loop"/>
<meta itemprop="property" content="PrepareSession"/>
<meta itemprop="property" content="RequestStop"/>
<meta itemprop="property" content="ShouldStop"/>
<meta itemprop="property" content="StartQueueRunners"/>
<meta itemprop="property" content="StartStandardServices"/>
<meta itemprop="property" content="Stop"/>
<meta itemprop="property" content="StopOnException"/>
<meta itemprop="property" content="SummaryComputed"/>
<meta itemprop="property" content="WaitForStop"/>
<meta itemprop="property" content="__init__"/>
<meta itemprop="property" content="loop"/>
<meta itemprop="property" content="managed_session"/>
<meta itemprop="property" content="prepare_or_wait_for_session"/>
<meta itemprop="property" content="request_stop"/>
<meta itemprop="property" content="should_stop"/>
<meta itemprop="property" content="start_queue_runners"/>
<meta itemprop="property" content="start_standard_services"/>
<meta itemprop="property" content="stop"/>
<meta itemprop="property" content="stop_on_exception"/>
<meta itemprop="property" content="summary_computed"/>
<meta itemprop="property" content="wait_for_stop"/>
<meta itemprop="property" content="USE_DEFAULT"/>
</div>


<h1>tf.compat.v1.train.Supervisor</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/supervisor.py">View source</a></p>

<h2>Class <code>Supervisor</code></h2>

<!-- Start diff -->


<p>A training helper that checkpoints models and computes summaries.</p>

<!-- Placeholder for "Used in" -->


<p>This class is deprecated. Please use
<a href="../../../../tf/compat/v1/train/MonitoredTrainingSession.html"><code>tf.compat.v1.train.MonitoredTrainingSession</code></a> instead.</p>

<p>The Supervisor is a small wrapper around a <code>Coordinator</code>, a <code>Saver</code>,
and a <code>SessionManager</code> that takes care of common needs of TensorFlow
training programs.</p>

<h4>Use for a single program</h4>

<p><code>python
with tf.Graph().as_default():
  ...add operations to the graph...
  # Create a Supervisor that will checkpoint the model in '/tmp/mydir'.
  sv = Supervisor(logdir='/tmp/mydir')
  # Get a TensorFlow session managed by the supervisor.
  with sv.managed_session(FLAGS.master) as sess:
    # Use the session to train the graph.
    while not sv.should_stop():
      sess.run(&lt;my_train_op&gt;)
</code></p>

<p>Within the <code>with sv.managed_session()</code> block all variables in the graph have
been initialized.  In addition, a few services have been started to
checkpoint the model and add summaries to the event log.</p>

<p>If the program crashes and is restarted, the managed session automatically
reinitialize variables from the most recent checkpoint.</p>

<p>The supervisor is notified of any exception raised by one of the services.
After an exception is raised, <code>should_stop()</code> returns <code>True</code>.  In that case
the training loop should also stop.  This is why the training loop has to
check for <code>sv.should_stop()</code>.</p>

<p>Exceptions that indicate that the training inputs have been exhausted,
<a href="../../../../tf/errors/OutOfRangeError.html"><code>tf.errors.OutOfRangeError</code></a>, also cause <code>sv.should_stop()</code> to return <code>True</code>
but are not re-raised from the <code>with</code> block: they indicate a normal
termination.</p>

<h4>Use for multiple replicas</h4>

<p>To train with replicas you deploy the same program in a <code>Cluster</code>.
One of the tasks must be identified as the <em>chief</em>: the task that handles
initialization, checkpoints, summaries, and recovery.  The other tasks
depend on the <em>chief</em> for these services.</p>

<p>The only change you have to do to the single program code is to indicate
if the program is running as the <em>chief</em>.</p>

<p>```python</p>

<h1>Choose a task as the chief. This could be based on server_def.task_index,</h1>

<h1>or job_def.name, or job_def.tasks. It&rsquo;s entirely up to the end user.</h1>

<h1>But there can be only one <em>chief</em>.</h1>

<p>is_chief = (server_def.task_index == 0)
server = tf.distribute.Server(server_def)</p>

<p>with tf.Graph().as_default():
  &hellip;add operations to the graph&hellip;
  # Create a Supervisor that uses log directory on a shared file system.
  # Indicate if you are the &lsquo;chief&rsquo;
  sv = Supervisor(logdir=&lsquo;/shared_directory/&hellip;&rsquo;, is_chief=is_chief)
  # Get a Session in a TensorFlow server on the cluster.
  with sv.managed_session(server.target) as sess:
    # Use the session to train the graph.
    while not sv.should_stop():
      sess.run(&lt;my_train_op>)
```</p>

<p>In the <em>chief</em> task, the <code>Supervisor</code> works exactly as in the first example
above.  In the other tasks <code>sv.managed_session()</code> waits for the Model to have
been initialized before returning a session to the training code.  The
non-chief tasks depend on the chief task for initializing the model.</p>

<p>If one of the tasks crashes and restarts, <code>managed_session()</code>
checks if the Model is initialized.  If yes, it just creates a session and
returns it to the training code that proceeds normally.  If the model needs
to be initialized, the chief task takes care of reinitializing it; the other
tasks just wait for the model to have been initialized.</p>

<p>NOTE: This modified program still works fine as a single program.
The single program marks itself as the chief.</p>

<h4>What <code>master</code> string to use</h4>

<p>Whether you are running on your machine or in the cluster you can use the
following values for the &ndash;master flag:</p>

<ul>
<li><p>Specifying <code>''</code> requests an in-process session that does not use RPC.</p></li>
<li><p>Specifying <code>'local'</code> requests a session that uses the RPC-based
&ldquo;Master interface&rdquo; to run TensorFlow programs. See
<code>tf.train.Server.create_local_server</code> for
details.</p></li>
<li><p>Specifying <code>'grpc://hostname:port'</code> requests a session that uses
the RPC interface to a specific host, and also allows the in-process
master to access remote tensorflow workers. Often, it is
appropriate to pass <code>server.target</code> (for some <a href="../../../../tf/distribute/Server.html"><code>tf.distribute.Server</code></a>
named `server).</p></li>
</ul>


<h4>Advanced use</h4>

<h5>Launching additional services</h5>

<p><code>managed_session()</code> launches the Checkpoint and Summary services (threads).
If you need more services to run you can simply launch them in the block
controlled by <code>managed_session()</code>.</p>

<p>Example: Start a thread to print losses.  We want this thread to run
every 60 seconds, so we launch it with <code>sv.loop()</code>.</p>

<p><code>python
...
sv = Supervisor(logdir='/tmp/mydir')
with sv.managed_session(FLAGS.master) as sess:
  sv.loop(60, print_loss, (sess, ))
  while not sv.should_stop():
    sess.run(my_train_op)
</code></p>

<h5>Launching fewer services</h5>

<p><code>managed_session()</code> launches the &ldquo;summary&rdquo; and &ldquo;checkpoint&rdquo; threads which use
either the optionally <code>summary_op</code> and <code>saver</code> passed to the constructor, or
default ones created automatically by the supervisor.  If you want to run
your own summary and checkpointing logic, disable these services by passing
<code>None</code> to the <code>summary_op</code> and <code>saver</code> parameters.</p>

<p>Example: Create summaries manually every 100 steps in the chief.</p>

<p>```python</p>

<h1>Create a Supervisor with no automatic summaries.</h1>

<p>sv = Supervisor(logdir=&lsquo;/tmp/mydir&rsquo;, is_chief=is_chief, summary_op=None)</p>

<h1>As summary_op was None, managed_session() does not start the</h1>

<h1>summary thread.</h1>

<p>with sv.managed_session(FLAGS.master) as sess:
  for step in xrange(1000000):
    if sv.should_stop():
      break
    if is_chief and step % 100 == 0:
      # Create the summary every 100 chief steps.
      sv.summary_computed(sess, sess.run(my_summary_op))
    else:
      # Train normally
      sess.run(my_train_op)
```</p>

<h5>Custom model initialization</h5>

<p><code>managed_session()</code> only supports initializing the model by running an
<code>init_op</code> or restoring from the latest checkpoint.  If you have special
initialization needs, see how to specify a <code>local_init_op</code> when creating the
supervisor.  You can also use the <code>SessionManager</code> directly to create a
session and check if it could be initialized automatically.</p>

<h2 id="__init__"><code>__init__</code></h2>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/supervisor.py">View source</a></p>

<p><code>python
__init__(
    graph=None,
    ready_op=USE_DEFAULT,
    ready_for_local_init_op=USE_DEFAULT,
    is_chief=True,
    init_op=USE_DEFAULT,
    init_feed_dict=None,
    local_init_op=USE_DEFAULT,
    logdir=None,
    summary_op=USE_DEFAULT,
    saver=USE_DEFAULT,
    global_step=USE_DEFAULT,
    save_summaries_secs=120,
    save_model_secs=600,
    recovery_wait_secs=30,
    stop_grace_secs=120,
    checkpoint_basename='model.ckpt',
    session_manager=None,
    summary_writer=USE_DEFAULT,
    init_fn=None,
    local_init_run_options=None
)
</code></p>

<p>Create a <code>Supervisor</code>. (deprecated)</p>

<p>Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession</p>

<h4>Args:</h4>

<ul>
<li><b><code>graph</code></b>: A <code>Graph</code>.  The graph that the model will use.  Defaults to the
default <code>Graph</code>.  The supervisor may add operations to the graph before
creating a session, but the graph should not be modified by the caller
after passing it to the supervisor.</li>
<li><b><code>ready_op</code></b>: 1-D string <code>Tensor</code>.  This tensor is evaluated by supervisors in
<code>prepare_or_wait_for_session()</code> to check if the model is ready to use.
The model is considered ready if it returns an empty array.  Defaults to
the tensor returned from <a href="../../../../tf/compat/v1/report_uninitialized_variables.html"><code>tf.compat.v1.report_uninitialized_variables()</code></a>
If <code>None</code>, the model is not checked for readiness.</li>
<li><b><code>ready_for_local_init_op</code></b>: 1-D string <code>Tensor</code>.  This tensor is evaluated by
supervisors in <code>prepare_or_wait_for_session()</code> to check if the model is
ready to run the local_init_op. The model is considered ready if it
returns an empty array. Defaults to <code>None</code>. If <code>None</code>, the model is not
checked for readiness before running local_init_op.</li>
<li><b><code>is_chief</code></b>: If True, create a chief supervisor in charge of initializing and
restoring the model.  If False, create a supervisor that relies on a
chief supervisor for inits and restore.</li>
<li><b><code>init_op</code></b>: <code>Operation</code>.  Used by chief supervisors to initialize the model
when it can not be recovered.  Defaults to an <code>Operation</code> that
initializes all global variables.  If <code>None</code>, no initialization is done
automatically unless you pass a value for <code>init_fn</code>, see below.</li>
<li><b><code>init_feed_dict</code></b>: A dictionary that maps <code>Tensor</code> objects to feed values.
This feed dictionary will be used when <code>init_op</code> is evaluated.</li>
<li><b><code>local_init_op</code></b>: <code>Operation</code>. Used by all supervisors to run initializations
that should run for every new supervisor instance. By default these are
table initializers and initializers for local variables. If <code>None</code>, no
further per supervisor-instance initialization is done automatically.</li>
<li><b><code>logdir</code></b>: A string.  Optional path to a directory where to checkpoint the
model and log events for the visualizer.  Used by chief supervisors. The
directory will be created if it does not exist.</li>
<li><b><code>summary_op</code></b>: An <code>Operation</code> that returns a Summary for the event logs. Used
by chief supervisors if a <code>logdir</code> was specified.  Defaults to the
operation returned from summary.merge_all().  If <code>None</code>, summaries are
not computed automatically.</li>
<li><b><code>saver</code></b>: A Saver object.  Used by chief supervisors if a <code>logdir</code> was
specified.  Defaults to the saved returned by Saver(). If <code>None</code>, the
model is not saved automatically.</li>
<li><b><code>global_step</code></b>: An integer Tensor of size 1 that counts steps.  The value
from &lsquo;global_step&rsquo; is used in summaries and checkpoint filenames.
Default to the op named &lsquo;global_step&rsquo; in the graph if it exists, is of
rank 1, size 1, and of type tf.int32 or tf.int64.  If <code>None</code> the global
step is not recorded in summaries and checkpoint files.  Used by chief
supervisors if a <code>logdir</code> was specified.</li>
<li><b><code>save_summaries_secs</code></b>: Number of seconds between the computation of
summaries for the event log.  Defaults to 120 seconds.  Pass 0 to
disable summaries.</li>
<li><b><code>save_model_secs</code></b>: Number of seconds between the creation of model
checkpoints.  Defaults to 600 seconds.  Pass 0 to disable checkpoints.</li>
<li><b><code>recovery_wait_secs</code></b>: Number of seconds between checks that the model is
ready.  Used by supervisors when waiting for a chief supervisor to
initialize or restore the model.  Defaults to 30 seconds.</li>
<li><b><code>stop_grace_secs</code></b>: Grace period, in seconds, given to running threads to
stop when <code>stop()</code> is called.  Defaults to 120 seconds.</li>
<li><b><code>checkpoint_basename</code></b>: The basename for checkpoint saving.</li>
<li><b><code>session_manager</code></b>: <code>SessionManager</code>, which manages Session creation and
recovery. If it is <code>None</code>, a default <code>SessionManager</code> will be created
with the set of arguments passed in for backwards compatibility.</li>
<li><b><code>summary_writer</code></b>: <code>SummaryWriter</code> to use or <code>USE_DEFAULT</code>.  Can be <code>None</code> to
indicate that no summaries should be written.</li>
<li><b><code>init_fn</code></b>: Optional callable used to initialize the model. Called after the
optional <code>init_op</code> is called.  The callable must accept one argument,
the session being initialized.</li>
<li><b><code>local_init_run_options</code></b>: RunOptions to be passed as the SessionManager
local_init_run_options parameter.</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Supervisor</code>.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>RuntimeError</code></b>: If called with eager execution enabled.</li>
</ul>


<h4>Eager Compatibility</h4>

<p><code>Supervisor</code>s are not supported when eager execution is enabled.</p>

<h2>Properties</h2>

<h3 id="coord"><code>coord</code></h3>


<p>Return the Coordinator used by the Supervisor.</p>

<p>The Coordinator can be useful if you want to run multiple threads
during your training.</p>

<h4>Returns:</h4>

<p>A Coordinator object.</p>

<h3 id="global_step"><code>global_step</code></h3>


<p>Return the global_step Tensor used by the supervisor.</p>

<h4>Returns:</h4>

<p>An integer Tensor for the global_step.</p>

<h3 id="init_feed_dict"><code>init_feed_dict</code></h3>


<p>Return the feed dictionary used when evaluating the <code>init_op</code>.</p>

<h4>Returns:</h4>

<p>A feed dictionary or <code>None</code>.</p>

<h3 id="init_op"><code>init_op</code></h3>


<p>Return the Init Op used by the supervisor.</p>

<h4>Returns:</h4>

<p>An Op or <code>None</code>.</p>

<h3 id="is_chief"><code>is_chief</code></h3>


<p>Return True if this is a chief supervisor.</p>

<h4>Returns:</h4>

<p>A bool.</p>

<h3 id="ready_for_local_init_op"><code>ready_for_local_init_op</code></h3>




<h3 id="ready_op"><code>ready_op</code></h3>


<p>Return the Ready Op used by the supervisor.</p>

<h4>Returns:</h4>

<p>An Op or <code>None</code>.</p>

<h3 id="save_model_secs"><code>save_model_secs</code></h3>


<p>Return the delay between checkpoints.</p>

<h4>Returns:</h4>

<p>A timestamp.</p>

<h3 id="save_path"><code>save_path</code></h3>


<p>Return the save path used by the supervisor.</p>

<h4>Returns:</h4>

<p>A string.</p>

<h3 id="save_summaries_secs"><code>save_summaries_secs</code></h3>


<p>Return the delay between summary computations.</p>

<h4>Returns:</h4>

<p>A timestamp.</p>

<h3 id="saver"><code>saver</code></h3>


<p>Return the Saver used by the supervisor.</p>

<h4>Returns:</h4>

<p>A Saver object.</p>

<h3 id="session_manager"><code>session_manager</code></h3>


<p>Return the SessionManager used by the Supervisor.</p>

<h4>Returns:</h4>

<p>A SessionManager object.</p>

<h3 id="summary_op"><code>summary_op</code></h3>


<p>Return the Summary Tensor used by the chief supervisor.</p>

<h4>Returns:</h4>

<p>A string Tensor for the summary or <code>None</code>.</p>

<h3 id="summary_writer"><code>summary_writer</code></h3>


<p>Return the SummaryWriter used by the chief supervisor.</p>

<h4>Returns:</h4>

<p>A SummaryWriter.</p>

<h2>Methods</h2>

<h3 id="Loop"><code>Loop</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/supervisor.py">View source</a></p>

<p><code>python
Loop(
    timer_interval_secs,
    target,
    args=None,
    kwargs=None
)
</code></p>

<p>Start a LooperThread that calls a function periodically.</p>

<p>If <code>timer_interval_secs</code> is None the thread calls <code>target(*args, **kwargs)</code>
repeatedly.  Otherwise it calls it every <code>timer_interval_secs</code>
seconds.  The thread terminates when a stop is requested.</p>

<p>The started thread is added to the list of threads managed by the supervisor
so it does not need to be passed to the <code>stop()</code> method.</p>

<h4>Args:</h4>

<ul>
<li><b><code>timer_interval_secs</code></b>: Number. Time boundaries at which to call <code>target</code>.</li>
<li><b><code>target</code></b>: A callable object.</li>
<li><b><code>args</code></b>: Optional arguments to pass to <code>target</code> when calling it.</li>
<li><b><code>kwargs</code></b>: Optional keyword arguments to pass to <code>target</code> when calling it.</li>
</ul>


<h4>Returns:</h4>

<p>The started thread.</p>

<h3 id="PrepareSession"><code>PrepareSession</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/supervisor.py">View source</a></p>

<p><code>python
PrepareSession(
    master='',
    config=None,
    wait_for_checkpoint=False,
    max_wait_secs=7200,
    start_standard_services=True
)
</code></p>

<p>Make sure the model is ready to be used.</p>

<p>Create a session on &lsquo;master&rsquo;, recovering or initializing the model as
needed, or wait for a session to be ready.  If running as the chief
and <code>start_standard_service</code> is set to True, also call the session
manager to start the standard services.</p>

<h4>Args:</h4>

<ul>
<li><b><code>master</code></b>: name of the TensorFlow master to use.  See the
<a href="../../../../tf/compat/v1/Session.html"><code>tf.compat.v1.Session</code></a> constructor for how this is interpreted.</li>
<li><b><code>config</code></b>: Optional ConfigProto proto used to configure the session, which is
passed as-is to create the session.</li>
<li><b><code>wait_for_checkpoint</code></b>: Whether we should wait for the availability of a
checkpoint before creating Session. Defaults to False.</li>
<li><b><code>max_wait_secs</code></b>: Maximum time to wait for the session to become available.</li>
<li><b><code>start_standard_services</code></b>: Whether to start the standard services and the
queue runners.</li>
</ul>


<h4>Returns:</h4>

<p>A Session object that can be used to drive the model.</p>

<h3 id="RequestStop"><code>RequestStop</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/supervisor.py">View source</a></p>

<p><code>python
RequestStop(ex=None)
</code></p>

<p>Request that the coordinator stop the threads.</p>

<p>See <code>Coordinator.request_stop()</code>.</p>

<h4>Args:</h4>

<ul>
<li><b><code>ex</code></b>: Optional <code>Exception</code>, or Python <code>exc_info</code> tuple as returned by
<code>sys.exc_info()</code>.  If this is the first call to <code>request_stop()</code> the
corresponding exception is recorded and re-raised from <code>join()</code>.</li>
</ul>


<h3 id="ShouldStop"><code>ShouldStop</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/supervisor.py">View source</a></p>

<p><code>python
ShouldStop()
</code></p>

<p>Check if the coordinator was told to stop.</p>

<p>See <code>Coordinator.should_stop()</code>.</p>

<h4>Returns:</h4>

<p>True if the coordinator was told to stop, False otherwise.</p>

<h3 id="StartQueueRunners"><code>StartQueueRunners</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/supervisor.py">View source</a></p>

<p><code>python
StartQueueRunners(
    sess,
    queue_runners=None
)
</code></p>

<p>Start threads for <code>QueueRunners</code>.</p>

<p>Note that the queue runners collected in the graph key <code>QUEUE_RUNNERS</code>
are already started automatically when you create a session with the
supervisor, so unless you have non-collected queue runners to start
you do not need to call this explicitly.</p>

<h4>Args:</h4>

<ul>
<li><b><code>sess</code></b>: A <code>Session</code>.</li>
<li><b><code>queue_runners</code></b>: A list of <code>QueueRunners</code>. If not specified, we&rsquo;ll use the
list of queue runners gathered in the graph under the key
<code>GraphKeys.QUEUE_RUNNERS</code>.</li>
</ul>


<h4>Returns:</h4>

<p>The list of threads started for the <code>QueueRunners</code>.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>RuntimeError</code></b>: If called with eager execution enabled.</li>
</ul>


<h4>Eager Compatibility</h4>

<p>Queues are not compatible with eager execution. To ingest data when eager
execution is enabled, use the <a href="../../../../tf/data.html"><code>tf.data</code></a> API.</p>

<h3 id="StartStandardServices"><code>StartStandardServices</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/supervisor.py">View source</a></p>

<p><code>python
StartStandardServices(sess)
</code></p>

<p>Start the standard services for &lsquo;sess&rsquo;.</p>

<p>This starts services in the background.  The services started depend
on the parameters to the constructor and may include:</p>

<ul>
<li>A Summary thread computing summaries every save_summaries_secs.</li>
<li>A Checkpoint thread saving the model every save_model_secs.</li>
<li>A StepCounter thread measure step time.</li>
</ul>


<h4>Args:</h4>

<ul>
<li><b><code>sess</code></b>: A Session.</li>
</ul>


<h4>Returns:</h4>

<p>A list of threads that are running the standard services.  You can use
the Supervisor&rsquo;s Coordinator to join these threads with:
  sv.coord.Join(<list of threads>)</p>

<h4>Raises:</h4>

<ul>
<li><b><code>RuntimeError</code></b>: If called with a non-chief Supervisor.</li>
<li><b><code>ValueError</code></b>: If not <code>logdir</code> was passed to the constructor as the
services need a log directory.</li>
</ul>


<h3 id="Stop"><code>Stop</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/supervisor.py">View source</a></p>

<p><code>python
Stop(
    threads=None,
    close_summary_writer=True,
    ignore_live_threads=False
)
</code></p>

<p>Stop the services and the coordinator.</p>

<p>This does not close the session.</p>

<h4>Args:</h4>

<ul>
<li><b><code>threads</code></b>: Optional list of threads to join with the coordinator.  If
<code>None</code>, defaults to the threads running the standard services, the
threads started for <code>QueueRunners</code>, and the threads started by the
<code>loop()</code> method.  To wait on additional threads, pass the list in this
parameter.</li>
<li><b><code>close_summary_writer</code></b>: Whether to close the <code>summary_writer</code>.  Defaults to
<code>True</code> if the summary writer was created by the supervisor, <code>False</code>
otherwise.</li>
<li><b><code>ignore_live_threads</code></b>: If <code>True</code> ignores threads that remain running after a
grace period when joining threads via the coordinator, instead of
raising a RuntimeError.</li>
</ul>


<h3 id="StopOnException"><code>StopOnException</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/supervisor.py">View source</a></p>

<p><code>python
StopOnException()
</code></p>

<p>Context handler to stop the supervisor when an exception is raised.</p>

<p>See <code>Coordinator.stop_on_exception()</code>.</p>

<h4>Returns:</h4>

<p>A context handler.</p>

<h3 id="SummaryComputed"><code>SummaryComputed</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/supervisor.py">View source</a></p>

<p><code>python
SummaryComputed(
    sess,
    summary,
    global_step=None
)
</code></p>

<p>Indicate that a summary was computed.</p>

<h4>Args:</h4>

<ul>
<li><b><code>sess</code></b>: A <code>Session</code> object.</li>
<li><b><code>summary</code></b>: A Summary proto, or a string holding a serialized summary proto.</li>
<li><b><code>global_step</code></b>: Int. global step this summary is associated with. If <code>None</code>,
it will try to fetch the current step.</li>
</ul>


<h4>Raises:</h4>

<ul>
<li><b><code>TypeError</code></b>: if &lsquo;summary&rsquo; is not a Summary proto or a string.</li>
<li><b><code>RuntimeError</code></b>: if the Supervisor was created without a <code>logdir</code>.</li>
</ul>


<h3 id="WaitForStop"><code>WaitForStop</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/supervisor.py">View source</a></p>

<p><code>python
WaitForStop()
</code></p>

<p>Block waiting for the coordinator to stop.</p>

<h3 id="loop"><code>loop</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/supervisor.py">View source</a></p>

<p><code>python
loop(
    timer_interval_secs,
    target,
    args=None,
    kwargs=None
)
</code></p>

<p>Start a LooperThread that calls a function periodically.</p>

<p>If <code>timer_interval_secs</code> is None the thread calls <code>target(*args, **kwargs)</code>
repeatedly.  Otherwise it calls it every <code>timer_interval_secs</code>
seconds.  The thread terminates when a stop is requested.</p>

<p>The started thread is added to the list of threads managed by the supervisor
so it does not need to be passed to the <code>stop()</code> method.</p>

<h4>Args:</h4>

<ul>
<li><b><code>timer_interval_secs</code></b>: Number. Time boundaries at which to call <code>target</code>.</li>
<li><b><code>target</code></b>: A callable object.</li>
<li><b><code>args</code></b>: Optional arguments to pass to <code>target</code> when calling it.</li>
<li><b><code>kwargs</code></b>: Optional keyword arguments to pass to <code>target</code> when calling it.</li>
</ul>


<h4>Returns:</h4>

<p>The started thread.</p>

<h3 id="managed_session"><code>managed_session</code></h3>


<p><code>python
managed_session(
    *args,
    **kwds
)
</code></p>

<p>Returns a context manager for a managed session.</p>

<p>This context manager creates and automatically recovers a session.  It
optionally starts the standard services that handle checkpoints and
summaries.  It monitors exceptions raised from the <code>with</code> block or from the
services and stops the supervisor as needed.</p>

<p>The context manager is typically used as follows:</p>

<p><code>python
def train():
  sv = tf.compat.v1.train.Supervisor(...)
  with sv.managed_session(&lt;master&gt;) as sess:
    for step in xrange(..):
      if sv.should_stop():
        break
      sess.run(&lt;my training op&gt;)
      ...do other things needed at each training step...
</code></p>

<p>An exception raised from the <code>with</code> block or one of the service threads is
raised again when the block exits.  This is done after stopping all threads
and closing the session.  For example, an <code>AbortedError</code> exception, raised
in case of preemption of one of the workers in a distributed model, is
raised again when the block exits.</p>

<p>If you want to retry the training loop in case of preemption you can do it
as follows:</p>

<p><code>python
def main(...):
  while True
    try:
      train()
    except tf.errors.Aborted:
      pass
</code></p>

<p>As a special case, exceptions used for control flow, such as
<code>OutOfRangeError</code> which reports that input queues are exhausted, are not
raised again from the <code>with</code> block: they indicate a clean termination of
the training loop and are considered normal termination.</p>

<h4>Args:</h4>

<ul>
<li><b><code>master</code></b>: name of the TensorFlow master to use.  See the
<a href="../../../../tf/compat/v1/Session.html"><code>tf.compat.v1.Session</code></a> constructor for how this is interpreted.</li>
<li><b><code>config</code></b>: Optional <code>ConfigProto</code> proto used to configure the session. Passed
as-is to create the session.</li>
<li><b><code>start_standard_services</code></b>: Whether to start the standard services, such as
checkpoint, summary and step counter.</li>
<li><b><code>close_summary_writer</code></b>: Whether to close the summary writer when closing the
session.  Defaults to True.</li>
</ul>


<h4>Returns:</h4>

<p>A context manager that yields a <code>Session</code> restored from the latest
checkpoint or initialized from scratch if not checkpoint exists.  The
session is closed when the <code>with</code> block exits.</p>

<h3 id="prepare_or_wait_for_session"><code>prepare_or_wait_for_session</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/supervisor.py">View source</a></p>

<p><code>python
prepare_or_wait_for_session(
    master='',
    config=None,
    wait_for_checkpoint=False,
    max_wait_secs=7200,
    start_standard_services=True
)
</code></p>

<p>Make sure the model is ready to be used.</p>

<p>Create a session on &lsquo;master&rsquo;, recovering or initializing the model as
needed, or wait for a session to be ready.  If running as the chief
and <code>start_standard_service</code> is set to True, also call the session
manager to start the standard services.</p>

<h4>Args:</h4>

<ul>
<li><b><code>master</code></b>: name of the TensorFlow master to use.  See the
<a href="../../../../tf/compat/v1/Session.html"><code>tf.compat.v1.Session</code></a> constructor for how this is interpreted.</li>
<li><b><code>config</code></b>: Optional ConfigProto proto used to configure the session, which is
passed as-is to create the session.</li>
<li><b><code>wait_for_checkpoint</code></b>: Whether we should wait for the availability of a
checkpoint before creating Session. Defaults to False.</li>
<li><b><code>max_wait_secs</code></b>: Maximum time to wait for the session to become available.</li>
<li><b><code>start_standard_services</code></b>: Whether to start the standard services and the
queue runners.</li>
</ul>


<h4>Returns:</h4>

<p>A Session object that can be used to drive the model.</p>

<h3 id="request_stop"><code>request_stop</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/supervisor.py">View source</a></p>

<p><code>python
request_stop(ex=None)
</code></p>

<p>Request that the coordinator stop the threads.</p>

<p>See <code>Coordinator.request_stop()</code>.</p>

<h4>Args:</h4>

<ul>
<li><b><code>ex</code></b>: Optional <code>Exception</code>, or Python <code>exc_info</code> tuple as returned by
<code>sys.exc_info()</code>.  If this is the first call to <code>request_stop()</code> the
corresponding exception is recorded and re-raised from <code>join()</code>.</li>
</ul>


<h3 id="should_stop"><code>should_stop</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/supervisor.py">View source</a></p>

<p><code>python
should_stop()
</code></p>

<p>Check if the coordinator was told to stop.</p>

<p>See <code>Coordinator.should_stop()</code>.</p>

<h4>Returns:</h4>

<p>True if the coordinator was told to stop, False otherwise.</p>

<h3 id="start_queue_runners"><code>start_queue_runners</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/supervisor.py">View source</a></p>

<p><code>python
start_queue_runners(
    sess,
    queue_runners=None
)
</code></p>

<p>Start threads for <code>QueueRunners</code>.</p>

<p>Note that the queue runners collected in the graph key <code>QUEUE_RUNNERS</code>
are already started automatically when you create a session with the
supervisor, so unless you have non-collected queue runners to start
you do not need to call this explicitly.</p>

<h4>Args:</h4>

<ul>
<li><b><code>sess</code></b>: A <code>Session</code>.</li>
<li><b><code>queue_runners</code></b>: A list of <code>QueueRunners</code>. If not specified, we&rsquo;ll use the
list of queue runners gathered in the graph under the key
<code>GraphKeys.QUEUE_RUNNERS</code>.</li>
</ul>


<h4>Returns:</h4>

<p>The list of threads started for the <code>QueueRunners</code>.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>RuntimeError</code></b>: If called with eager execution enabled.</li>
</ul>


<h4>Eager Compatibility</h4>

<p>Queues are not compatible with eager execution. To ingest data when eager
execution is enabled, use the <a href="../../../../tf/data.html"><code>tf.data</code></a> API.</p>

<h3 id="start_standard_services"><code>start_standard_services</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/supervisor.py">View source</a></p>

<p><code>python
start_standard_services(sess)
</code></p>

<p>Start the standard services for &lsquo;sess&rsquo;.</p>

<p>This starts services in the background.  The services started depend
on the parameters to the constructor and may include:</p>

<ul>
<li>A Summary thread computing summaries every save_summaries_secs.</li>
<li>A Checkpoint thread saving the model every save_model_secs.</li>
<li>A StepCounter thread measure step time.</li>
</ul>


<h4>Args:</h4>

<ul>
<li><b><code>sess</code></b>: A Session.</li>
</ul>


<h4>Returns:</h4>

<p>A list of threads that are running the standard services.  You can use
the Supervisor&rsquo;s Coordinator to join these threads with:
  sv.coord.Join(<list of threads>)</p>

<h4>Raises:</h4>

<ul>
<li><b><code>RuntimeError</code></b>: If called with a non-chief Supervisor.</li>
<li><b><code>ValueError</code></b>: If not <code>logdir</code> was passed to the constructor as the
services need a log directory.</li>
</ul>


<h3 id="stop"><code>stop</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/supervisor.py">View source</a></p>

<p><code>python
stop(
    threads=None,
    close_summary_writer=True,
    ignore_live_threads=False
)
</code></p>

<p>Stop the services and the coordinator.</p>

<p>This does not close the session.</p>

<h4>Args:</h4>

<ul>
<li><b><code>threads</code></b>: Optional list of threads to join with the coordinator.  If
<code>None</code>, defaults to the threads running the standard services, the
threads started for <code>QueueRunners</code>, and the threads started by the
<code>loop()</code> method.  To wait on additional threads, pass the list in this
parameter.</li>
<li><b><code>close_summary_writer</code></b>: Whether to close the <code>summary_writer</code>.  Defaults to
<code>True</code> if the summary writer was created by the supervisor, <code>False</code>
otherwise.</li>
<li><b><code>ignore_live_threads</code></b>: If <code>True</code> ignores threads that remain running after a
grace period when joining threads via the coordinator, instead of
raising a RuntimeError.</li>
</ul>


<h3 id="stop_on_exception"><code>stop_on_exception</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/supervisor.py">View source</a></p>

<p><code>python
stop_on_exception()
</code></p>

<p>Context handler to stop the supervisor when an exception is raised.</p>

<p>See <code>Coordinator.stop_on_exception()</code>.</p>

<h4>Returns:</h4>

<p>A context handler.</p>

<h3 id="summary_computed"><code>summary_computed</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/supervisor.py">View source</a></p>

<p><code>python
summary_computed(
    sess,
    summary,
    global_step=None
)
</code></p>

<p>Indicate that a summary was computed.</p>

<h4>Args:</h4>

<ul>
<li><b><code>sess</code></b>: A <code>Session</code> object.</li>
<li><b><code>summary</code></b>: A Summary proto, or a string holding a serialized summary proto.</li>
<li><b><code>global_step</code></b>: Int. global step this summary is associated with. If <code>None</code>,
it will try to fetch the current step.</li>
</ul>


<h4>Raises:</h4>

<ul>
<li><b><code>TypeError</code></b>: if &lsquo;summary&rsquo; is not a Summary proto or a string.</li>
<li><b><code>RuntimeError</code></b>: if the Supervisor was created without a <code>logdir</code>.</li>
</ul>


<h3 id="wait_for_stop"><code>wait_for_stop</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/training/supervisor.py">View source</a></p>

<p><code>python
wait_for_stop()
</code></p>

<p>Block waiting for the coordinator to stop.</p>

<h2>Class Members</h2>

<ul>
<li><code>USE_DEFAULT = 0</code> <a id="USE_DEFAULT"></a></li>
</ul>

