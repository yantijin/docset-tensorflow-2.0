<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.compat.v1.nn" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="swish"/>
</div>


<h1>Module: tf.compat.v1.nn</h1>

<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p>Wrappers for primitive Neural Net (NN) Operations.</p>

<h2>Modules</h2>

<p><a href="../../../tf/compat/v1/nn/rnn_cell.html"><code>rnn_cell</code></a> module: Module for constructing RNN Cells.</p>

<h2>Functions</h2>

<p><a href="../../../tf/random/all_candidate_sampler.html"><code>all_candidate_sampler(...)</code></a>: Generate the set of all classes.</p>

<p><a href="../../../tf/nn/atrous_conv2d.html"><code>atrous_conv2d(...)</code></a>: Atrous convolution (a.k.a. convolution with holes or dilated convolution).</p>

<p><a href="../../../tf/nn/atrous_conv2d_transpose.html"><code>atrous_conv2d_transpose(...)</code></a>: The transpose of <code>atrous_conv2d</code>.</p>

<p><a href="../../../tf/compat/v1/nn/avg_pool.html"><code>avg_pool(...)</code></a>: Performs the average pooling on the input.</p>

<p><a href="../../../tf/nn/avg_pool1d.html"><code>avg_pool1d(...)</code></a>: Performs the average pooling on the input.</p>

<p><a href="../../../tf/compat/v1/nn/avg_pool.html"><code>avg_pool2d(...)</code></a>: Performs the average pooling on the input.</p>

<p><a href="../../../tf/nn/avg_pool3d.html"><code>avg_pool3d(...)</code></a>: Performs the average pooling on the input.</p>

<p><a href="../../../tf/nn/avg_pool.html"><code>avg_pool_v2(...)</code></a>: Performs the avg pooling on the input.</p>

<p><a href="../../../tf/compat/v1/nn/batch_norm_with_global_normalization.html"><code>batch_norm_with_global_normalization(...)</code></a>: Batch normalization.</p>

<p><a href="../../../tf/nn/batch_normalization.html"><code>batch_normalization(...)</code></a>: Batch normalization.</p>

<p><a href="../../../tf/nn/bias_add.html"><code>bias_add(...)</code></a>: Adds <code>bias</code> to <code>value</code>.</p>

<p><a href="../../../tf/compat/v1/nn/bidirectional_dynamic_rnn.html"><code>bidirectional_dynamic_rnn(...)</code></a>: Creates a dynamic version of bidirectional recurrent neural network. (deprecated)</p>

<p><a href="../../../tf/nn/collapse_repeated.html"><code>collapse_repeated(...)</code></a>: Merge repeated labels into single labels.</p>

<p><a href="../../../tf/nn/compute_accidental_hits.html"><code>compute_accidental_hits(...)</code></a>: Compute the position ids in <code>sampled_candidates</code> matching <code>true_classes</code>.</p>

<p><a href="../../../tf/nn/compute_average_loss.html"><code>compute_average_loss(...)</code></a>: Scales per-example losses with sample_weights and computes their average.</p>

<p><a href="../../../tf/compat/v1/nn/conv1d.html"><code>conv1d(...)</code></a>: Computes a 1-D convolution given 3-D input and filter tensors. (deprecated argument values) (deprecated argument values)</p>

<p><a href="../../../tf/nn/conv1d_transpose.html"><code>conv1d_transpose(...)</code></a>: The transpose of <code>conv1d</code>.</p>

<p><a href="../../../tf/compat/v1/nn/conv2d.html"><code>conv2d(...)</code></a>: Computes a 2-D convolution given 4-D <code>input</code> and <code>filter</code> tensors.</p>

<p><a href="../../../tf/compat/v1/nn/conv2d_backprop_filter.html"><code>conv2d_backprop_filter(...)</code></a>: Computes the gradients of convolution with respect to the filter.</p>

<p><a href="../../../tf/compat/v1/nn/conv2d_backprop_input.html"><code>conv2d_backprop_input(...)</code></a>: Computes the gradients of convolution with respect to the input.</p>

<p><a href="../../../tf/compat/v1/nn/conv2d_transpose.html"><code>conv2d_transpose(...)</code></a>: The transpose of <code>conv2d</code>.</p>

<p><a href="../../../tf/compat/v1/nn/conv3d.html"><code>conv3d(...)</code></a>: Computes a 3-D convolution given 5-D <code>input</code> and <code>filter</code> tensors.</p>

<p><a href="../../../tf/compat/v1/nn/conv3d_backprop_filter.html"><code>conv3d_backprop_filter(...)</code></a>: Computes the gradients of 3-D convolution with respect to the filter.</p>

<p><a href="../../../tf/compat/v1/nn/conv3d_backprop_filter.html"><code>conv3d_backprop_filter_v2(...)</code></a>: Computes the gradients of 3-D convolution with respect to the filter.</p>

<p><a href="../../../tf/compat/v1/nn/conv3d_transpose.html"><code>conv3d_transpose(...)</code></a>: The transpose of <code>conv3d</code>.</p>

<p><a href="../../../tf/nn/conv_transpose.html"><code>conv_transpose(...)</code></a>: The transpose of <code>convolution</code>.</p>

<p><a href="../../../tf/compat/v1/nn/convolution.html"><code>convolution(...)</code></a>: Computes sums of N-D convolutions (actually cross-correlation).</p>

<p><a href="../../../tf/compat/v1/nn/crelu.html"><code>crelu(...)</code></a>: Computes Concatenated ReLU.</p>

<p><a href="../../../tf/compat/v1/nn/ctc_beam_search_decoder.html"><code>ctc_beam_search_decoder(...)</code></a>: Performs beam search decoding on the logits given in input.</p>

<p><a href="../../../tf/nn/ctc_beam_search_decoder.html"><code>ctc_beam_search_decoder_v2(...)</code></a>: Performs beam search decoding on the logits given in input.</p>

<p><a href="../../../tf/nn/ctc_greedy_decoder.html"><code>ctc_greedy_decoder(...)</code></a>: Performs greedy decoding on the logits given in input (best path).</p>

<p><a href="../../../tf/compat/v1/nn/ctc_loss.html"><code>ctc_loss(...)</code></a>: Computes the CTC (Connectionist Temporal Classification) Loss.</p>

<p><a href="../../../tf/nn/ctc_loss.html"><code>ctc_loss_v2(...)</code></a>: Computes CTC (Connectionist Temporal Classification) loss.</p>

<p><a href="../../../tf/nn/ctc_unique_labels.html"><code>ctc_unique_labels(...)</code></a>: Get unique labels and indices for batched labels for <a href="../../../tf/nn/ctc_loss.html"><code>tf.nn.ctc_loss</code></a>.</p>

<p><a href="../../../tf/compat/v1/depth_to_space.html"><code>depth_to_space(...)</code></a>: DepthToSpace for tensors of type T.</p>

<p><a href="../../../tf/compat/v1/nn/depthwise_conv2d.html"><code>depthwise_conv2d(...)</code></a>: Depthwise 2-D convolution.</p>

<p><a href="../../../tf/nn/depthwise_conv2d_backprop_filter.html"><code>depthwise_conv2d_backprop_filter(...)</code></a>: Computes the gradients of depthwise convolution with respect to the filter.</p>

<p><a href="../../../tf/nn/depthwise_conv2d_backprop_input.html"><code>depthwise_conv2d_backprop_input(...)</code></a>: Computes the gradients of depthwise convolution with respect to the input.</p>

<p><a href="../../../tf/compat/v1/nn/depthwise_conv2d_native.html"><code>depthwise_conv2d_native(...)</code></a>: Computes a 2-D depthwise convolution given 4-D <code>input</code> and <code>filter</code> tensors.</p>

<p><a href="../../../tf/nn/depthwise_conv2d_backprop_filter.html"><code>depthwise_conv2d_native_backprop_filter(...)</code></a>: Computes the gradients of depthwise convolution with respect to the filter.</p>

<p><a href="../../../tf/nn/depthwise_conv2d_backprop_input.html"><code>depthwise_conv2d_native_backprop_input(...)</code></a>: Computes the gradients of depthwise convolution with respect to the input.</p>

<p><a href="../../../tf/compat/v1/nn/dilation2d.html"><code>dilation2d(...)</code></a>: Computes the grayscale dilation of 4-D <code>input</code> and 3-D <code>filter</code> tensors.</p>

<p><a href="../../../tf/compat/v1/nn/dropout.html"><code>dropout(...)</code></a>: Computes dropout. (deprecated arguments)</p>

<p><a href="../../../tf/compat/v1/nn/dynamic_rnn.html"><code>dynamic_rnn(...)</code></a>: Creates a recurrent neural network specified by RNNCell <code>cell</code>. (deprecated)</p>

<p><a href="../../../tf/nn/elu.html"><code>elu(...)</code></a>: Computes exponential linear: <code>exp(features) - 1</code> if &lt; 0, <code>features</code> otherwise.</p>

<p><a href="../../../tf/compat/v1/nn/embedding_lookup.html"><code>embedding_lookup(...)</code></a>: Looks up <code>ids</code> in a list of embedding tensors.</p>

<p><a href="../../../tf/compat/v1/nn/embedding_lookup_sparse.html"><code>embedding_lookup_sparse(...)</code></a>: Computes embeddings for the given ids and weights.</p>

<p><a href="../../../tf/compat/v1/nn/erosion2d.html"><code>erosion2d(...)</code></a>: Computes the grayscale erosion of 4-D <code>value</code> and 3-D <code>kernel</code> tensors.</p>

<p><a href="../../../tf/random/fixed_unigram_candidate_sampler.html"><code>fixed_unigram_candidate_sampler(...)</code></a>: Samples a set of classes using the provided (fixed) base distribution.</p>

<p><a href="../../../tf/compat/v1/nn/fractional_avg_pool.html"><code>fractional_avg_pool(...)</code></a>: Performs fractional average pooling on the input. (deprecated)</p>

<p><a href="../../../tf/compat/v1/nn/fractional_max_pool.html"><code>fractional_max_pool(...)</code></a>: Performs fractional max pooling on the input. (deprecated)</p>

<p><a href="../../../tf/compat/v1/nn/fused_batch_norm.html"><code>fused_batch_norm(...)</code></a>: Batch normalization.</p>

<p><a href="../../../tf/compat/v1/math/in_top_k.html"><code>in_top_k(...)</code></a>: Says whether the targets are in the top <code>K</code> predictions.</p>

<p><a href="../../../tf/nn/l2_loss.html"><code>l2_loss(...)</code></a>: L2 Loss.</p>

<p><a href="../../../tf/compat/v1/linalg/l2_normalize.html"><code>l2_normalize(...)</code></a>: Normalizes along dimension <code>axis</code> using an L2 norm. (deprecated arguments)</p>

<p><a href="../../../tf/nn/leaky_relu.html"><code>leaky_relu(...)</code></a>: Compute the Leaky ReLU activation function.</p>

<p><a href="../../../tf/random/learned_unigram_candidate_sampler.html"><code>learned_unigram_candidate_sampler(...)</code></a>: Samples a set of classes from a distribution learned during training.</p>

<p><a href="../../../tf/nn/local_response_normalization.html"><code>local_response_normalization(...)</code></a>: Local Response Normalization.</p>

<p><a href="../../../tf/nn/log_poisson_loss.html"><code>log_poisson_loss(...)</code></a>: Computes log Poisson loss given <code>log_input</code>.</p>

<p><a href="../../../tf/compat/v1/math/log_softmax.html"><code>log_softmax(...)</code></a>: Computes log softmax activations. (deprecated arguments)</p>

<p><a href="../../../tf/random/log_uniform_candidate_sampler.html"><code>log_uniform_candidate_sampler(...)</code></a>: Samples a set of classes using a log-uniform (Zipfian) base distribution.</p>

<p><a href="../../../tf/nn/local_response_normalization.html"><code>lrn(...)</code></a>: Local Response Normalization.</p>

<p><a href="../../../tf/compat/v1/nn/max_pool.html"><code>max_pool(...)</code></a>: Performs the max pooling on the input.</p>

<p><a href="../../../tf/nn/max_pool1d.html"><code>max_pool1d(...)</code></a>: Performs the max pooling on the input.</p>

<p><a href="../../../tf/nn/max_pool2d.html"><code>max_pool2d(...)</code></a>: Performs the max pooling on the input.</p>

<p><a href="../../../tf/nn/max_pool3d.html"><code>max_pool3d(...)</code></a>: Performs the max pooling on the input.</p>

<p><a href="../../../tf/nn/max_pool.html"><code>max_pool_v2(...)</code></a>: Performs the max pooling on the input.</p>

<p><a href="../../../tf/compat/v1/nn/max_pool_with_argmax.html"><code>max_pool_with_argmax(...)</code></a>: Performs max pooling on the input and outputs both max values and indices.</p>

<p><a href="../../../tf/compat/v1/nn/moments.html"><code>moments(...)</code></a>: Calculate the mean and variance of <code>x</code>.</p>

<p><a href="../../../tf/compat/v1/nn/nce_loss.html"><code>nce_loss(...)</code></a>: Computes and returns the noise-contrastive estimation training loss.</p>

<p><a href="../../../tf/nn/normalize_moments.html"><code>normalize_moments(...)</code></a>: Calculate the mean and variance of based on the sufficient statistics.</p>

<p><a href="../../../tf/compat/v1/nn/pool.html"><code>pool(...)</code></a>: Performs an N-D pooling operation.</p>

<p><a href="../../../tf/compat/v1/nn/quantized_avg_pool.html"><code>quantized_avg_pool(...)</code></a>: Produces the average pool of the input tensor for quantized types.</p>

<p><a href="../../../tf/compat/v1/nn/quantized_conv2d.html"><code>quantized_conv2d(...)</code></a>: Computes a 2D convolution given quantized 4D input and filter tensors.</p>

<p><a href="../../../tf/compat/v1/nn/quantized_max_pool.html"><code>quantized_max_pool(...)</code></a>: Produces the max pool of the input tensor for quantized types.</p>

<p><a href="../../../tf/compat/v1/nn/quantized_relu_x.html"><code>quantized_relu_x(...)</code></a>: Computes Quantized Rectified Linear X: <code>min(max(features, 0), max_value)</code></p>

<p><a href="../../../tf/compat/v1/nn/raw_rnn.html"><code>raw_rnn(...)</code></a>: Creates an <code>RNN</code> specified by RNNCell <code>cell</code> and loop function <code>loop_fn</code>.</p>

<p><a href="../../../tf/nn/relu.html"><code>relu(...)</code></a>: Computes rectified linear: <code>max(features, 0)</code>.</p>

<p><a href="../../../tf/nn/relu6.html"><code>relu6(...)</code></a>: Computes Rectified Linear 6: <code>min(max(features, 0), 6)</code>.</p>

<p><a href="../../../tf/compat/v1/nn/relu_layer.html"><code>relu_layer(...)</code></a>: Computes Relu(x * weight + biases).</p>

<p><a href="../../../tf/compat/v1/nn/safe_embedding_lookup_sparse.html"><code>safe_embedding_lookup_sparse(...)</code></a>: Lookup embedding results, accounting for invalid IDs and empty features.</p>

<p><a href="../../../tf/compat/v1/nn/sampled_softmax_loss.html"><code>sampled_softmax_loss(...)</code></a>: Computes and returns the sampled softmax training loss.</p>

<p><a href="../../../tf/nn/scale_regularization_loss.html"><code>scale_regularization_loss(...)</code></a>: Scales the sum of the given regularization losses by number of replicas.</p>

<p><a href="../../../tf/nn/selu.html"><code>selu(...)</code></a>: Computes scaled exponential linear: <code>scale * alpha * (exp(features) - 1)</code></p>

<p><a href="../../../tf/compat/v1/nn/separable_conv2d.html"><code>separable_conv2d(...)</code></a>: 2-D convolution with separable filters.</p>

<p><a href="../../../tf/math/sigmoid.html"><code>sigmoid(...)</code></a>: Computes sigmoid of <code>x</code> element-wise.</p>

<p><a href="../../../tf/compat/v1/nn/sigmoid_cross_entropy_with_logits.html"><code>sigmoid_cross_entropy_with_logits(...)</code></a>: Computes sigmoid cross entropy given <code>logits</code>.</p>

<p><a href="../../../tf/compat/v1/math/softmax.html"><code>softmax(...)</code></a>: Computes softmax activations. (deprecated arguments)</p>

<p><a href="../../../tf/compat/v1/nn/softmax_cross_entropy_with_logits.html"><code>softmax_cross_entropy_with_logits(...)</code></a>: Computes softmax cross entropy between <code>logits</code> and <code>labels</code>. (deprecated)</p>

<p><a href="../../../tf/compat/v1/nn/softmax_cross_entropy_with_logits_v2.html"><code>softmax_cross_entropy_with_logits_v2(...)</code></a>: Computes softmax cross entropy between <code>logits</code> and <code>labels</code>. (deprecated arguments)</p>

<p><a href="../../../tf/math/softplus.html"><code>softplus(...)</code></a>: Computes softplus: <code>log(exp(features) + 1)</code>.</p>

<p><a href="../../../tf/nn/softsign.html"><code>softsign(...)</code></a>: Computes softsign: <code>features / (abs(features) + 1)</code>.</p>

<p><a href="../../../tf/compat/v1/space_to_batch.html"><code>space_to_batch(...)</code></a>: SpaceToBatch for 4-D tensors of type T.</p>

<p><a href="../../../tf/compat/v1/space_to_depth.html"><code>space_to_depth(...)</code></a>: SpaceToDepth for tensors of type T.</p>

<p><a href="../../../tf/compat/v1/nn/sparse_softmax_cross_entropy_with_logits.html"><code>sparse_softmax_cross_entropy_with_logits(...)</code></a>: Computes sparse softmax cross entropy between <code>logits</code> and <code>labels</code>.</p>

<p><a href="../../../tf/compat/v1/nn/static_bidirectional_rnn.html"><code>static_bidirectional_rnn(...)</code></a>: Creates a bidirectional recurrent neural network. (deprecated)</p>

<p><a href="../../../tf/compat/v1/nn/static_rnn.html"><code>static_rnn(...)</code></a>: Creates a recurrent neural network specified by RNNCell <code>cell</code>. (deprecated)</p>

<p><a href="../../../tf/compat/v1/nn/static_state_saving_rnn.html"><code>static_state_saving_rnn(...)</code></a>: RNN that accepts a state saver for time-truncated RNN calculation. (deprecated)</p>

<p><a href="../../../tf/compat/v1/nn/sufficient_statistics.html"><code>sufficient_statistics(...)</code></a>: Calculate the sufficient statistics for the mean and variance of <code>x</code>.</p>

<p><a href="../../../tf/math/tanh.html"><code>tanh(...)</code></a>: Computes hyperbolic tangent of <code>x</code> element-wise.</p>

<p><a href="../../../tf/math/top_k.html"><code>top_k(...)</code></a>: Finds values and indices of the <code>k</code> largest entries for the last dimension.</p>

<p><a href="../../../tf/random/uniform_candidate_sampler.html"><code>uniform_candidate_sampler(...)</code></a>: Samples a set of classes using a uniform base distribution.</p>

<p><a href="../../../tf/compat/v1/nn/weighted_cross_entropy_with_logits.html"><code>weighted_cross_entropy_with_logits(...)</code></a>: Computes a weighted cross entropy. (deprecated arguments)</p>

<p><a href="../../../tf/compat/v1/nn/weighted_moments.html"><code>weighted_moments(...)</code></a>: Returns the frequency-weighted mean and variance of <code>x</code>.</p>

<p><a href="../../../tf/nn/with_space_to_batch.html"><code>with_space_to_batch(...)</code></a>: Performs <code>op</code> on the space-to-batch representation of <code>input</code>.</p>

<p><a href="../../../tf/compat/v1/nn/xw_plus_b.html"><code>xw_plus_b(...)</code></a>: Computes matmul(x, weights) + biases.</p>

<p><a href="../../../tf/math/zero_fraction.html"><code>zero_fraction(...)</code></a>: Returns the fraction of zeros in <code>value</code>.</p>

<h2>Other Members</h2>

<ul>
<li><code>swish</code> <a id="swish"></a></li>
</ul>

