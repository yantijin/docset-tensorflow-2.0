<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.compat.v1.sparse_merge" />
<meta itemprop="path" content="Stable" />
</div>


<h1>tf.compat.v1.sparse_merge</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p><a target="_blank" href="/code/stable/tensorflow/python/ops/sparse_ops.py">View source</a></p>

<!-- Start diff -->


<p>Combines a batch of feature ids and values into a single <code>SparseTensor</code>. (deprecated)</p>

<h3>Aliases:</h3>

<ul>
<li><code>tf.compat.v1.sparse.merge</code></li>
</ul>


<p><code>python
tf.compat.v1.sparse_merge(
    sp_ids,
    sp_values,
    vocab_size,
    name=None,
    already_sorted=False
)
</code></p>

<!-- Placeholder for "Used in" -->


<p>Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
No similar op available at this time.</p>

<p>The most common use case for this function occurs when feature ids and
their corresponding values are stored in <code>Example</code> protos on disk.
<code>parse_example</code> will return a batch of ids and a batch of values, and this
function joins them into a single logical <code>SparseTensor</code> for use in
functions such as <code>sparse_tensor_dense_matmul</code>, <code>sparse_to_dense</code>, etc.</p>

<p>The <code>SparseTensor</code> returned by this function has the following properties:</p>

<ul>
<li><code>indices</code> is equivalent to <code>sp_ids.indices</code> with the last
dimension discarded and replaced with <code>sp_ids.values</code>.</li>
<li><code>values</code> is simply <code>sp_values.values</code>.</li>
<li>If <code>sp_ids.dense_shape = [D0, D1, ..., Dn, K]</code>, then
<code>output.shape = [D0, D1, ..., Dn, vocab_size]</code>.</li>
</ul>


<p>For example, consider the following feature vectors:</p>

<p><code>python
  vector1 = [-3, 0, 0, 0, 0, 0]
  vector2 = [ 0, 1, 0, 4, 1, 0]
  vector3 = [ 5, 0, 0, 9, 0, 0]
</code></p>

<p>These might be stored sparsely in the following Example protos by storing
only the feature ids (column number if the vectors are treated as a matrix)
of the non-zero elements and the corresponding values:</p>

<p><code>python
  examples = [Example(features={
                  "ids": Feature(int64_list=Int64List(value=[0])),
                  "values": Feature(float_list=FloatList(value=[-3]))}),
              Example(features={
                  "ids": Feature(int64_list=Int64List(value=[1, 4, 3])),
                  "values": Feature(float_list=FloatList(value=[1, 1, 4]))}),
              Example(features={
                  "ids": Feature(int64_list=Int64List(value=[0, 3])),
                  "values": Feature(float_list=FloatList(value=[5, 9]))})]
</code></p>

<p>The result of calling parse_example on these examples will produce a
dictionary with entries for &ldquo;ids&rdquo; and &ldquo;values&rdquo;. Passing those two objects
to this function along with vocab_size=6, will produce a <code>SparseTensor</code> that
sparsely represents all three instances. Namely, the <code>indices</code> property will
contain the coordinates of the non-zero entries in the feature matrix (the
first dimension is the row number in the matrix, i.e., the index within the
batch, and the second dimension is the column number, i.e., the feature id);
<code>values</code> will contain the actual values. <code>shape</code> will be the shape of the
original matrix, i.e., (3, 6). For our example above, the output will be
equal to:</p>

<p><code>python
  SparseTensor(indices=[[0, 0], [1, 1], [1, 3], [1, 4], [2, 0], [2, 3]],
               values=[-3, 1, 4, 1, 5, 9],
               dense_shape=[3, 6])
</code></p>

<p>This method generalizes to higher-dimensions by simply providing a list for
both the sp_ids as well as the vocab_size.
In this case the resulting <code>SparseTensor</code> has the following properties:
  - <code>indices</code> is equivalent to <code>sp_ids[0].indices</code> with the last
    dimension discarded and concatenated with
    <code>sp_ids[0].values, sp_ids[1].values, ...</code>.
  - <code>values</code> is simply <code>sp_values.values</code>.
  - If <code>sp_ids.dense_shape = [D0, D1, ..., Dn, K]</code>, then
    <code>output.shape = [D0, D1, ..., Dn] + vocab_size</code>.</p>

<h4>Args:</h4>

<ul>
<li><b><code>sp_ids</code></b>: A single <code>SparseTensor</code> with <code>values</code> property of type <code>int32</code>
or <code>int64</code> or a Python list of such <code>SparseTensor</code>s or a list thereof.</li>
<li><b><code>sp_values</code></b>: A <code>SparseTensor</code> of any type.</li>
<li><b><code>vocab_size</code></b>: A scalar <code>int64</code> Tensor (or Python int) containing the new size
of the last dimension, <code>all(0 &lt;= sp_ids.values &lt; vocab_size)</code>.
Or a list thereof with <code>all(0 &lt;= sp_ids[i].values &lt; vocab_size[i])</code> for
all <code>i</code>.</li>
<li><b><code>name</code></b>: A name prefix for the returned tensors (optional)</li>
<li><b><code>already_sorted</code></b>: A boolean to specify whether the per-batch values in
<code>sp_values</code> are already sorted. If so skip sorting, False by default
(optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>SparseTensor</code> compactly representing a batch of feature ids and values,
useful for passing to functions that expect such a <code>SparseTensor</code>.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>TypeError</code></b>: If <code>sp_values</code> is not a <code>SparseTensor</code>. Or if <code>sp_ids</code> is neither
a <code>SparseTensor</code> nor a list thereof. Or if <code>vocab_size</code> is not a
<code>Tensor</code> or a Python int and <code>sp_ids</code> is a <code>SparseTensor</code>. Or if
<code>vocab_size</code> is not a or list thereof and <code>sp_ids</code> is a list.</li>
<li><b><code>ValueError</code></b>: If <code>sp_ids</code> and <code>vocab_size</code> are lists of different lengths.</li>
</ul>

