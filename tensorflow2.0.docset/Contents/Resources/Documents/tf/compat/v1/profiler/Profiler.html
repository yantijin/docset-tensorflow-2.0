<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.compat.v1.profiler.Profiler" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="__init__"/>
<meta itemprop="property" content="add_step"/>
<meta itemprop="property" content="advise"/>
<meta itemprop="property" content="profile_graph"/>
<meta itemprop="property" content="profile_name_scope"/>
<meta itemprop="property" content="profile_operations"/>
<meta itemprop="property" content="profile_python"/>
<meta itemprop="property" content="serialize_to_string"/>
</div>


<h1>tf.compat.v1.profiler.Profiler</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p><a target="_blank" href="/code/stable/tensorflow/python/profiler/model_analyzer.py">View source</a></p>

<h2>Class <code>Profiler</code></h2>

<!-- Start diff -->


<p>TensorFlow multi-step profiler.</p>

<!-- Placeholder for "Used in" -->


<p>https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/README.html</p>

<p>```python
Typical use case:
  # Currently we are only allowed to create 1 profiler per process.
  profiler = Profiler(sess.graph)</p>

<p>  for i in xrange(total_steps):
    if i % 10000 == 0:
      run_meta = tf.compat.v1.RunMetadata()
      _ = sess.run(&hellip;,
                   options=tf.compat.v1.RunOptions(
                       trace_level=tf.RunOptions.FULL_TRACE),
                   run_metadata=run_meta)
      profiler.add_step(i, run_meta)</p>

<pre><code>  # Profile the parameters of your model.
  profiler.profile_name_scope(options=(option_builder.ProfileOptionBuilder
      .trainable_variables_parameter()))

  # Or profile the timing of your model operations.
  opts = option_builder.ProfileOptionBuilder.time_and_memory()
  profiler.profile_operations(options=opts)

  # Or you can generate a timeline:
  opts = (option_builder.ProfileOptionBuilder(
          option_builder.ProfileOptionBuilder.time_and_memory())
          .with_step(i)
          .with_timeline_output(filename).build())
  profiler.profile_graph(options=opts)
else:
  _ = sess.run(...)
</code></pre>

<p>  # Auto detect problems and generate advice.
  profiler.advise()
```</p>

<h2 id="__init__"><code>__init__</code></h2>


<p><a target="_blank" href="/code/stable/tensorflow/python/profiler/model_analyzer.py">View source</a></p>

<p><code>python
__init__(
    graph=None,
    op_log=None
)
</code></p>

<p>Constructor.</p>

<h4>Args:</h4>

<ul>
<li><b><code>graph</code></b>: tf.Graph. If None and eager execution is not enabled, use
  default graph.</li>
<li><b><code>op_log</code></b>: optional. tensorflow::tfprof::OpLogProto proto. Used to define
  extra op types.</li>
</ul>


<h2>Methods</h2>

<h3 id="add_step"><code>add_step</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/profiler/model_analyzer.py">View source</a></p>

<p><code>python
add_step(
    step,
    run_meta
)
</code></p>

<p>Add statistics of a step.</p>

<h4>Args:</h4>

<ul>
<li><b><code>step</code></b>: int, An id used to group one or more different <code>run_meta</code> together.
  When profiling with the profile_xxx APIs, user can use the <code>step</code>
  id in the <code>options</code> to profile these <code>run_meta</code> together.</li>
<li><b><code>run_meta</code></b>: RunMetadata proto that contains statistics of a session run.</li>
</ul>


<h3 id="advise"><code>advise</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/profiler/model_analyzer.py">View source</a></p>

<p><code>python
advise(options)
</code></p>

<p>Automatically detect problems and generate reports.</p>

<h4>Args:</h4>

<ul>
<li><b><code>options</code></b>: A dict of options. See ALL_ADVICE example above.</li>
</ul>


<h4>Returns:</h4>

<p>A Advise proto that conains the reports from all checkers.</p>

<h3 id="profile_graph"><code>profile_graph</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/profiler/model_analyzer.py">View source</a></p>

<p><code>python
profile_graph(options)
</code></p>

<p>Profile the statistics of graph nodes, organized by dataflow graph.</p>

<h4>Args:</h4>

<ul>
<li><b><code>options</code></b>: A dict of options. See core/profiler/g3doc/options.html.</li>
</ul>


<h4>Returns:</h4>

<p>a GraphNodeProto that records the results.</p>

<h3 id="profile_name_scope"><code>profile_name_scope</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/profiler/model_analyzer.py">View source</a></p>

<p><code>python
profile_name_scope(options)
</code></p>

<p>Profile the statistics of graph nodes, organized by name scope.</p>

<h4>Args:</h4>

<ul>
<li><b><code>options</code></b>: A dict of options. See core/profiler/g3doc/options.html.</li>
</ul>


<h4>Returns:</h4>

<p>a GraphNodeProto that records the results.</p>

<h3 id="profile_operations"><code>profile_operations</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/profiler/model_analyzer.py">View source</a></p>

<p><code>python
profile_operations(options)
</code></p>

<p>Profile the statistics of the Operation types (e.g. MatMul, Conv2D).</p>

<h4>Args:</h4>

<ul>
<li><b><code>options</code></b>: A dict of options. See core/profiler/g3doc/options.html.</li>
</ul>


<h4>Returns:</h4>

<p>a MultiGraphNodeProto that records the results.</p>

<h3 id="profile_python"><code>profile_python</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/profiler/model_analyzer.py">View source</a></p>

<p><code>python
profile_python(options)
</code></p>

<p>Profile the statistics of the Python codes.</p>

<p>  By default, it shows the call stack from root. To avoid
  redundant output, you may use options to filter as below
    options[&lsquo;show_name_regexes&rsquo;] = [&lsquo;.<em>my_code.py.</em>&rsquo;]</p>

<h4>Args:</h4>

<ul>
<li><b><code>options</code></b>: A dict of options. See core/profiler/g3doc/options.html.</li>
</ul>


<h4>Returns:</h4>

<p>a MultiGraphNodeProto that records the results.</p>

<h3 id="serialize_to_string"><code>serialize_to_string</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/profiler/model_analyzer.py">View source</a></p>

<p><code>python
serialize_to_string()
</code></p>

<p>Serialize the ProfileProto to a binary string.</p>

<p>  Users can write it to file for offline analysis by tfprof commandline
  or graphical interface.</p>

<h4>Returns:</h4>

<p>ProfileProto binary string.</p>
