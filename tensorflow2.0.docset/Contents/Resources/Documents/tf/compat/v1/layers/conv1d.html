<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.compat.v1.layers.conv1d" />
<meta itemprop="path" content="Stable" />
</div>


<h1>tf.compat.v1.layers.conv1d</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p><a target="_blank" href="/code/stable/tensorflow/python/layers/convolutional.py">View source</a></p>

<!-- Start diff -->


<p>Functional interface for 1D convolution layer (e.g. temporal convolution). (deprecated)</p>

<p><code>python
tf.compat.v1.layers.conv1d(
    inputs,
    filters,
    kernel_size,
    strides=1,
    padding='valid',
    data_format='channels_last',
    dilation_rate=1,
    activation=None,
    use_bias=True,
    kernel_initializer=None,
    bias_initializer=tf.zeros_initializer(),
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    trainable=True,
    name=None,
    reuse=None
)
</code></p>

<!-- Placeholder for "Used in" -->


<p>Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Use <a href="../../../../tf/keras/layers/Conv1D.html"><code>tf.keras.layers.Conv1D</code></a> instead.</p>

<p>This layer creates a convolution kernel that is convolved
(actually cross-correlated) with the layer input to produce a tensor of
outputs. If <code>use_bias</code> is True (and a <code>bias_initializer</code> is provided),
a bias vector is created and added to the outputs. Finally, if
<code>activation</code> is not <code>None</code>, it is applied to the outputs as well.</p>

<h4>Arguments:</h4>

<ul>
<li><b><code>inputs</code></b>: Tensor input.</li>
<li><b><code>filters</code></b>: Integer, the dimensionality of the output space (i.e. the number
of filters in the convolution).</li>
<li><b><code>kernel_size</code></b>: An integer or tuple/list of a single integer, specifying the
length of the 1D convolution window.</li>
<li><b><code>strides</code></b>: An integer or tuple/list of a single integer,
specifying the stride length of the convolution.
Specifying any stride value != 1 is incompatible with specifying
any <code>dilation_rate</code> value != 1.</li>
<li><b><code>padding</code></b>: One of <code>"valid"</code> or <code>"same"</code> (case-insensitive).</li>
<li><b><code>data_format</code></b>: A string, one of <code>channels_last</code> (default) or <code>channels_first</code>.
The ordering of the dimensions in the inputs.
<code>channels_last</code> corresponds to inputs with shape
<code>(batch, length, channels)</code> while <code>channels_first</code> corresponds to
inputs with shape <code>(batch, channels, length)</code>.</li>
<li><b><code>dilation_rate</code></b>: An integer or tuple/list of a single integer, specifying
the dilation rate to use for dilated convolution.
Currently, specifying any <code>dilation_rate</code> value != 1 is
incompatible with specifying any <code>strides</code> value != 1.</li>
<li><b><code>activation</code></b>: Activation function. Set it to None to maintain a
linear activation.</li>
<li><b><code>use_bias</code></b>: Boolean, whether the layer uses a bias.</li>
<li><b><code>kernel_initializer</code></b>: An initializer for the convolution kernel.</li>
<li><b><code>bias_initializer</code></b>: An initializer for the bias vector. If None, the default
initializer will be used.</li>
<li><b><code>kernel_regularizer</code></b>: Optional regularizer for the convolution kernel.</li>
<li><b><code>bias_regularizer</code></b>: Optional regularizer for the bias vector.</li>
<li><b><code>activity_regularizer</code></b>: Optional regularizer function for the output.</li>
<li><b><code>kernel_constraint</code></b>: Optional projection function to be applied to the
  kernel after being updated by an <code>Optimizer</code> (e.g. used to implement
  norm constraints or value constraints for layer weights). The function
  must take as input the unprojected variable and must return the
  projected variable (which must have the same shape). Constraints are
  not safe to use when doing asynchronous distributed training.</li>
<li><b><code>bias_constraint</code></b>: Optional projection function to be applied to the
  bias after being updated by an <code>Optimizer</code>.</li>
<li><b><code>trainable</code></b>: Boolean, if <code>True</code> also add variables to the graph collection
<code>GraphKeys.TRAINABLE_VARIABLES</code> (see <a href="../../../../tf/Variable.html"><code>tf.Variable</code></a>).</li>
<li><b><code>name</code></b>: A string, the name of the layer.</li>
<li><b><code>reuse</code></b>: Boolean, whether to reuse the weights of a previous layer
by the same name.</li>
</ul>


<h4>Returns:</h4>

<p>Output tensor.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: if eager execution is enabled.</li>
</ul>

