
    <html lang="zh-cn">
    <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <link href="../../../../../default.css" rel="stylesheet">
    <link href="
   ../../../../../github.css" rel="stylesheet">
    </head>
    <body>
    <div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.compat.v1.layers.dense" />
<meta itemprop="path" content="Stable" />
</div>

<h1 id="tfcompatv1layersdense">tf.compat.v1.layers.dense</h1>
<!-- Insert buttons -->

<table class="tfo-notebook-buttons tfo-api" align="left">
</table>

<p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/layers/core.py">View source</a></p>
<!-- Start diff -->

<p>Functional interface for the densely-connected layer. (deprecated)</p>
<div class="codehilite"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span>
    <span class="n">inputs</span><span class="p">,</span>
    <span class="n">units</span><span class="p">,</span>
    <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">kernel_initializer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">bias_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">(),</span>
    <span class="n">kernel_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">bias_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">activity_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">kernel_constraint</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">bias_constraint</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">reuse</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</pre></div>


<!-- Placeholder for "Used in" -->

<p>Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.</p>
<p>This layer implements the operation:
<code>outputs = activation(inputs * kernel + bias)</code>
where <code>activation</code> is the activation function passed as the <code>activation</code>
argument (if not <code>None</code>), <code>kernel</code> is a weights matrix created by the layer,
and <code>bias</code> is a bias vector created by the layer
(only if <code>use_bias</code> is <code>True</code>).</p>
<h4 id="arguments">Arguments:</h4>
<ul>
<li><b><code>inputs</code></b>: Tensor input.</li>
<li><b><code>units</code></b>: Integer or Long, dimensionality of the output space.</li>
<li><b><code>activation</code></b>: Activation function (callable). Set it to None to maintain a
  linear activation.</li>
<li><b><code>use_bias</code></b>: Boolean, whether the layer uses a bias.</li>
<li><b><code>kernel_initializer</code></b>: Initializer function for the weight matrix.
  If <code>None</code> (default), weights are initialized using the default
  initializer used by <a href="../../../../tf/compat/v1/get_variable.html"><code>tf.compat.v1.get_variable</code></a>.</li>
<li><b><code>bias_initializer</code></b>: Initializer function for the bias.</li>
<li><b><code>kernel_regularizer</code></b>: Regularizer function for the weight matrix.</li>
<li><b><code>bias_regularizer</code></b>: Regularizer function for the bias.</li>
<li><b><code>activity_regularizer</code></b>: Regularizer function for the output.</li>
<li><b><code>kernel_constraint</code></b>: An optional projection function to be applied to the
    kernel after being updated by an <code>Optimizer</code> (e.g. used to implement
    norm constraints or value constraints for layer weights). The function
    must take as input the unprojected variable and must return the
    projected variable (which must have the same shape). Constraints are
    not safe to use when doing asynchronous distributed training.</li>
<li><b><code>bias_constraint</code></b>: An optional projection function to be applied to the
    bias after being updated by an <code>Optimizer</code>.</li>
<li><b><code>trainable</code></b>: Boolean, if <code>True</code> also add variables to the graph collection
  <code>GraphKeys.TRAINABLE_VARIABLES</code> (see <a href="../../../../tf/Variable.html"><code>tf.Variable</code></a>).</li>
<li><b><code>name</code></b>: String, the name of the layer.</li>
<li><b><code>reuse</code></b>: Boolean, whether to reuse the weights of a previous layer
  by the same name.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>Output tensor the same shape as <code>inputs</code> except the last dimension is of
size <code>units</code>.</p>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: if eager execution is enabled.</li>
</ul>
    </body>
    </html>
   