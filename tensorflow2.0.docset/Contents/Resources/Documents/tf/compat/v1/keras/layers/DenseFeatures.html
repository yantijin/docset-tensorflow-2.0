<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.compat.v1.keras.layers.DenseFeatures" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="__init__"/>
</div>


<h1>tf.compat.v1.keras.layers.DenseFeatures</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p><a target="_blank" href="/code/stable/tensorflow/python/feature_column/dense_features.py">View source</a></p>

<h2>Class <code>DenseFeatures</code></h2>

<!-- Start diff -->


<p>A layer that produces a dense <code>Tensor</code> based on given <code>feature_columns</code>.</p>

<!-- Placeholder for "Used in" -->


<p>Generally a single example in training data is described with FeatureColumns.
At the first layer of the model, this column oriented data should be converted
to a single <code>Tensor</code>.</p>

<p>This layer can be called multiple times with different features.</p>

<p>This is the V1 version of this layer that uses variable_scope&rsquo;s to create
variables which works well with PartitionedVariables. Variable scopes are
deprecated in V2, so the V2 version uses name_scopes instead. But currently
that lacks support for partitioned variables. Use this if you need
partitioned variables.</p>

<h4>Example:</h4>

<p>```python
price = numeric_column(&lsquo;price&rsquo;)
keywords_embedded = embedding_column(
    categorical_column_with_hash_bucket(&ldquo;keywords&rdquo;, 10K), dimensions=16)
columns = [price, keywords_embedded, &hellip;]
feature_layer = DenseFeatures(columns)</p>

<p>features = tf.io.parse_example(&hellip;, features=make_parse_example_spec(columns))
dense_tensor = feature_layer(features)
for units in [128, 64, 32]:
  dense_tensor = tf.compat.v1.keras.layers.Dense(
                     units, activation=&lsquo;relu&rsquo;)(dense_tensor)
prediction = tf.compat.v1.keras.layers.Dense(1)(dense_tensor)
```</p>

<h2 id="__init__"><code>__init__</code></h2>


<p><a target="_blank" href="/code/stable/tensorflow/python/feature_column/dense_features.py">View source</a></p>

<p><code>python
__init__(
    feature_columns,
    trainable=True,
    name=None,
    **kwargs
)
</code></p>

<p>Constructs a DenseFeatures layer.</p>

<h4>Args:</h4>

<ul>
<li><b><code>feature_columns</code></b>: An iterable containing the FeatureColumns to use as
inputs to your model. All items should be instances of classes derived
from <code>DenseColumn</code> such as <code>numeric_column</code>, <code>embedding_column</code>,
<code>bucketized_column</code>, <code>indicator_column</code>. If you have categorical
features, you can wrap them with an <code>embedding_column</code> or
<code>indicator_column</code>.</li>
<li><b><code>trainable</code></b>:  Boolean, whether the layer&rsquo;s variables will be updated via
gradient descent during training.</li>
<li><b><code>name</code></b>: Name to give to the DenseFeatures.</li>
<li><b><code>**kwargs</code></b>: Keyword arguments to construct a layer.</li>
</ul>


<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: if an item in <code>feature_columns</code> is not a <code>DenseColumn</code>.</li>
</ul>

