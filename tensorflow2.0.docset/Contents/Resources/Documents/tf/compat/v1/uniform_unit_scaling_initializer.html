
    <html lang="zh-cn">
    <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <link href=../../../../default.css" rel="stylesheet">
    <link href="
   ../../../../github.css" rel="stylesheet">
    </head>
    <body>
    <div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.compat.v1.uniform_unit_scaling_initializer" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="__call__"/>
<meta itemprop="property" content="__init__"/>
<meta itemprop="property" content="from_config"/>
<meta itemprop="property" content="get_config"/>
</div>

<h1 id="tfcompatv1uniform_unit_scaling_initializer">tf.compat.v1.uniform_unit_scaling_initializer</h1>
<!-- Insert buttons -->

<table class="tfo-notebook-buttons tfo-api" align="left">
</table>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/init_ops.py">View source</a></p>
<h2 id="class-uniform_unit_scaling_initializer">Class <code>uniform_unit_scaling_initializer</code></h2>
<!-- Start diff -->

<p>Initializer that generates tensors without scaling variance.</p>
<p>Inherits From: <a href="../../../tf/compat/v1/keras/initializers/Initializer.html"><code>Initializer</code></a></p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li>Class <code>tf.compat.v1.initializers.uniform_unit_scaling</code></li>
</ul>
<!-- Placeholder for "Used in" -->

<p>When initializing a deep network, it is in principle advantageous to keep
the scale of the input variance constant, so it does not explode or diminish
by reaching the final layer. If the input is <code>x</code> and the operation <code>x * W</code>,
and we want to initialize <code>W</code> uniformly at random, we need to pick <code>W</code> from</p>
<div class="codehilite"><pre><span></span><span class="err">[-sqrt(3) / sqrt(dim), sqrt(3) / sqrt(dim)]</span>
</pre></div>


<p>to keep the scale intact, where <code>dim = W.shape[0]</code> (the size of the input).
A similar calculation for convolutional networks gives an analogous result
with <code>dim</code> equal to the product of the first 3 dimensions.  When
nonlinearities are present, we need to multiply this by a constant <code>factor</code>.
See (Sussillo et al., 2014) for deeper motivation, experiments
and the calculation of constants. In section 2.3 there, the constants were
numerically computed: for a linear layer it's 1.0, relu: ~1.43, tanh: ~1.15.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>factor</code></b>: Float.  A multiplicative factor by which the values will be scaled.</li>
<li><b><code>seed</code></b>: A Python integer. Used to create random seeds. See
  <a href="../../../tf/compat/v1/set_random_seed.html"><code>tf.compat.v1.set_random_seed</code></a> for behavior.</li>
<li><b><code>dtype</code></b>: Default data type, used if no <code>dtype</code> argument is provided when
  calling the initializer. Only floating point types are supported.</li>
</ul>
<h4 id="references">References:</h4>
<p><a href="https://arxiv.org/abs/1412.6558">Sussillo et al., 2014</a>
(<a href="http://arxiv.org/pdf/1412.6558.pdf">pdf</a>)</p>
<h2 id="__init__"><code>__init__</code></h2>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/init_ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="fm">__init__</span><span class="p">(</span>
    <span class="n">factor</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">float32</span>
<span class="p">)</span>
</pre></div>


<p>DEPRECATED FUNCTION (deprecated arguments)</p>
<p>Warning: SOME ARGUMENTS ARE DEPRECATED: <code>(dtype)</code>. They will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor</p>
<p>Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.</p>
<h2 id="methods">Methods</h2>
<h3 id="__call__"><code>__call__</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/init_ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="fm">__call__</span><span class="p">(</span>
    <span class="n">shape</span><span class="p">,</span>
    <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">partition_info</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</pre></div>


<p>Returns a tensor object initialized as specified by the initializer.</p>
<h4 id="args_1">Args:</h4>
<ul>
<li><b><code>shape</code></b>: Shape of the tensor.</li>
<li><b><code>dtype</code></b>: Optional dtype of the tensor. If not provided use the initializer
  dtype.</li>
<li><b><code>partition_info</code></b>: Optional information about the possible partitioning of a
  tensor.</li>
</ul>
<h3 id="from_config"><code>from_config</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/init_ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">from_config</span><span class="p">(</span>
    <span class="bp">cls</span><span class="p">,</span>
    <span class="n">config</span>
<span class="p">)</span>
</pre></div>


<p>Instantiates an initializer from a configuration dictionary.</p>
<h4 id="example">Example:</h4>
<div class="codehilite"><pre><span></span><span class="n">initializer</span> <span class="o">=</span> <span class="n">RandomUniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">initializer</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
<span class="n">initializer</span> <span class="o">=</span> <span class="n">RandomUniform</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</pre></div>


<h4 id="args_2">Args:</h4>
<ul>
<li><b><code>config</code></b>: A Python dictionary. It will typically be the output of
  <code>get_config</code>.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>An Initializer instance.</p>
<h3 id="get_config"><code>get_config</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/init_ops.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">get_config</span><span class="p">()</span>
</pre></div>


<p>Returns the configuration of the initializer as a JSON-serializable dict.</p>
<h4 id="returns_1">Returns:</h4>
<p>A JSON-serializable Python dict.</p>
    </body>
    </html>
   