
    <html lang="zh-cn">
    <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <link href="../../../../../default.css" rel="stylesheet">
    <link href="
   ../../../../../github.css" rel="stylesheet">
    </head>
    <body>
    <div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.compat.v2.keras.layers" />
<meta itemprop="path" content="Stable" />
</div>

<h1 id="module-tfcompatv2keraslayers">Module: tf.compat.v2.keras.layers</h1>
<table class="tfo-notebook-buttons tfo-api" align="left">
</table>

<p>Keras layers API.</p>
<h2 id="classes">Classes</h2>
<p><a href="../../../../tf/keras/layers/AbstractRNNCell.html"><code>class AbstractRNNCell</code></a>: Abstract object representing an RNN cell.</p>
<p><a href="../../../../tf/keras/layers/Activation.html"><code>class Activation</code></a>: Applies an activation function to an output.</p>
<p><a href="../../../../tf/keras/layers/ActivityRegularization.html"><code>class ActivityRegularization</code></a>: Layer that applies an update to the cost function based input activity.</p>
<p><a href="../../../../tf/keras/layers/Add.html"><code>class Add</code></a>: Layer that adds a list of inputs.</p>
<p><a href="../../../../tf/keras/layers/AdditiveAttention.html"><code>class AdditiveAttention</code></a>: Additive attention layer, a.k.a. Bahdanau-style attention.</p>
<p><a href="../../../../tf/keras/layers/AlphaDropout.html"><code>class AlphaDropout</code></a>: Applies Alpha Dropout to the input.</p>
<p><a href="../../../../tf/keras/layers/Attention.html"><code>class Attention</code></a>: Dot-product attention layer, a.k.a. Luong-style attention.</p>
<p><a href="../../../../tf/keras/layers/Average.html"><code>class Average</code></a>: Layer that averages a list of inputs.</p>
<p><a href="../../../../tf/keras/layers/AveragePooling1D.html"><code>class AveragePooling1D</code></a>: Average pooling for temporal data.</p>
<p><a href="../../../../tf/keras/layers/AveragePooling2D.html"><code>class AveragePooling2D</code></a>: Average pooling operation for spatial data.</p>
<p><a href="../../../../tf/keras/layers/AveragePooling3D.html"><code>class AveragePooling3D</code></a>: Average pooling operation for 3D data (spatial or spatio-temporal).</p>
<p><a href="../../../../tf/keras/layers/AveragePooling1D.html"><code>class AvgPool1D</code></a>: Average pooling for temporal data.</p>
<p><a href="../../../../tf/keras/layers/AveragePooling2D.html"><code>class AvgPool2D</code></a>: Average pooling operation for spatial data.</p>
<p><a href="../../../../tf/keras/layers/AveragePooling3D.html"><code>class AvgPool3D</code></a>: Average pooling operation for 3D data (spatial or spatio-temporal).</p>
<p><a href="../../../../tf/keras/layers/BatchNormalization.html"><code>class BatchNormalization</code></a>: Base class of Batch normalization layer (Ioffe and Szegedy, 2014).</p>
<p><a href="../../../../tf/keras/layers/Bidirectional.html"><code>class Bidirectional</code></a>: Bidirectional wrapper for RNNs.</p>
<p><a href="../../../../tf/keras/layers/Concatenate.html"><code>class Concatenate</code></a>: Layer that concatenates a list of inputs.</p>
<p><a href="../../../../tf/keras/layers/Conv1D.html"><code>class Conv1D</code></a>: 1D convolution layer (e.g. temporal convolution).</p>
<p><a href="../../../../tf/keras/layers/Conv2D.html"><code>class Conv2D</code></a>: 2D convolution layer (e.g. spatial convolution over images).</p>
<p><a href="../../../../tf/keras/layers/Conv2DTranspose.html"><code>class Conv2DTranspose</code></a>: Transposed convolution layer (sometimes called Deconvolution).</p>
<p><a href="../../../../tf/keras/layers/Conv3D.html"><code>class Conv3D</code></a>: 3D convolution layer (e.g. spatial convolution over volumes).</p>
<p><a href="../../../../tf/keras/layers/Conv3DTranspose.html"><code>class Conv3DTranspose</code></a>: Transposed convolution layer (sometimes called Deconvolution).</p>
<p><a href="../../../../tf/keras/layers/ConvLSTM2D.html"><code>class ConvLSTM2D</code></a>: Convolutional LSTM.</p>
<p><a href="../../../../tf/keras/layers/Conv1D.html"><code>class Convolution1D</code></a>: 1D convolution layer (e.g. temporal convolution).</p>
<p><a href="../../../../tf/keras/layers/Conv2D.html"><code>class Convolution2D</code></a>: 2D convolution layer (e.g. spatial convolution over images).</p>
<p><a href="../../../../tf/keras/layers/Conv2DTranspose.html"><code>class Convolution2DTranspose</code></a>: Transposed convolution layer (sometimes called Deconvolution).</p>
<p><a href="../../../../tf/keras/layers/Conv3D.html"><code>class Convolution3D</code></a>: 3D convolution layer (e.g. spatial convolution over volumes).</p>
<p><a href="../../../../tf/keras/layers/Conv3DTranspose.html"><code>class Convolution3DTranspose</code></a>: Transposed convolution layer (sometimes called Deconvolution).</p>
<p><a href="../../../../tf/keras/layers/Cropping1D.html"><code>class Cropping1D</code></a>: Cropping layer for 1D input (e.g. temporal sequence).</p>
<p><a href="../../../../tf/keras/layers/Cropping2D.html"><code>class Cropping2D</code></a>: Cropping layer for 2D input (e.g. picture).</p>
<p><a href="../../../../tf/keras/layers/Cropping3D.html"><code>class Cropping3D</code></a>: Cropping layer for 3D data (e.g. spatial or spatio-temporal).</p>
<p><a href="../../../../tf/keras/layers/Dense.html"><code>class Dense</code></a>: Just your regular densely-connected NN layer.</p>
<p><a href="../../../../tf/keras/layers/DenseFeatures.html"><code>class DenseFeatures</code></a>: A layer that produces a dense <code>Tensor</code> based on given <code>feature_columns</code>.</p>
<p><a href="../../../../tf/keras/layers/DepthwiseConv2D.html"><code>class DepthwiseConv2D</code></a>: Depthwise separable 2D convolution.</p>
<p><a href="../../../../tf/keras/layers/Dot.html"><code>class Dot</code></a>: Layer that computes a dot product between samples in two tensors.</p>
<p><a href="../../../../tf/keras/layers/Dropout.html"><code>class Dropout</code></a>: Applies Dropout to the input.</p>
<p><a href="../../../../tf/keras/layers/ELU.html"><code>class ELU</code></a>: Exponential Linear Unit.</p>
<p><a href="../../../../tf/keras/layers/Embedding.html"><code>class Embedding</code></a>: Turns positive integers (indexes) into dense vectors of fixed size.</p>
<p><a href="../../../../tf/keras/layers/Flatten.html"><code>class Flatten</code></a>: Flattens the input. Does not affect the batch size.</p>
<p><a href="../../../../tf/keras/layers/GRU.html"><code>class GRU</code></a>: Gated Recurrent Unit - Cho et al. 2014.</p>
<p><a href="../../../../tf/keras/layers/GRUCell.html"><code>class GRUCell</code></a>: Cell class for the GRU layer.</p>
<p><a href="../../../../tf/keras/layers/GaussianDropout.html"><code>class GaussianDropout</code></a>: Apply multiplicative 1-centered Gaussian noise.</p>
<p><a href="../../../../tf/keras/layers/GaussianNoise.html"><code>class GaussianNoise</code></a>: Apply additive zero-centered Gaussian noise.</p>
<p><a href="../../../../tf/keras/layers/GlobalAveragePooling1D.html"><code>class GlobalAveragePooling1D</code></a>: Global average pooling operation for temporal data.</p>
<p><a href="../../../../tf/keras/layers/GlobalAveragePooling2D.html"><code>class GlobalAveragePooling2D</code></a>: Global average pooling operation for spatial data.</p>
<p><a href="../../../../tf/keras/layers/GlobalAveragePooling3D.html"><code>class GlobalAveragePooling3D</code></a>: Global Average pooling operation for 3D data.</p>
<p><a href="../../../../tf/keras/layers/GlobalAveragePooling1D.html"><code>class GlobalAvgPool1D</code></a>: Global average pooling operation for temporal data.</p>
<p><a href="../../../../tf/keras/layers/GlobalAveragePooling2D.html"><code>class GlobalAvgPool2D</code></a>: Global average pooling operation for spatial data.</p>
<p><a href="../../../../tf/keras/layers/GlobalAveragePooling3D.html"><code>class GlobalAvgPool3D</code></a>: Global Average pooling operation for 3D data.</p>
<p><a href="../../../../tf/keras/layers/GlobalMaxPool1D.html"><code>class GlobalMaxPool1D</code></a>: Global max pooling operation for temporal data.</p>
<p><a href="../../../../tf/keras/layers/GlobalMaxPool2D.html"><code>class GlobalMaxPool2D</code></a>: Global max pooling operation for spatial data.</p>
<p><a href="../../../../tf/keras/layers/GlobalMaxPool3D.html"><code>class GlobalMaxPool3D</code></a>: Global Max pooling operation for 3D data.</p>
<p><a href="../../../../tf/keras/layers/GlobalMaxPool1D.html"><code>class GlobalMaxPooling1D</code></a>: Global max pooling operation for temporal data.</p>
<p><a href="../../../../tf/keras/layers/GlobalMaxPool2D.html"><code>class GlobalMaxPooling2D</code></a>: Global max pooling operation for spatial data.</p>
<p><a href="../../../../tf/keras/layers/GlobalMaxPool3D.html"><code>class GlobalMaxPooling3D</code></a>: Global Max pooling operation for 3D data.</p>
<p><a href="../../../../tf/keras/layers/InputLayer.html"><code>class InputLayer</code></a>: Layer to be used as an entry point into a Network (a graph of layers).</p>
<p><a href="../../../../tf/keras/layers/InputSpec.html"><code>class InputSpec</code></a>: Specifies the ndim, dtype and shape of every input to a layer.</p>
<p><a href="../../../../tf/keras/layers/LSTM.html"><code>class LSTM</code></a>: Long Short-Term Memory layer - Hochreiter 1997.</p>
<p><a href="../../../../tf/keras/layers/LSTMCell.html"><code>class LSTMCell</code></a>: Cell class for the LSTM layer.</p>
<p><a href="../../../../tf/keras/layers/Lambda.html"><code>class Lambda</code></a>: Wraps arbitrary expressions as a <code>Layer</code> object.</p>
<p><a href="../../../../tf/keras/layers/Layer.html"><code>class Layer</code></a>: Base layer class.</p>
<p><a href="../../../../tf/keras/layers/LayerNormalization.html"><code>class LayerNormalization</code></a>: Layer normalization layer (Ba et al., 2016).</p>
<p><a href="../../../../tf/keras/layers/LeakyReLU.html"><code>class LeakyReLU</code></a>: Leaky version of a Rectified Linear Unit.</p>
<p><a href="../../../../tf/keras/layers/LocallyConnected1D.html"><code>class LocallyConnected1D</code></a>: Locally-connected layer for 1D inputs.</p>
<p><a href="../../../../tf/keras/layers/LocallyConnected2D.html"><code>class LocallyConnected2D</code></a>: Locally-connected layer for 2D inputs.</p>
<p><a href="../../../../tf/keras/layers/Masking.html"><code>class Masking</code></a>: Masks a sequence by using a mask value to skip timesteps.</p>
<p><a href="../../../../tf/keras/layers/MaxPool1D.html"><code>class MaxPool1D</code></a>: Max pooling operation for temporal data.</p>
<p><a href="../../../../tf/keras/layers/MaxPool2D.html"><code>class MaxPool2D</code></a>: Max pooling operation for spatial data.</p>
<p><a href="../../../../tf/keras/layers/MaxPool3D.html"><code>class MaxPool3D</code></a>: Max pooling operation for 3D data (spatial or spatio-temporal).</p>
<p><a href="../../../../tf/keras/layers/MaxPool1D.html"><code>class MaxPooling1D</code></a>: Max pooling operation for temporal data.</p>
<p><a href="../../../../tf/keras/layers/MaxPool2D.html"><code>class MaxPooling2D</code></a>: Max pooling operation for spatial data.</p>
<p><a href="../../../../tf/keras/layers/MaxPool3D.html"><code>class MaxPooling3D</code></a>: Max pooling operation for 3D data (spatial or spatio-temporal).</p>
<p><a href="../../../../tf/keras/layers/Maximum.html"><code>class Maximum</code></a>: Layer that computes the maximum (element-wise) a list of inputs.</p>
<p><a href="../../../../tf/keras/layers/Minimum.html"><code>class Minimum</code></a>: Layer that computes the minimum (element-wise) a list of inputs.</p>
<p><a href="../../../../tf/keras/layers/Multiply.html"><code>class Multiply</code></a>: Layer that multiplies (element-wise) a list of inputs.</p>
<p><a href="../../../../tf/keras/layers/PReLU.html"><code>class PReLU</code></a>: Parametric Rectified Linear Unit.</p>
<p><a href="../../../../tf/keras/layers/Permute.html"><code>class Permute</code></a>: Permutes the dimensions of the input according to a given pattern.</p>
<p><a href="../../../../tf/keras/layers/RNN.html"><code>class RNN</code></a>: Base class for recurrent layers.</p>
<p><a href="../../../../tf/keras/layers/ReLU.html"><code>class ReLU</code></a>: Rectified Linear Unit activation function.</p>
<p><a href="../../../../tf/keras/layers/RepeatVector.html"><code>class RepeatVector</code></a>: Repeats the input n times.</p>
<p><a href="../../../../tf/keras/layers/Reshape.html"><code>class Reshape</code></a>: Reshapes an output to a certain shape.</p>
<p><a href="../../../../tf/keras/layers/SeparableConv1D.html"><code>class SeparableConv1D</code></a>: Depthwise separable 1D convolution.</p>
<p><a href="../../../../tf/keras/layers/SeparableConv2D.html"><code>class SeparableConv2D</code></a>: Depthwise separable 2D convolution.</p>
<p><a href="../../../../tf/keras/layers/SeparableConv1D.html"><code>class SeparableConvolution1D</code></a>: Depthwise separable 1D convolution.</p>
<p><a href="../../../../tf/keras/layers/SeparableConv2D.html"><code>class SeparableConvolution2D</code></a>: Depthwise separable 2D convolution.</p>
<p><a href="../../../../tf/keras/layers/SimpleRNN.html"><code>class SimpleRNN</code></a>: Fully-connected RNN where the output is to be fed back to input.</p>
<p><a href="../../../../tf/keras/layers/SimpleRNNCell.html"><code>class SimpleRNNCell</code></a>: Cell class for SimpleRNN.</p>
<p><a href="../../../../tf/keras/layers/Softmax.html"><code>class Softmax</code></a>: Softmax activation function.</p>
<p><a href="../../../../tf/keras/layers/SpatialDropout1D.html"><code>class SpatialDropout1D</code></a>: Spatial 1D version of Dropout.</p>
<p><a href="../../../../tf/keras/layers/SpatialDropout2D.html"><code>class SpatialDropout2D</code></a>: Spatial 2D version of Dropout.</p>
<p><a href="../../../../tf/keras/layers/SpatialDropout3D.html"><code>class SpatialDropout3D</code></a>: Spatial 3D version of Dropout.</p>
<p><a href="../../../../tf/keras/layers/StackedRNNCells.html"><code>class StackedRNNCells</code></a>: Wrapper allowing a stack of RNN cells to behave as a single cell.</p>
<p><a href="../../../../tf/keras/layers/Subtract.html"><code>class Subtract</code></a>: Layer that subtracts two inputs.</p>
<p><a href="../../../../tf/keras/layers/ThresholdedReLU.html"><code>class ThresholdedReLU</code></a>: Thresholded Rectified Linear Unit.</p>
<p><a href="../../../../tf/keras/layers/TimeDistributed.html"><code>class TimeDistributed</code></a>: This wrapper allows to apply a layer to every temporal slice of an input.</p>
<p><a href="../../../../tf/keras/layers/UpSampling1D.html"><code>class UpSampling1D</code></a>: Upsampling layer for 1D inputs.</p>
<p><a href="../../../../tf/keras/layers/UpSampling2D.html"><code>class UpSampling2D</code></a>: Upsampling layer for 2D inputs.</p>
<p><a href="../../../../tf/keras/layers/UpSampling3D.html"><code>class UpSampling3D</code></a>: Upsampling layer for 3D inputs.</p>
<p><a href="../../../../tf/keras/layers/Wrapper.html"><code>class Wrapper</code></a>: Abstract wrapper base class.</p>
<p><a href="../../../../tf/keras/layers/ZeroPadding1D.html"><code>class ZeroPadding1D</code></a>: Zero-padding layer for 1D input (e.g. temporal sequence).</p>
<p><a href="../../../../tf/keras/layers/ZeroPadding2D.html"><code>class ZeroPadding2D</code></a>: Zero-padding layer for 2D input (e.g. picture).</p>
<p><a href="../../../../tf/keras/layers/ZeroPadding3D.html"><code>class ZeroPadding3D</code></a>: Zero-padding layer for 3D data (spatial or spatio-temporal).</p>
<h2 id="functions">Functions</h2>
<p><a href="../../../../tf/keras/Input.html"><code>Input(...)</code></a>: <code>Input()</code> is used to instantiate a Keras tensor.</p>
<p><a href="../../../../tf/keras/layers/add.html"><code>add(...)</code></a>: Functional interface to the <code>Add</code> layer.</p>
<p><a href="../../../../tf/keras/layers/average.html"><code>average(...)</code></a>: Functional interface to the <code>Average</code> layer.</p>
<p><a href="../../../../tf/keras/layers/concatenate.html"><code>concatenate(...)</code></a>: Functional interface to the <code>Concatenate</code> layer.</p>
<p><a href="../../../../tf/keras/layers/deserialize.html"><code>deserialize(...)</code></a>: Instantiates a layer from a config dictionary.</p>
<p><a href="../../../../tf/keras/layers/dot.html"><code>dot(...)</code></a>: Functional interface to the <code>Dot</code> layer.</p>
<p><a href="../../../../tf/keras/layers/maximum.html"><code>maximum(...)</code></a>: Functional interface to the <code>Maximum</code> layer that computes</p>
<p><a href="../../../../tf/keras/layers/minimum.html"><code>minimum(...)</code></a>: Functional interface to the <code>Minimum</code> layer.</p>
<p><a href="../../../../tf/keras/layers/multiply.html"><code>multiply(...)</code></a>: Functional interface to the <code>Multiply</code> layer.</p>
<p><a href="../../../../tf/keras/layers/serialize.html"><code>serialize(...)</code></a></p>
<p><a href="../../../../tf/keras/layers/subtract.html"><code>subtract(...)</code></a>: Functional interface to the <code>Subtract</code> layer.</p>
    </body>
    </html>
   