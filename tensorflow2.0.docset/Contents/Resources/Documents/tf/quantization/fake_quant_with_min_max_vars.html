<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.quantization.fake_quant_with_min_max_vars" />
<meta itemprop="path" content="Stable" />
</div>


<h1>tf.quantization.fake_quant_with_min_max_vars</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p>Defined in generated file: <code>python/ops/gen_array_ops.py</code></p>

<!-- Start diff -->


<p>Fake-quantize the &lsquo;inputs&rsquo; tensor of type float via global float scalars <code>min</code></p>

<h3>Aliases:</h3>

<ul>
<li><code>tf.compat.v1.fake_quant_with_min_max_vars</code></li>
<li><code>tf.compat.v1.quantization.fake_quant_with_min_max_vars</code></li>
<li><code>tf.compat.v2.quantization.fake_quant_with_min_max_vars</code></li>
</ul>


<p><code>python
tf.quantization.fake_quant_with_min_max_vars(
    inputs,
    min,
    max,
    num_bits=8,
    narrow_range=False,
    name=None
)
</code></p>

<!-- Placeholder for "Used in" -->


<p>and <code>max</code> to &lsquo;outputs&rsquo; tensor of same shape as <code>inputs</code>.</p>

<p><code>[min; max]</code> define the clamping range for the <code>inputs</code> data.
<code>inputs</code> values are quantized into the quantization range (<code>[0; 2^num_bits - 1]</code>
when <code>narrow_range</code> is false and <code>[1; 2^num_bits - 1]</code> when it is true) and
then de-quantized and output as floats in <code>[min; max]</code> interval.
<code>num_bits</code> is the bitwidth of the quantization; between 2 and 16, inclusive.</p>

<p>Before quantization, <code>min</code> and <code>max</code> values are adjusted with the following
logic.
It is suggested to have <code>min &lt;= 0 &lt;= max</code>. If <code>0</code> is not in the range of values,
the behavior can be unexpected:
If <code>0 &lt; min &lt; max</code>: <code>min_adj = 0</code> and <code>max_adj = max - min</code>.
If <code>min &lt; max &lt; 0</code>: <code>min_adj = min - max</code> and <code>max_adj = 0</code>.
If <code>min &lt;= 0 &lt;= max</code>: <code>scale = (max - min) / (2^num_bits - 1)</code>,
<code>min_adj = scale * round(min / scale)</code> and <code>max_adj = max + min_adj - min</code>.</p>

<p>This operation has a gradient and thus allows for training <code>min</code> and <code>max</code>
values.</p>

<h4>Args:</h4>

<ul>
<li><b><code>inputs</code></b>: A <code>Tensor</code> of type <code>float32</code>.</li>
<li><b><code>min</code></b>: A <code>Tensor</code> of type <code>float32</code>.</li>
<li><b><code>max</code></b>: A <code>Tensor</code> of type <code>float32</code>.</li>
<li><b><code>num_bits</code></b>: An optional <code>int</code>. Defaults to <code>8</code>.</li>
<li><b><code>narrow_range</code></b>: An optional <code>bool</code>. Defaults to <code>False</code>.</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>


<h4>Returns:</h4>

<p>A <code>Tensor</code> of type <code>float32</code>.</p>
