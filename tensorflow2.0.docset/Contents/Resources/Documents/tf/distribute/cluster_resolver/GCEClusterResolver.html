<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.distribute.cluster_resolver.GCEClusterResolver" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="environment"/>
<meta itemprop="property" content="rpc_layer"/>
<meta itemprop="property" content="task_id"/>
<meta itemprop="property" content="task_type"/>
<meta itemprop="property" content="__init__"/>
<meta itemprop="property" content="cluster_spec"/>
<meta itemprop="property" content="master"/>
<meta itemprop="property" content="num_accelerators"/>
</div>


<h1>tf.distribute.cluster_resolver.GCEClusterResolver</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p><a target="_blank" href="/code/stable/tensorflow/python/distribute/cluster_resolver/gce_cluster_resolver.py">View source</a></p>

<h2>Class <code>GCEClusterResolver</code></h2>

<!-- Start diff -->


<p>ClusterResolver for Google Compute Engine.</p>

<p>Inherits From: <a href="../../../tf/distribute/cluster_resolver/ClusterResolver.html"><code>ClusterResolver</code></a></p>

<h3>Aliases:</h3>

<ul>
<li>Class <code>tf.compat.v1.distribute.cluster_resolver.GCEClusterResolver</code></li>
<li>Class <code>tf.compat.v2.distribute.cluster_resolver.GCEClusterResolver</code></li>
</ul>


<!-- Placeholder for "Used in" -->


<p>This is an implementation of cluster resolvers for the Google Compute Engine
instance group platform. By specifying a project, zone, and instance group,
this will retrieve the IP address of all the instances within the instance
group and return a ClusterResolver object suitable for use for distributed
TensorFlow.</p>

<h2 id="__init__"><code>__init__</code></h2>


<p><a target="_blank" href="/code/stable/tensorflow/python/distribute/cluster_resolver/gce_cluster_resolver.py">View source</a></p>

<p><code>python
__init__(
    project,
    zone,
    instance_group,
    port,
    task_type='worker',
    task_id=0,
    rpc_layer='grpc',
    credentials='default',
    service=None
)
</code></p>

<p>Creates a new GCEClusterResolver object.</p>

<p>This takes in a few parameters and creates a GCEClusterResolver project. It
will then use these parameters to query the GCE API for the IP addresses of
each instance in the instance group.</p>

<h4>Args:</h4>

<ul>
<li><b><code>project</code></b>: Name of the GCE project.</li>
<li><b><code>zone</code></b>: Zone of the GCE instance group.</li>
<li><b><code>instance_group</code></b>: Name of the GCE instance group.</li>
<li><b><code>port</code></b>: Port of the listening TensorFlow server (default: 8470)</li>
<li><b><code>task_type</code></b>: Name of the TensorFlow job this GCE instance group of VM
instances belong to.</li>
<li><b><code>task_id</code></b>: The task index for this particular VM, within the GCE
instance group. In particular, every single instance should be assigned
a unique ordinal index within an instance group manually so that they
can be distinguished from each other.</li>
<li><b><code>rpc_layer</code></b>: The RPC layer TensorFlow should use to communicate across
instances.</li>
<li><b><code>credentials</code></b>: GCE Credentials. If nothing is specified, this defaults to
GoogleCredentials.get_application_default().</li>
<li><b><code>service</code></b>: The GCE API object returned by the googleapiclient.discovery
function. (Default: discovery.build(&lsquo;compute&rsquo;, &lsquo;v1&rsquo;)). If you specify a
custom service object, then the credentials parameter will be ignored.</li>
</ul>


<h4>Raises:</h4>

<ul>
<li><b><code>ImportError</code></b>: If the googleapiclient is not installed.</li>
</ul>


<h2>Properties</h2>

<h3 id="environment"><code>environment</code></h3>


<p>Returns the current environment which TensorFlow is running in.</p>

<p>There are two possible return values, &ldquo;google&rdquo; (when TensorFlow is running
in a Google-internal environment) or an empty string (when TensorFlow is
running elsewhere).</p>

<p>If you are implementing a ClusterResolver that works in both the Google
environment and the open-source world (for instance, a TPU ClusterResolver
or similar), you will have to return the appropriate string depending on the
environment, which you will have to detect.</p>

<p>Otherwise, if you are implementing a ClusterResolver that will only work
in open-source TensorFlow, you do not need to implement this property.</p>

<h3 id="rpc_layer"><code>rpc_layer</code></h3>




<h3 id="task_id"><code>task_id</code></h3>




<h3 id="task_type"><code>task_type</code></h3>


<h2>Methods</h2>

<h3 id="cluster_spec"><code>cluster_spec</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/distribute/cluster_resolver/gce_cluster_resolver.py">View source</a></p>

<p><code>python
cluster_spec()
</code></p>

<p>Returns a ClusterSpec object based on the latest instance group info.</p>

<p>This returns a ClusterSpec object for use based on information from the
specified instance group. We will retrieve the information from the GCE APIs
every time this method is called.</p>

<h4>Returns:</h4>

<p>A ClusterSpec containing host information retrieved from GCE.</p>

<h3 id="master"><code>master</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/distribute/cluster_resolver/gce_cluster_resolver.py">View source</a></p>

<p><code>python
master(
    task_type=None,
    task_id=None,
    rpc_layer=None
)
</code></p>

<p>Retrieves the name or URL of the session master.</p>

<h4>Args:</h4>

<ul>
<li><b><code>task_type</code></b>: (Optional) The type of the TensorFlow task of the master.</li>
<li><b><code>task_id</code></b>: (Optional) The index of the TensorFlow task of the master.</li>
<li><b><code>rpc_layer</code></b>: (Optional) The RPC protocol for the given cluster.</li>
</ul>


<h4>Returns:</h4>

<p>The name or URL of the session master.</p>

<p>Implementors of this function must take care in ensuring that the master
returned is up-to-date at the time to calling this function. This usually
means retrieving the master every time this function is invoked.</p>

<h3 id="num_accelerators"><code>num_accelerators</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/distribute/cluster_resolver/cluster_resolver.py">View source</a></p>

<p><code>python
num_accelerators(
    task_type=None,
    task_id=None,
    config_proto=None
)
</code></p>

<p>Returns the number of accelerator cores per worker.</p>

<p>This returns the number of accelerator cores (such as GPUs and TPUs)
available per worker.</p>

<p>Optionally, we allow callers to specify the task_type, and task_id, for
if they want to target a specific TensorFlow process to query
the number of accelerators. This is to support heterogenous environments,
where the number of accelerators cores per host is different.</p>

<h4>Args:</h4>

<ul>
<li><b><code>task_type</code></b>: (Optional) The type of the TensorFlow task of the machine we
want to query.</li>
<li><b><code>task_id</code></b>: (Optional) The index of the TensorFlow task of the machine we
want to query.</li>
<li><b><code>config_proto</code></b>: (Optional) Configuration for starting a new session to
query how many accelerator cores it has.</li>
</ul>


<h4>Returns:</h4>

<p>A map of accelerator types to number of cores.</p>
