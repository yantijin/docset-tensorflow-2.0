<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.distribute.CrossDeviceOps" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="__init__"/>
<meta itemprop="property" content="batch_reduce"/>
<meta itemprop="property" content="batch_reduce_implementation"/>
<meta itemprop="property" content="broadcast"/>
<meta itemprop="property" content="broadcast_implementation"/>
<meta itemprop="property" content="reduce"/>
<meta itemprop="property" content="reduce_implementation"/>
</div>


<h1>tf.distribute.CrossDeviceOps</h1>

<!-- Insert buttons -->




<table class="tfo-notebook-buttons tfo-api" align="left">
</table>


<p><a target="_blank" href="/code/stable/tensorflow/python/distribute/cross_device_ops.py">View source</a></p>

<h2>Class <code>CrossDeviceOps</code></h2>

<!-- Start diff -->


<p>Base class for cross-device reduction and broadcasting algorithms.</p>

<h3>Aliases:</h3>

<ul>
<li>Class <code>tf.compat.v1.distribute.CrossDeviceOps</code></li>
<li>Class <code>tf.compat.v2.distribute.CrossDeviceOps</code></li>
</ul>


<!-- Placeholder for "Used in" -->




<h2 id="__init__"><code>__init__</code></h2>


<p><a target="_blank" href="/code/stable/tensorflow/python/distribute/cross_device_ops.py">View source</a></p>

<p><code>python
__init__()
</code></p>

<p>Initialize self.  See help(type(self)) for accurate signature.</p>

<h2>Methods</h2>

<h3 id="batch_reduce"><code>batch_reduce</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/distribute/cross_device_ops.py">View source</a></p>

<p><code>python
batch_reduce(
    reduce_op,
    value_destination_pairs
)
</code></p>

<p>Reduce PerReplica objects in a batch.</p>

<p>Reduce each first element in <code>value_destination_pairs</code> to each second
element which indicates the destinations.</p>

<h4>Args:</h4>

<ul>
<li><b><code>reduce_op</code></b>: Indicates how per_replica_value will be reduced. Accepted
values are <a href="../../tf/distribute/ReduceOp.html#SUM"><code>tf.distribute.ReduceOp.SUM</code></a>, <a href="../../tf/distribute/ReduceOp.html#MEAN"><code>tf.distribute.ReduceOp.MEAN</code></a>.</li>
<li><b><code>value_destination_pairs</code></b>: a list or a tuple of tuples of PerReplica objects
(or tensors with device set if there is one device) and destinations.</li>
</ul>


<h4>Returns:</h4>

<p>a list of Mirrored objects.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: if <code>value_destination_pairs</code> is not a list or a tuple of
tuples of PerReplica objects and destinations</li>
</ul>


<h3 id="batch_reduce_implementation"><code>batch_reduce_implementation</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/distribute/cross_device_ops.py">View source</a></p>

<p><code>python
batch_reduce_implementation(
    reduce_op,
    value_destination_pairs
)
</code></p>

<p>Implementation of reduce PerReplica objects in a batch.</p>

<p>Reduce each first element in <code>value_destination_pairs</code> to each second
element which indicates the destinations.</p>

<h4>Args:</h4>

<ul>
<li><b><code>reduce_op</code></b>: Indicates how per_replica_value will be reduced. Accepted
values are <a href="../../tf/distribute/ReduceOp.html#SUM"><code>tf.distribute.ReduceOp.SUM</code></a>, <a href="../../tf/distribute/ReduceOp.html#MEAN"><code>tf.distribute.ReduceOp.MEAN</code></a>.</li>
<li><b><code>value_destination_pairs</code></b>: a list or a tuple of tuples of PerReplica objects
(or tensors with device set if there is one device) and destinations.</li>
</ul>


<h4>Returns:</h4>

<p>a list of Mirrored objects.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: if <code>value_destination_pairs</code> is not a list or a tuple of
tuples of PerReplica objects and destinations</li>
</ul>


<h3 id="broadcast"><code>broadcast</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/distribute/cross_device_ops.py">View source</a></p>

<p><code>python
broadcast(
    tensor,
    destinations
)
</code></p>

<p>Broadcast the <code>tensor</code> to destinations.</p>

<h4>Args:</h4>

<ul>
<li><b><code>tensor</code></b>: the tensor to broadcast.</li>
<li><b><code>destinations</code></b>: the broadcast destinations.</li>
</ul>


<h4>Returns:</h4>

<p>a Mirrored object.</p>

<h3 id="broadcast_implementation"><code>broadcast_implementation</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/distribute/cross_device_ops.py">View source</a></p>

<p><code>python
broadcast_implementation(
    tensor,
    destinations
)
</code></p>

<p>Implementation of broadcast the <code>tensor</code> to destinations.</p>

<h4>Args:</h4>

<ul>
<li><b><code>tensor</code></b>: the tensor to broadcast.</li>
<li><b><code>destinations</code></b>: the broadcast destinations.</li>
</ul>


<h4>Returns:</h4>

<p>a Mirrored object.</p>

<h3 id="reduce"><code>reduce</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/distribute/cross_device_ops.py">View source</a></p>

<p><code>python
reduce(
    reduce_op,
    per_replica_value,
    destinations
)
</code></p>

<p>Reduce <code>per_replica_value</code> to <code>destinations</code>.</p>

<p>It runs the reduction operation defined by <code>reduce_op</code> and put the
result on <code>destinations</code>.</p>

<h4>Args:</h4>

<ul>
<li><b><code>reduce_op</code></b>: Indicates how per_replica_value will be reduced. Accepted
values are <a href="../../tf/distribute/ReduceOp.html#SUM"><code>tf.distribute.ReduceOp.SUM</code></a>, <a href="../../tf/distribute/ReduceOp.html#MEAN"><code>tf.distribute.ReduceOp.MEAN</code></a>.</li>
<li><b><code>per_replica_value</code></b>: a PerReplica object or a tensor with device set.</li>
<li><b><code>destinations</code></b>: the reduction destinations.</li>
</ul>


<h4>Returns:</h4>

<p>a Mirrored object.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: if per_replica_value can&rsquo;t be converted to a PerReplica
object.</li>
</ul>


<h3 id="reduce_implementation"><code>reduce_implementation</code></h3>


<p><a target="_blank" href="/code/stable/tensorflow/python/distribute/cross_device_ops.py">View source</a></p>

<p><code>python
reduce_implementation(
    reduce_op,
    per_replica_value,
    destinations
)
</code></p>

<p>The implementation of reduce of <code>per_replica_value</code> to <code>destinations</code>.</p>

<p>It runs the reduction operation defined by <code>reduce_op</code> and put the
result on <code>destinations</code>.</p>

<h4>Args:</h4>

<ul>
<li><b><code>reduce_op</code></b>: Indicates how per_replica_value will be reduced. Accepted
values are <a href="../../tf/distribute/ReduceOp.html#SUM"><code>tf.distribute.ReduceOp.SUM</code></a>, <a href="../../tf/distribute/ReduceOp.html#MEAN"><code>tf.distribute.ReduceOp.MEAN</code></a>.</li>
<li><b><code>per_replica_value</code></b>: a PerReplica object or a tensor with device set.</li>
<li><b><code>destinations</code></b>: the reduction destinations.</li>
</ul>


<h4>Returns:</h4>

<p>a Mirrored object.</p>

<h4>Raises:</h4>

<ul>
<li><b><code>ValueError</code></b>: if per_replica_value can&rsquo;t be converted to a PerReplica
object.</li>
</ul>

