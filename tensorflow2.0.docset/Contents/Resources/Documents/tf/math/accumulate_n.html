
    <html lang="zh-cn">
    <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <link href=../../../default.css" rel="stylesheet">
    <link href="
   ../../../github.css" rel="stylesheet">
    </head>
    <body>
    <div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.math.accumulate_n" />
<meta itemprop="path" content="Stable" />
</div>

<h1 id="tfmathaccumulate_n">tf.math.accumulate_n</h1>
<!-- Insert buttons -->

<table class="tfo-notebook-buttons tfo-api" align="left">
</table>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/math_ops.py">View source</a></p>
<!-- Start diff -->

<p>Returns the element-wise sum of a list of tensors.</p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li><code>tf.compat.v1.accumulate_n</code></li>
<li><code>tf.compat.v1.math.accumulate_n</code></li>
<li><code>tf.compat.v2.math.accumulate_n</code></li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">accumulate_n</span><span class="p">(</span>
    <span class="n">inputs</span><span class="p">,</span>
    <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">tensor_dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</pre></div>


<!-- Placeholder for "Used in" -->

<p>Optionally, pass <code>shape</code> and <code>tensor_dtype</code> for shape and type checking,
otherwise, these are inferred.</p>
<p><code>accumulate_n</code> performs the same operation as <a href="../../tf/math/add_n.html"><code>tf.math.add_n</code></a>, but
does not wait for all of its inputs to be ready before beginning to sum.
This approach can save memory if inputs are ready at different times, since
minimum temporary storage is proportional to the output size rather than the
inputs' size.</p>
<p><code>accumulate_n</code> is differentiable (but wasn't previous to TensorFlow 1.7).</p>
<h4 id="for-example">For example:</h4>
<div class="codehilite"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">accumulate_n</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">a</span><span class="p">])</span>  <span class="c1"># [[7, 4], [6, 14]]</span>

<span class="c1"># Explicitly pass shape and type</span>
<span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">accumulate_n</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">a</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">tensor_dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
                                                               <span class="c1"># [[7,  4],</span>
                                                               <span class="c1">#  [6, 14]]</span>
</pre></div>


<h4 id="args">Args:</h4>
<ul>
<li><b><code>inputs</code></b>: A list of <code>Tensor</code> objects, each with same shape and type.</li>
<li><b><code>shape</code></b>: Expected shape of elements of <code>inputs</code> (optional). Also controls the
  output shape of this op, which may affect type inference in other ops. A
  value of <code>None</code> means "infer the input shape from the shapes in <code>inputs</code>".</li>
<li><b><code>tensor_dtype</code></b>: Expected data type of <code>inputs</code> (optional). A value of <code>None</code>
  means "infer the input dtype from <code>inputs[0]</code>".</li>
<li><b><code>name</code></b>: A name for the operation (optional).</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A <code>Tensor</code> of same shape and type as the elements of <code>inputs</code>.</p>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: If <code>inputs</code> don't all have same shape and dtype or the shape
cannot be inferred.</li>
</ul>
    </body>
    </html>
   