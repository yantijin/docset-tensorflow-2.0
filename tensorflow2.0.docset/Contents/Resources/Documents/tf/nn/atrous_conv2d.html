
    <html lang="zh-cn">
    <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <link href="../../../default.css" rel="stylesheet">
    <link href="
   ../../../github.css" rel="stylesheet">
    </head>
    <body>
    <div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.nn.atrous_conv2d" />
<meta itemprop="path" content="Stable" />
</div>

<h1 id="tfnnatrous_conv2d">tf.nn.atrous_conv2d</h1>
<!-- Insert buttons -->

<table class="tfo-notebook-buttons tfo-api" align="left">
</table>

<p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/ops/nn_ops.py">View source</a></p>
<!-- Start diff -->

<p>Atrous convolution (a.k.a. convolution with holes or dilated convolution).</p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li><code>tf.compat.v1.nn.atrous_conv2d</code></li>
<li><code>tf.compat.v2.nn.atrous_conv2d</code></li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">atrous_conv2d</span><span class="p">(</span>
    <span class="n">value</span><span class="p">,</span>
    <span class="n">filters</span><span class="p">,</span>
    <span class="n">rate</span><span class="p">,</span>
    <span class="n">padding</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</pre></div>


<!-- Placeholder for "Used in" -->

<p>This function is a simpler wrapper around the more general
<a href="../../tf/nn/convolution.html"><code>tf.nn.convolution</code></a>, and exists only for backwards compatibility. You can
use <a href="../../tf/nn/convolution.html"><code>tf.nn.convolution</code></a> to perform 1-D, 2-D, or 3-D atrous convolution.</p>
<p>Computes a 2-D atrous convolution, also known as convolution with holes or
dilated convolution, given 4-D <code>value</code> and <code>filters</code> tensors. If the <code>rate</code>
parameter is equal to one, it performs regular 2-D convolution. If the <code>rate</code>
parameter is greater than one, it performs convolution with holes, sampling
the input values every <code>rate</code> pixels in the <code>height</code> and <code>width</code> dimensions.
This is equivalent to convolving the input with a set of upsampled filters,
produced by inserting <code>rate - 1</code> zeros between two consecutive values of the
filters along the <code>height</code> and <code>width</code> dimensions, hence the name atrous
convolution or convolution with holes (the French word trous means holes in
English).</p>
<h4 id="more-specifically">More specifically:</h4>
<div class="codehilite"><pre><span></span><span class="err">output[batch, height, width, out_channel] =</span>
<span class="err">    sum_{dheight, dwidth, in_channel} (</span>
<span class="err">        filters[dheight, dwidth, in_channel, out_channel] *</span>
<span class="err">        value[batch, height + rate*dheight, width + rate*dwidth, in_channel]</span>
<span class="err">    )</span>
</pre></div>


<p>Atrous convolution allows us to explicitly control how densely to compute
feature responses in fully convolutional networks. Used in conjunction with
bilinear interpolation, it offers an alternative to <code>conv2d_transpose</code> in
dense prediction tasks such as semantic image segmentation, optical flow
computation, or depth estimation. It also allows us to effectively enlarge
the field of view of filters without increasing the number of parameters or
the amount of computation.</p>
<p>For a description of atrous convolution and how it can be used for dense
feature extraction, please see: <a href="http://arxiv.org/abs/1412.7062">Semantic Image Segmentation with Deep
Convolutional Nets and Fully Connected CRFs</a>.
The same operation is investigated further in <a href="http://arxiv.org/abs/1511.07122">Multi-Scale Context Aggregation
by Dilated Convolutions</a>. Previous works
that effectively use atrous convolution in different ways are, among others,
<a href="http://arxiv.org/abs/1312.6229">OverFeat: Integrated Recognition, Localization and Detection using
Convolutional Networks</a> and <a href="http://arxiv.org/abs/1302.1700">Fast Image
Scanning with Deep Max-Pooling Convolutional Neural
Networks</a>.
Atrous convolution is also closely related to the so-called noble identities
in multi-rate signal processing.</p>
<p>There are many different ways to implement atrous convolution (see the refs
above). The implementation here reduces</p>
<div class="codehilite"><pre><span></span>    <span class="n">atrous_conv2d</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">)</span>
</pre></div>


<p>to the following three operations:</p>
<div class="codehilite"><pre><span></span>    <span class="n">paddings</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">space_to_batch</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="n">rate</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">conv2d</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;VALID&quot;</span><span class="p">)</span>
    <span class="n">crops</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">batch_to_space</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">crops</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="n">rate</span><span class="p">)</span>
</pre></div>


<p>Advanced usage. Note the following optimization: A sequence of <code>atrous_conv2d</code>
operations with identical <code>rate</code> parameters, 'SAME' <code>padding</code>, and filters
with odd heights/ widths:</p>
<div class="codehilite"><pre><span></span>    <span class="n">net</span> <span class="o">=</span> <span class="n">atrous_conv2d</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">filters1</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;SAME&quot;</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">atrous_conv2d</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">filters2</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;SAME&quot;</span><span class="p">)</span>
    <span class="o">...</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">atrous_conv2d</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">filtersK</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;SAME&quot;</span><span class="p">)</span>
</pre></div>


<p>can be equivalently performed cheaper in terms of computation and memory as:</p>
<div class="codehilite"><pre><span></span>    <span class="n">pad</span> <span class="o">=</span> <span class="o">...</span>  <span class="c1"># padding so that the input dims are multiples of rate</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">space_to_batch</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">paddings</span><span class="o">=</span><span class="n">pad</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="n">rate</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">conv2d</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">filters1</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;SAME&quot;</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">conv2d</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">filters2</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;SAME&quot;</span><span class="p">)</span>
    <span class="o">...</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">conv2d</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">filtersK</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;SAME&quot;</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">batch_to_space</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">crops</span><span class="o">=</span><span class="n">pad</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="n">rate</span><span class="p">)</span>
</pre></div>


<p>because a pair of consecutive <code>space_to_batch</code> and <code>batch_to_space</code> ops with
the same <code>block_size</code> cancel out when their respective <code>paddings</code> and <code>crops</code>
inputs are identical.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>value</code></b>: A 4-D <code>Tensor</code> of type <code>float</code>. It needs to be in the default "NHWC"
  format. Its shape is <code>[batch, in_height, in_width, in_channels]</code>.</li>
<li><b><code>filters</code></b>: A 4-D <code>Tensor</code> with the same type as <code>value</code> and shape
  <code>[filter_height, filter_width, in_channels, out_channels]</code>. <code>filters</code>'
  <code>in_channels</code> dimension must match that of <code>value</code>. Atrous convolution is
  equivalent to standard convolution with upsampled filters with effective
  height <code>filter_height + (filter_height - 1) * (rate - 1)</code> and effective
  width <code>filter_width + (filter_width - 1) * (rate - 1)</code>, produced by
  inserting <code>rate - 1</code> zeros along consecutive elements across the
  <code>filters</code>' spatial dimensions.</li>
<li><b><code>rate</code></b>: A positive int32. The stride with which we sample input values across
  the <code>height</code> and <code>width</code> dimensions. Equivalently, the rate by which we
  upsample the filter values by inserting zeros across the <code>height</code> and
  <code>width</code> dimensions. In the literature, the same parameter is sometimes
  called <code>input stride</code> or <code>dilation</code>.</li>
<li><b><code>padding</code></b>: A string, either <code>'VALID'</code> or <code>'SAME'</code>. The padding algorithm.</li>
<li><b><code>name</code></b>: Optional name for the returned tensor.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A <code>Tensor</code> with the same type as <code>value</code>.
Output shape with <code>'VALID'</code> padding is:</p>
<div class="codehilite"><pre><span></span><span class="err">[batch, height - 2 * (filter_width - 1),</span>
<span class="err"> width - 2 * (filter_height - 1), out_channels].</span>
</pre></div>


<p>Output shape with <code>'SAME'</code> padding is:</p>
<div class="codehilite"><pre><span></span><span class="err">[batch, height, width, out_channels].</span>
</pre></div>


<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: If input/output depth does not match <code>filters</code>' shape, or if
  padding is other than <code>'VALID'</code> or <code>'SAME'</code>.</li>
</ul>
    </body>
    </html>
   