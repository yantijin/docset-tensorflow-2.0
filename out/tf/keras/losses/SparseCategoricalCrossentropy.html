
    <html lang="zh-cn">
    <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <link href="../../../../default.css" rel="stylesheet">
    <link href="
   ../../../../github.css" rel="stylesheet">
    </head>
    <body>
    <div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.keras.losses.SparseCategoricalCrossentropy" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="__call__"/>
<meta itemprop="property" content="__init__"/>
<meta itemprop="property" content="from_config"/>
<meta itemprop="property" content="get_config"/>
</div>

<h1 id="tfkeraslossessparsecategoricalcrossentropy">tf.keras.losses.SparseCategoricalCrossentropy</h1>
<!-- Insert buttons -->

<table class="tfo-notebook-buttons tfo-api" align="left">
</table>

<p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/losses.py">View source</a></p>
<h2 id="class-sparsecategoricalcrossentropy">Class <code>SparseCategoricalCrossentropy</code></h2>
<!-- Start diff -->

<p>Computes the crossentropy loss between the labels and predictions.</p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li>Class <code>tf.compat.v1.keras.losses.SparseCategoricalCrossentropy</code></li>
<li>Class <code>tf.compat.v2.keras.losses.SparseCategoricalCrossentropy</code></li>
<li>Class <code>tf.compat.v2.losses.SparseCategoricalCrossentropy</code></li>
<li>Class <code>tf.losses.SparseCategoricalCrossentropy</code></li>
</ul>
<!-- Placeholder for "Used in" -->

<p>Use this crossentropy loss function when there are two or more label classes.
We expect labels to be provided as integers. If you want to provide labels
using <code>one-hot</code> representation, please use <code>CategoricalCrossentropy</code> loss.
There should be <code># classes</code> floating point values per feature for <code>y_pred</code>
and a single floating point value per feature for <code>y_true</code>.</p>
<p>In the snippet below, there is a single floating point value per example for
<code>y_true</code> and <code># classes</code> floating pointing values per example for <code>y_pred</code>.
The shape of <code>y_true</code> is <code>[batch_size]</code> and the shape of <code>y_pred</code> is
<code>[batch_size, num_classes]</code>.</p>
<h4 id="usage">Usage:</h4>
<div class="codehilite"><pre><span></span><span class="n">cce</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">cce</span><span class="p">(</span>
  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
  <span class="p">[[</span><span class="o">.</span><span class="mi">9</span><span class="p">,</span> <span class="o">.</span><span class="mi">05</span><span class="p">,</span> <span class="o">.</span><span class="mi">05</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">89</span><span class="p">,</span> <span class="o">.</span><span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">05</span><span class="p">,</span> <span class="o">.</span><span class="mi">01</span><span class="p">,</span> <span class="o">.</span><span class="mi">94</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Loss: &#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>  <span class="c1"># Loss: 0.3239</span>
</pre></div>


<p>Usage with the <code>compile</code> API:</p>
<div class="codehilite"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s1">&#39;sgd&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">())</span>
</pre></div>


<h4 id="args">Args:</h4>
<ul>
<li><b><code>from_logits</code></b>: Whether <code>y_pred</code> is expected to be a logits tensor. By default,
  we assume that <code>y_pred</code> encodes a probability distribution.
  Note: Using from_logits=True may be more numerically stable.</li>
<li><b><code>reduction</code></b>: (Optional) Type of <a href="../../../tf/keras/losses/Reduction.html"><code>tf.keras.losses.Reduction</code></a> to apply to loss.
  Default value is <code>AUTO</code>. <code>AUTO</code> indicates that the reduction option will
  be determined by the usage context. For almost all cases this defaults to
  <code>SUM_OVER_BATCH_SIZE</code>.
  When used with <a href="../../../tf/distribute/Strategy.html"><code>tf.distribute.Strategy</code></a>, outside of built-in training
  loops such as <a href="../../../tf/keras.html"><code>tf.keras</code></a> <code>compile</code> and <code>fit</code>, using <code>AUTO</code> or
  <code>SUM_OVER_BATCH_SIZE</code> will raise an error. Please see
  https://www.tensorflow.org/alpha/tutorials/distribute/training_loops
  for more details on this.</li>
<li><b><code>name</code></b>: Optional name for the op.</li>
</ul>
<h2 id="__init__"><code>__init__</code></h2>

<p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/losses.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="fm">__init__</span><span class="p">(</span>
    <span class="n">from_logits</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">reduction</span><span class="o">=</span><span class="n">losses_utils</span><span class="o">.</span><span class="n">ReductionV2</span><span class="o">.</span><span class="n">AUTO</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span>
<span class="p">)</span>
</pre></div>


<p>Initialize self.  See help(type(self)) for accurate signature.</p>
<h2 id="methods">Methods</h2>
<h3 id="__call__"><code>__call__</code></h3>

<p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/losses.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="fm">__call__</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</pre></div>


<p>Invokes the <code>Loss</code> instance.</p>
<h4 id="args_1">Args:</h4>
<ul>
<li><b><code>y_true</code></b>: Ground truth values. shape = <code>[batch_size, d0, .. dN]</code></li>
<li><b><code>y_pred</code></b>: The predicted values. shape = <code>[batch_size, d0, .. dN]</code></li>
<li><b><code>sample_weight</code></b>: Optional <code>sample_weight</code> acts as a
  coefficient for the loss. If a scalar is provided, then the loss is
  simply scaled by the given value. If <code>sample_weight</code> is a tensor of size
  <code>[batch_size]</code>, then the total loss for each sample of the batch is
  rescaled by the corresponding element in the <code>sample_weight</code> vector. If
  the shape of <code>sample_weight</code> is <code>[batch_size, d0, .. dN-1]</code> (or can be
  broadcasted to this shape), then each loss element of <code>y_pred</code> is scaled
  by the corresponding value of <code>sample_weight</code>. (Note on<code>dN-1</code>: all loss
  functions reduce by 1 dimension, usually axis=-1.)</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>Weighted loss float <code>Tensor</code>. If <code>reduction</code> is <code>NONE</code>, this has
  shape <code>[batch_size, d0, .. dN-1]</code>; otherwise, it is scalar. (Note <code>dN-1</code>
  because all loss functions reduce by 1 dimension, usually axis=-1.)</p>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: If the shape of <code>sample_weight</code> is invalid.</li>
</ul>
<h3 id="from_config"><code>from_config</code></h3>

<p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/losses.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">from_config</span><span class="p">(</span>
    <span class="bp">cls</span><span class="p">,</span>
    <span class="n">config</span>
<span class="p">)</span>
</pre></div>


<p>Instantiates a <code>Loss</code> from its config (output of <code>get_config()</code>).</p>
<h4 id="args_2">Args:</h4>
<ul>
<li><b><code>config</code></b>: Output of <code>get_config()</code>.</li>
</ul>
<h4 id="returns_1">Returns:</h4>
<p>A <code>Loss</code> instance.</p>
<h3 id="get_config"><code>get_config</code></h3>

<p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/losses.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">get_config</span><span class="p">()</span>
</pre></div>
    </body>
    </html>
   