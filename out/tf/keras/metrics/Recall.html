
    <html lang="zh-cn">
    <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <link href="../../../../default.css" rel="stylesheet">
    <link href="
   ../../../../github.css" rel="stylesheet">
    </head>
    <body>
    <div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.keras.metrics.Recall" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="__init__"/>
<meta itemprop="property" content="__new__"/>
<meta itemprop="property" content="reset_states"/>
<meta itemprop="property" content="result"/>
<meta itemprop="property" content="update_state"/>
</div>

<h1 id="tfkerasmetricsrecall">tf.keras.metrics.Recall</h1>
<!-- Insert buttons -->

<table class="tfo-notebook-buttons tfo-api" align="left">
</table>

<p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/metrics.py">View source</a></p>
<h2 id="class-recall">Class <code>Recall</code></h2>
<!-- Start diff -->

<p>Computes the recall of the predictions with respect to the labels.</p>
<p>Inherits From: <a href="../../../tf/keras/metrics/Metric.html"><code>Metric</code></a></p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li>Class <code>tf.compat.v1.keras.metrics.Recall</code></li>
<li>Class <code>tf.compat.v2.keras.metrics.Recall</code></li>
<li>Class <code>tf.compat.v2.metrics.Recall</code></li>
<li>Class <code>tf.metrics.Recall</code></li>
</ul>
<!-- Placeholder for "Used in" -->

<p>For example, if <code>y_true</code> is [0, 1, 1, 1] and <code>y_pred</code> is [1, 0, 1, 1]
then the recall value is 2/(2+1) ie. 0.66. If the weights were specified as
[0, 0, 1, 0] then the recall value would be 1.</p>
<p>This metric creates two local variables, <code>true_positives</code> and
<code>false_negatives</code>, that are used to compute the recall. This value is
ultimately returned as <code>recall</code>, an idempotent operation that simply divides
<code>true_positives</code> by the sum of <code>true_positives</code> and <code>false_negatives</code>.</p>
<p>If <code>sample_weight</code> is <code>None</code>, weights default to 1.
Use <code>sample_weight</code> of 0 to mask values.</p>
<p>If <code>top_k</code> is set, recall will be computed as how often on average a class
among the labels of a batch entry is in the top-k predictions.</p>
<p>If <code>class_id</code> is specified, we calculate recall by considering only the
entries in the batch for which <code>class_id</code> is in the label, and computing the
fraction of them for which <code>class_id</code> is above the threshold and/or in the
top-k predictions.</p>
<h4 id="usage">Usage:</h4>
<div class="codehilite"><pre><span></span><span class="n">m</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Recall</span><span class="p">()</span>
<span class="n">m</span><span class="o">.</span><span class="n">update_state</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Final result: &#39;</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>  <span class="c1"># Final result: 0.66</span>
</pre></div>


<p>Usage with tf.keras API:</p>
<div class="codehilite"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s1">&#39;sgd&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Recall</span><span class="p">()])</span>
</pre></div>


<h2 id="__init__"><code>__init__</code></h2>

<p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/metrics.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="fm">__init__</span><span class="p">(</span>
    <span class="n">thresholds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">top_k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">class_id</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</pre></div>


<p>Creates a <code>Recall</code> instance.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>thresholds</code></b>: (Optional) A float value or a python list/tuple of float
  threshold values in [0, 1]. A threshold is compared with prediction
  values to determine the truth value of predictions (i.e., above the
  threshold is <code>true</code>, below is <code>false</code>). One metric value is generated
  for each threshold value. If neither thresholds nor top_k are set, the
  default is to calculate recall with <code>thresholds=0.5</code>.</li>
<li><b><code>top_k</code></b>: (Optional) Unset by default. An int value specifying the top-k
  predictions to consider when calculating recall.</li>
<li><b><code>class_id</code></b>: (Optional) Integer class ID for which we want binary metrics.
  This must be in the half-open interval <code>[0, num_classes)</code>, where
  <code>num_classes</code> is the last dimension of predictions.</li>
<li><b><code>name</code></b>: (Optional) string name of the metric instance.</li>
<li><b><code>dtype</code></b>: (Optional) data type of the metric result.</li>
</ul>
<h2 id="__new__"><code>__new__</code></h2>

<p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/metrics.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="fm">__new__</span><span class="p">(</span>
    <span class="bp">cls</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</pre></div>


<p>Create and return a new object.  See help(type) for accurate signature.</p>
<h2 id="methods">Methods</h2>
<h3 id="reset_states"><code>reset_states</code></h3>

<p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/metrics.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">reset_states</span><span class="p">()</span>
</pre></div>


<p>Resets all of the metric state variables.</p>
<p>This function is called between epochs/steps,
when a metric is evaluated during training.</p>
<h3 id="result"><code>result</code></h3>

<p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/metrics.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">result</span><span class="p">()</span>
</pre></div>


<p>Computes and returns the metric value tensor.</p>
<p>Result computation is an idempotent operation that simply calculates the
metric value using the state variables.</p>
<h3 id="update_state"><code>update_state</code></h3>

<p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/metrics.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">update_state</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</pre></div>


<p>Accumulates true positive and false negative statistics.</p>
<h4 id="args_1">Args:</h4>
<ul>
<li><b><code>y_true</code></b>: The ground truth values, with the same dimensions as <code>y_pred</code>.
  Will be cast to <code>bool</code>.</li>
<li><b><code>y_pred</code></b>: The predicted values. Each element must be in the range <code>[0, 1]</code>.</li>
<li><b><code>sample_weight</code></b>: Optional weighting of each example. Defaults to 1. Can be a
  <code>Tensor</code> whose rank is either 0, or the same rank as <code>y_true</code>, and must
  be broadcastable to <code>y_true</code>.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>Update op.</p>
    </body>
    </html>
   