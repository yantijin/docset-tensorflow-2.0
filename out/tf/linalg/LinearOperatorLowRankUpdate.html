
    <html lang="zh-cn">
    <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <link href=../../../default.css" rel="stylesheet">
    <link href="
   ../../../github.css" rel="stylesheet">
    </head>
    <body>
    <div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.linalg.LinearOperatorLowRankUpdate" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="H"/>
<meta itemprop="property" content="base_operator"/>
<meta itemprop="property" content="batch_shape"/>
<meta itemprop="property" content="diag_operator"/>
<meta itemprop="property" content="diag_update"/>
<meta itemprop="property" content="domain_dimension"/>
<meta itemprop="property" content="dtype"/>
<meta itemprop="property" content="graph_parents"/>
<meta itemprop="property" content="is_diag_update_positive"/>
<meta itemprop="property" content="is_non_singular"/>
<meta itemprop="property" content="is_positive_definite"/>
<meta itemprop="property" content="is_self_adjoint"/>
<meta itemprop="property" content="is_square"/>
<meta itemprop="property" content="range_dimension"/>
<meta itemprop="property" content="shape"/>
<meta itemprop="property" content="tensor_rank"/>
<meta itemprop="property" content="u"/>
<meta itemprop="property" content="v"/>
<meta itemprop="property" content="__init__"/>
<meta itemprop="property" content="add_to_tensor"/>
<meta itemprop="property" content="adjoint"/>
<meta itemprop="property" content="assert_non_singular"/>
<meta itemprop="property" content="assert_positive_definite"/>
<meta itemprop="property" content="assert_self_adjoint"/>
<meta itemprop="property" content="batch_shape_tensor"/>
<meta itemprop="property" content="cholesky"/>
<meta itemprop="property" content="determinant"/>
<meta itemprop="property" content="diag_part"/>
<meta itemprop="property" content="domain_dimension_tensor"/>
<meta itemprop="property" content="inverse"/>
<meta itemprop="property" content="log_abs_determinant"/>
<meta itemprop="property" content="matmul"/>
<meta itemprop="property" content="matvec"/>
<meta itemprop="property" content="range_dimension_tensor"/>
<meta itemprop="property" content="shape_tensor"/>
<meta itemprop="property" content="solve"/>
<meta itemprop="property" content="solvevec"/>
<meta itemprop="property" content="tensor_rank_tensor"/>
<meta itemprop="property" content="to_dense"/>
<meta itemprop="property" content="trace"/>
</div>

<h1 id="tflinalglinearoperatorlowrankupdate">tf.linalg.LinearOperatorLowRankUpdate</h1>
<!-- Insert buttons -->

<table class="tfo-notebook-buttons tfo-api" align="left">
</table>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator_low_rank_update.py">View source</a></p>
<h2 id="class-linearoperatorlowrankupdate">Class <code>LinearOperatorLowRankUpdate</code></h2>
<!-- Start diff -->

<p>Perturb a <code>LinearOperator</code> with a rank <code>K</code> update.</p>
<p>Inherits From: <a href="../../tf/linalg/LinearOperator.html"><code>LinearOperator</code></a></p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li>Class <code>tf.compat.v1.linalg.LinearOperatorLowRankUpdate</code></li>
<li>Class <code>tf.compat.v2.linalg.LinearOperatorLowRankUpdate</code></li>
</ul>
<!-- Placeholder for "Used in" -->

<p>This operator acts like a [batch] matrix <code>A</code> with shape
<code>[B1,...,Bb, M, N]</code> for some <code>b &gt;= 0</code>.  The first <code>b</code> indices index a
batch member.  For every batch index <code>(i1,...,ib)</code>, <code>A[i1,...,ib, : :]</code> is
an <code>M x N</code> matrix.</p>
<p><code>LinearOperatorLowRankUpdate</code> represents <code>A = L + U D V^H</code>, where</p>
<div class="codehilite"><pre><span></span><span class="n">L</span><span class="p">,</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">LinearOperator</span><span class="w"> </span><span class="n">representing</span><span class="w"> </span><span class="o">[</span><span class="n">batch</span><span class="o">]</span><span class="w"> </span><span class="n">M</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="n">matrices</span><span class="w"></span>
<span class="n">U</span><span class="p">,</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">[</span><span class="n">batch</span><span class="o">]</span><span class="w"> </span><span class="n">M</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="n">K</span><span class="w"> </span><span class="n">matrix</span><span class="p">.</span><span class="w">  </span><span class="n">Typically</span><span class="w"> </span><span class="n">K</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">M</span><span class="p">.</span><span class="w"></span>
<span class="n">D</span><span class="p">,</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">[</span><span class="n">batch</span><span class="o">]</span><span class="w"> </span><span class="n">K</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="n">K</span><span class="w"> </span><span class="n">matrix</span><span class="p">.</span><span class="w"></span>
<span class="n">V</span><span class="p">,</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">[</span><span class="n">batch</span><span class="o">]</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="n">K</span><span class="w"> </span><span class="n">matrix</span><span class="p">.</span><span class="w">  </span><span class="n">Typically</span><span class="w"> </span><span class="n">K</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">.</span><span class="w"></span>
<span class="n">V</span><span class="o">^</span><span class="n">H</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Hermitian</span><span class="w"> </span><span class="n">transpose</span><span class="w"> </span><span class="p">(</span><span class="n">adjoint</span><span class="p">)</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">V</span><span class="p">.</span><span class="w"></span>
</pre></div>


<p>If <code>M = N</code>, determinants and solves are done using the matrix determinant
lemma and Woodbury identities, and thus require L and D to be non-singular.</p>
<p>Solves and determinants will be attempted unless the "is_non_singular"
property of L and D is False.</p>
<p>In the event that L and D are positive-definite, and U = V, solves and
determinants can be done using a Cholesky factorization.</p>
<div class="codehilite"><pre><span></span><span class="c1"># Create a 3 x 3 diagonal linear operator.</span>
<span class="n">diag_operator</span> <span class="o">=</span> <span class="n">LinearOperatorDiag</span><span class="p">(</span>
    <span class="n">diag_update</span><span class="o">=</span><span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span> <span class="n">is_non_singular</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">is_self_adjoint</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">is_positive_definite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Perturb with a rank 2 perturbation</span>
<span class="n">operator</span> <span class="o">=</span> <span class="n">LinearOperatorLowRankUpdate</span><span class="p">(</span>
    <span class="n">operator</span><span class="o">=</span><span class="n">diag_operator</span><span class="p">,</span>
    <span class="n">u</span><span class="o">=</span><span class="p">[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]],</span>
    <span class="n">diag_update</span><span class="o">=</span><span class="p">[</span><span class="mf">11.</span><span class="p">,</span> <span class="mf">12.</span><span class="p">],</span>
    <span class="n">v</span><span class="o">=</span><span class="p">[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span> <span class="p">[</span><span class="mf">10.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">]])</span>

<span class="n">operator</span><span class="o">.</span><span class="n">shape</span>
<span class="o">==&gt;</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>

<span class="n">operator</span><span class="o">.</span><span class="n">log_abs_determinant</span><span class="p">()</span>
<span class="o">==&gt;</span> <span class="n">scalar</span> <span class="n">Tensor</span>

<span class="n">x</span> <span class="o">=</span> <span class="o">...</span> <span class="n">Shape</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span> <span class="n">Tensor</span>
<span class="n">operator</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="o">==&gt;</span> <span class="n">Shape</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span> <span class="n">Tensor</span>
</pre></div>


<h3 id="shape-compatibility">Shape compatibility</h3>
<p>This operator acts on [batch] matrix with compatible shape.
<code>x</code> is a batch matrix with compatible shape for <code>matmul</code> and <code>solve</code> if</p>
<div class="codehilite"><pre><span></span><span class="err">operator.shape = [B1,...,Bb] + [M, N],  with b &gt;= 0</span>
<span class="err">x.shape =        [B1,...,Bb] + [N, R],  with R &gt;= 0.</span>
</pre></div>


<h3 id="performance">Performance</h3>
<p>Suppose <code>operator</code> is a <code>LinearOperatorLowRankUpdate</code> of shape <code>[M, N]</code>,
made from a rank <code>K</code> update of <code>base_operator</code> which performs <code>.matmul(x)</code> on
<code>x</code> having <code>x.shape = [N, R]</code> with <code>O(L_matmul*N*R)</code> complexity (and similarly
for <code>solve</code>, <code>determinant</code>.  Then, if <code>x.shape = [N, R]</code>,</p>
<ul>
<li><code>operator.matmul(x)</code> is <code>O(L_matmul*N*R + K*N*R)</code></li>
</ul>
<p>and if <code>M = N</code>,</p>
<ul>
<li><code>operator.solve(x)</code> is <code>O(L_matmul*N*R + N*K*R + K^2*R + K^3)</code></li>
<li><code>operator.determinant()</code> is <code>O(L_determinant + L_solve*N*K + K^2*N + K^3)</code></li>
</ul>
<p>If instead <code>operator</code> and <code>x</code> have shape <code>[B1,...,Bb, M, N]</code> and
<code>[B1,...,Bb, N, R]</code>, every operation increases in complexity by <code>B1*...*Bb</code>.</p>
<h4 id="matrix-property-hints">Matrix property hints</h4>
<p>This <code>LinearOperator</code> is initialized with boolean flags of the form <code>is_X</code>,
for <code>X = non_singular</code>, <code>self_adjoint</code>, <code>positive_definite</code>,
<code>diag_update_positive</code> and <code>square</code>. These have the following meaning:</p>
<ul>
<li>If <code>is_X == True</code>, callers should expect the operator to have the
  property <code>X</code>.  This is a promise that should be fulfilled, but is <em>not</em> a
  runtime assert.  For example, finite floating point precision may result
  in these promises being violated.</li>
<li>If <code>is_X == False</code>, callers should expect the operator to not have <code>X</code>.</li>
<li>If <code>is_X == None</code> (the default), callers should have no expectation either
  way.</li>
</ul>
<h2 id="__init__"><code>__init__</code></h2>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator_low_rank_update.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="fm">__init__</span><span class="p">(</span>
    <span class="n">base_operator</span><span class="p">,</span>
    <span class="n">u</span><span class="p">,</span>
    <span class="n">diag_update</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">v</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">is_diag_update_positive</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">is_non_singular</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">is_self_adjoint</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">is_positive_definite</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">is_square</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;LinearOperatorLowRankUpdate&#39;</span>
<span class="p">)</span>
</pre></div>


<p>Initialize a <code>LinearOperatorLowRankUpdate</code>.</p>
<p>This creates a <code>LinearOperator</code> of the form <code>A = L + U D V^H</code>, with
<code>L</code> a <code>LinearOperator</code>, <code>U, V</code> both [batch] matrices, and <code>D</code> a [batch]
diagonal matrix.</p>
<p>If <code>L</code> is non-singular, solves and determinants are available.
Solves/determinants both involve a solve/determinant of a <code>K x K</code> system.
In the event that L and D are self-adjoint positive-definite, and U = V,
this can be done using a Cholesky factorization.  The user should set the
<code>is_X</code> matrix property hints, which will trigger the appropriate code path.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>base_operator</code></b>:  Shape <code>[B1,...,Bb, M, N]</code>.</li>
<li><b><code>u</code></b>:  Shape <code>[B1,...,Bb, M, K]</code> <code>Tensor</code> of same <code>dtype</code> as <code>base_operator</code>.
  This is <code>U</code> above.</li>
<li><b><code>diag_update</code></b>:  Optional shape <code>[B1,...,Bb, K]</code> <code>Tensor</code> with same <code>dtype</code>
  as <code>base_operator</code>.  This is the diagonal of <code>D</code> above.
   Defaults to <code>D</code> being the identity operator.</li>
<li><b><code>v</code></b>:  Optional <code>Tensor</code> of same <code>dtype</code> as <code>u</code> and shape <code>[B1,...,Bb, N, K]</code>
   Defaults to <code>v = u</code>, in which case the perturbation is symmetric.
   If <code>M != N</code>, then <code>v</code> must be set since the perturbation is not square.</li>
<li><b><code>is_diag_update_positive</code></b>:  Python <code>bool</code>.
  If <code>True</code>, expect <code>diag_update &gt; 0</code>.</li>
<li><b><code>is_non_singular</code></b>:  Expect that this operator is non-singular.
  Default is <code>None</code>, unless <code>is_positive_definite</code> is auto-set to be
  <code>True</code> (see below).</li>
<li><b><code>is_self_adjoint</code></b>:  Expect that this operator is equal to its hermitian
  transpose.  Default is <code>None</code>, unless <code>base_operator</code> is self-adjoint
  and <code>v = None</code> (meaning <code>u=v</code>), in which case this defaults to <code>True</code>.</li>
<li><b><code>is_positive_definite</code></b>:  Expect that this operator is positive definite.
  Default is <code>None</code>, unless <code>base_operator</code> is positive-definite
  <code>v = None</code> (meaning <code>u=v</code>), and <code>is_diag_update_positive</code>, in which case
  this defaults to <code>True</code>.
  Note that we say an operator is positive definite when the quadratic
  form <code>x^H A x</code> has positive real part for all nonzero <code>x</code>.</li>
<li><b><code>is_square</code></b>:  Expect that this operator acts like square [batch] matrices.</li>
<li><b><code>name</code></b>: A name for this <code>LinearOperator</code>.</li>
</ul>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>:  If <code>is_X</code> flags are set in an inconsistent way.</li>
</ul>
<h2 id="properties">Properties</h2>
<h3 id="H"><code>H</code></h3>

<p>Returns the adjoint of the current <code>LinearOperator</code>.</p>
<p>Given <code>A</code> representing this <code>LinearOperator</code>, return <code>A*</code>.
Note that calling <code>self.adjoint()</code> and <code>self.H</code> are equivalent.</p>
<h4 id="args_1">Args:</h4>
<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p><code>LinearOperator</code> which represents the adjoint of this <code>LinearOperator</code>.</p>
<h3 id="base_operator"><code>base_operator</code></h3>

<p>If this operator is <code>A = L + U D V^H</code>, this is the <code>L</code>.</p>
<h3 id="batch_shape"><code>batch_shape</code></h3>

<p><code>TensorShape</code> of batch dimensions of this <code>LinearOperator</code>.</p>
<p>If this operator acts like the batch matrix <code>A</code> with
<code>A.shape = [B1,...,Bb, M, N]</code>, then this returns
<code>TensorShape([B1,...,Bb])</code>, equivalent to <code>A.get_shape()[:-2]</code></p>
<h4 id="returns_1">Returns:</h4>
<p><code>TensorShape</code>, statically determined, may be undefined.</p>
<h3 id="diag_operator"><code>diag_operator</code></h3>

<p>If this operator is <code>A = L + U D V^H</code>, this is <code>D</code>.</p>
<h3 id="diag_update"><code>diag_update</code></h3>

<p>If this operator is <code>A = L + U D V^H</code>, this is the diagonal of <code>D</code>.</p>
<h3 id="domain_dimension"><code>domain_dimension</code></h3>

<p>Dimension (in the sense of vector spaces) of the domain of this operator.</p>
<p>If this operator acts like the batch matrix <code>A</code> with
<code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>N</code>.</p>
<h4 id="returns_2">Returns:</h4>
<p><code>Dimension</code> object.</p>
<h3 id="dtype"><code>dtype</code></h3>

<p>The <code>DType</code> of <code>Tensor</code>s handled by this <code>LinearOperator</code>.</p>
<h3 id="graph_parents"><code>graph_parents</code></h3>

<p>List of graph dependencies of this <code>LinearOperator</code>.</p>
<h3 id="is_diag_update_positive"><code>is_diag_update_positive</code></h3>

<p>If this operator is <code>A = L + U D V^H</code>, this hints <code>D &gt; 0</code> elementwise.</p>
<h3 id="is_non_singular"><code>is_non_singular</code></h3>

<h3 id="is_positive_definite"><code>is_positive_definite</code></h3>

<h3 id="is_self_adjoint"><code>is_self_adjoint</code></h3>

<h3 id="is_square"><code>is_square</code></h3>

<p>Return <code>True/False</code> depending on if this operator is square.</p>
<h3 id="range_dimension"><code>range_dimension</code></h3>

<p>Dimension (in the sense of vector spaces) of the range of this operator.</p>
<p>If this operator acts like the batch matrix <code>A</code> with
<code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>M</code>.</p>
<h4 id="returns_3">Returns:</h4>
<p><code>Dimension</code> object.</p>
<h3 id="shape"><code>shape</code></h3>

<p><code>TensorShape</code> of this <code>LinearOperator</code>.</p>
<p>If this operator acts like the batch matrix <code>A</code> with
<code>A.shape = [B1,...,Bb, M, N]</code>, then this returns
<code>TensorShape([B1,...,Bb, M, N])</code>, equivalent to <code>A.get_shape()</code>.</p>
<h4 id="returns_4">Returns:</h4>
<p><code>TensorShape</code>, statically determined, may be undefined.</p>
<h3 id="tensor_rank"><code>tensor_rank</code></h3>

<p>Rank (in the sense of tensors) of matrix corresponding to this operator.</p>
<p>If this operator acts like the batch matrix <code>A</code> with
<code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>b + 2</code>.</p>
<h4 id="args_2">Args:</h4>
<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns_5">Returns:</h4>
<p>Python integer, or None if the tensor rank is undefined.</p>
<h3 id="u"><code>u</code></h3>

<p>If this operator is <code>A = L + U D V^H</code>, this is the <code>U</code>.</p>
<h3 id="v"><code>v</code></h3>

<p>If this operator is <code>A = L + U D V^H</code>, this is the <code>V</code>.</p>
<h2 id="methods">Methods</h2>
<h3 id="add_to_tensor"><code>add_to_tensor</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">add_to_tensor</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;add_to_tensor&#39;</span>
<span class="p">)</span>
</pre></div>


<p>Add matrix represented by this operator to <code>x</code>.  Equivalent to <code>A + x</code>.</p>
<h4 id="args_3">Args:</h4>
<ul>
<li><b><code>x</code></b>:  <code>Tensor</code> with same <code>dtype</code> and shape broadcastable to <code>self.shape</code>.</li>
<li><b><code>name</code></b>:  A name to give this <code>Op</code>.</li>
</ul>
<h4 id="returns_6">Returns:</h4>
<p>A <code>Tensor</code> with broadcast shape and same <code>dtype</code> as <code>self</code>.</p>
<h3 id="adjoint"><code>adjoint</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">adjoint</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;adjoint&#39;</span><span class="p">)</span>
</pre></div>


<p>Returns the adjoint of the current <code>LinearOperator</code>.</p>
<p>Given <code>A</code> representing this <code>LinearOperator</code>, return <code>A*</code>.
Note that calling <code>self.adjoint()</code> and <code>self.H</code> are equivalent.</p>
<h4 id="args_4">Args:</h4>
<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns_7">Returns:</h4>
<p><code>LinearOperator</code> which represents the adjoint of this <code>LinearOperator</code>.</p>
<h3 id="assert_non_singular"><code>assert_non_singular</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">assert_non_singular</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;assert_non_singular&#39;</span><span class="p">)</span>
</pre></div>


<p>Returns an <code>Op</code> that asserts this operator is non singular.</p>
<p>This operator is considered non-singular if</p>
<div class="codehilite"><pre><span></span><span class="err">ConditionNumber &lt; max{100, range_dimension, domain_dimension} * eps,</span>
<span class="err">eps := np.finfo(self.dtype.as_numpy_dtype).eps</span>
</pre></div>


<h4 id="args_5">Args:</h4>
<ul>
<li><b><code>name</code></b>:  A string name to prepend to created ops.</li>
</ul>
<h4 id="returns_8">Returns:</h4>
<p>An <code>Assert</code> <code>Op</code>, that, when run, will raise an <code>InvalidArgumentError</code> if
  the operator is singular.</p>
<h3 id="assert_positive_definite"><code>assert_positive_definite</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">assert_positive_definite</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;assert_positive_definite&#39;</span><span class="p">)</span>
</pre></div>


<p>Returns an <code>Op</code> that asserts this operator is positive definite.</p>
<p>Here, positive definite means that the quadratic form <code>x^H A x</code> has positive
real part for all nonzero <code>x</code>.  Note that we do not require the operator to
be self-adjoint to be positive definite.</p>
<h4 id="args_6">Args:</h4>
<ul>
<li><b><code>name</code></b>:  A name to give this <code>Op</code>.</li>
</ul>
<h4 id="returns_9">Returns:</h4>
<p>An <code>Assert</code> <code>Op</code>, that, when run, will raise an <code>InvalidArgumentError</code> if
  the operator is not positive definite.</p>
<h3 id="assert_self_adjoint"><code>assert_self_adjoint</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">assert_self_adjoint</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;assert_self_adjoint&#39;</span><span class="p">)</span>
</pre></div>


<p>Returns an <code>Op</code> that asserts this operator is self-adjoint.</p>
<p>Here we check that this operator is <em>exactly</em> equal to its hermitian
transpose.</p>
<h4 id="args_7">Args:</h4>
<ul>
<li><b><code>name</code></b>:  A string name to prepend to created ops.</li>
</ul>
<h4 id="returns_10">Returns:</h4>
<p>An <code>Assert</code> <code>Op</code>, that, when run, will raise an <code>InvalidArgumentError</code> if
  the operator is not self-adjoint.</p>
<h3 id="batch_shape_tensor"><code>batch_shape_tensor</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">batch_shape_tensor</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;batch_shape_tensor&#39;</span><span class="p">)</span>
</pre></div>


<p>Shape of batch dimensions of this operator, determined at runtime.</p>
<p>If this operator acts like the batch matrix <code>A</code> with
<code>A.shape = [B1,...,Bb, M, N]</code>, then this returns a <code>Tensor</code> holding
<code>[B1,...,Bb]</code>.</p>
<h4 id="args_8">Args:</h4>
<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns_11">Returns:</h4>
<p><code>int32</code> <code>Tensor</code></p>
<h3 id="cholesky"><code>cholesky</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">cholesky</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;cholesky&#39;</span><span class="p">)</span>
</pre></div>


<p>Returns a Cholesky factor as a <code>LinearOperator</code>.</p>
<p>Given <code>A</code> representing this <code>LinearOperator</code>, if <code>A</code> is positive definite
self-adjoint, return <code>L</code>, where <code>A = L L^T</code>, i.e. the cholesky
decomposition.</p>
<h4 id="args_9">Args:</h4>
<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns_12">Returns:</h4>
<p><code>LinearOperator</code> which represents the lower triangular matrix
in the Cholesky decomposition.</p>
<h4 id="raises_1">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: When the <code>LinearOperator</code> is not hinted to be positive
  definite and self adjoint.</li>
</ul>
<h3 id="determinant"><code>determinant</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">determinant</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;det&#39;</span><span class="p">)</span>
</pre></div>


<p>Determinant for every batch member.</p>
<h4 id="args_10">Args:</h4>
<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns_13">Returns:</h4>
<p><code>Tensor</code> with shape <code>self.batch_shape</code> and same <code>dtype</code> as <code>self</code>.</p>
<h4 id="raises_2">Raises:</h4>
<ul>
<li><b><code>NotImplementedError</code></b>:  If <code>self.is_square</code> is <code>False</code>.</li>
</ul>
<h3 id="diag_part"><code>diag_part</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">diag_part</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;diag_part&#39;</span><span class="p">)</span>
</pre></div>


<p>Efficiently get the [batch] diagonal part of this operator.</p>
<p>If this operator has shape <code>[B1,...,Bb, M, N]</code>, this returns a
<code>Tensor</code> <code>diagonal</code>, of shape <code>[B1,...,Bb, min(M, N)]</code>, where
<code>diagonal[b1,...,bb, i] = self.to_dense()[b1,...,bb, i, i]</code>.</p>
<div class="codehilite"><pre><span></span><span class="n">my_operator</span> <span class="o">=</span> <span class="n">LinearOperatorDiag</span><span class="p">([</span><span class="mi">1</span><span class="p">.,</span> <span class="mi">2</span><span class="p">.])</span>

<span class="o">#</span> <span class="n">Efficiently</span> <span class="k">get</span> <span class="n">the</span> <span class="n">diagonal</span>
<span class="n">my_operator</span><span class="p">.</span><span class="n">diag_part</span><span class="p">()</span>
<span class="o">==&gt;</span> <span class="p">[</span><span class="mi">1</span><span class="p">.,</span> <span class="mi">2</span><span class="p">.]</span>

<span class="o">#</span> <span class="n">Equivalent</span><span class="p">,</span> <span class="n">but</span> <span class="n">inefficient</span> <span class="k">method</span>
<span class="n">tf</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">diag_part</span><span class="p">(</span><span class="n">my_operator</span><span class="p">.</span><span class="n">to_dense</span><span class="p">())</span>
<span class="o">==&gt;</span> <span class="p">[</span><span class="mi">1</span><span class="p">.,</span> <span class="mi">2</span><span class="p">.]</span>
</pre></div>


<h4 id="args_11">Args:</h4>
<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns_14">Returns:</h4>
<ul>
<li><b><code>diag_part</code></b>:  A <code>Tensor</code> of same <code>dtype</code> as self.</li>
</ul>
<h3 id="domain_dimension_tensor"><code>domain_dimension_tensor</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">domain_dimension_tensor</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;domain_dimension_tensor&#39;</span><span class="p">)</span>
</pre></div>


<p>Dimension (in the sense of vector spaces) of the domain of this operator.</p>
<p>Determined at runtime.</p>
<p>If this operator acts like the batch matrix <code>A</code> with
<code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>N</code>.</p>
<h4 id="args_12">Args:</h4>
<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns_15">Returns:</h4>
<p><code>int32</code> <code>Tensor</code></p>
<h3 id="inverse"><code>inverse</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">inverse</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;inverse&#39;</span><span class="p">)</span>
</pre></div>


<p>Returns the Inverse of this <code>LinearOperator</code>.</p>
<p>Given <code>A</code> representing this <code>LinearOperator</code>, return a <code>LinearOperator</code>
representing <code>A^-1</code>.</p>
<h4 id="args_13">Args:</h4>
<ul>
<li><b><code>name</code></b>: A name scope to use for ops added by this method.</li>
</ul>
<h4 id="returns_16">Returns:</h4>
<p><code>LinearOperator</code> representing inverse of this matrix.</p>
<h4 id="raises_3">Raises:</h4>
<ul>
<li><b><code>ValueError</code></b>: When the <code>LinearOperator</code> is not hinted to be <code>non_singular</code>.</li>
</ul>
<h3 id="log_abs_determinant"><code>log_abs_determinant</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">log_abs_determinant</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;log_abs_det&#39;</span><span class="p">)</span>
</pre></div>


<p>Log absolute value of determinant for every batch member.</p>
<h4 id="args_14">Args:</h4>
<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns_17">Returns:</h4>
<p><code>Tensor</code> with shape <code>self.batch_shape</code> and same <code>dtype</code> as <code>self</code>.</p>
<h4 id="raises_4">Raises:</h4>
<ul>
<li><b><code>NotImplementedError</code></b>:  If <code>self.is_square</code> is <code>False</code>.</li>
</ul>
<h3 id="matmul"><code>matmul</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">matmul</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">adjoint</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">adjoint_arg</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;matmul&#39;</span>
<span class="p">)</span>
</pre></div>


<p>Transform [batch] matrix <code>x</code> with left multiplication:  <code>x --&gt; Ax</code>.</p>
<div class="codehilite"><pre><span></span><span class="c1"># Make an operator acting like batch matrix A.  Assume A.shape = [..., M, N]</span>
<span class="n">operator</span> <span class="o">=</span> <span class="n">LinearOperator</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">operator</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">]</span>

<span class="n">X</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># shape [..., N, R], batch matrix, R &gt; 0.</span>

<span class="n">Y</span> <span class="o">=</span> <span class="n">operator</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">Y</span><span class="o">.</span><span class="n">shape</span>
<span class="o">==&gt;</span> <span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">R</span><span class="p">]</span>

<span class="n">Y</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:,</span> <span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="n">sum_j</span> <span class="n">A</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:,</span> <span class="n">j</span><span class="p">]</span> <span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">r</span><span class="p">]</span>
</pre></div>


<h4 id="args_15">Args:</h4>
<ul>
<li><b><code>x</code></b>: <code>LinearOperator</code> or <code>Tensor</code> with compatible shape and same <code>dtype</code> as
  <code>self</code>. See class docstring for definition of compatibility.</li>
<li><b><code>adjoint</code></b>: Python <code>bool</code>.  If <code>True</code>, left multiply by the adjoint: <code>A^H x</code>.</li>
<li><b><code>adjoint_arg</code></b>:  Python <code>bool</code>.  If <code>True</code>, compute <code>A x^H</code> where <code>x^H</code> is
  the hermitian transpose (transposition and complex conjugation).</li>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns_18">Returns:</h4>
<p>A <code>LinearOperator</code> or <code>Tensor</code> with shape <code>[..., M, R]</code> and same <code>dtype</code>
  as <code>self</code>.</p>
<h3 id="matvec"><code>matvec</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">matvec</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">adjoint</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;matvec&#39;</span>
<span class="p">)</span>
</pre></div>


<p>Transform [batch] vector <code>x</code> with left multiplication:  <code>x --&gt; Ax</code>.</p>
<div class="codehilite"><pre><span></span><span class="c1"># Make an operator acting like batch matric A.  Assume A.shape = [..., M, N]</span>
<span class="n">operator</span> <span class="o">=</span> <span class="n">LinearOperator</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># shape [..., N], batch vector</span>

<span class="n">Y</span> <span class="o">=</span> <span class="n">operator</span><span class="o">.</span><span class="n">matvec</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">Y</span><span class="o">.</span><span class="n">shape</span>
<span class="o">==&gt;</span> <span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">M</span><span class="p">]</span>

<span class="n">Y</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">sum_j</span> <span class="n">A</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:,</span> <span class="n">j</span><span class="p">]</span> <span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
</pre></div>


<h4 id="args_16">Args:</h4>
<ul>
<li><b><code>x</code></b>: <code>Tensor</code> with compatible shape and same <code>dtype</code> as <code>self</code>.
  <code>x</code> is treated as a [batch] vector meaning for every set of leading
  dimensions, the last dimension defines a vector.
  See class docstring for definition of compatibility.</li>
<li><b><code>adjoint</code></b>: Python <code>bool</code>.  If <code>True</code>, left multiply by the adjoint: <code>A^H x</code>.</li>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns_19">Returns:</h4>
<p>A <code>Tensor</code> with shape <code>[..., M]</code> and same <code>dtype</code> as <code>self</code>.</p>
<h3 id="range_dimension_tensor"><code>range_dimension_tensor</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">range_dimension_tensor</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;range_dimension_tensor&#39;</span><span class="p">)</span>
</pre></div>


<p>Dimension (in the sense of vector spaces) of the range of this operator.</p>
<p>Determined at runtime.</p>
<p>If this operator acts like the batch matrix <code>A</code> with
<code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>M</code>.</p>
<h4 id="args_17">Args:</h4>
<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns_20">Returns:</h4>
<p><code>int32</code> <code>Tensor</code></p>
<h3 id="shape_tensor"><code>shape_tensor</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">shape_tensor</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;shape_tensor&#39;</span><span class="p">)</span>
</pre></div>


<p>Shape of this <code>LinearOperator</code>, determined at runtime.</p>
<p>If this operator acts like the batch matrix <code>A</code> with
<code>A.shape = [B1,...,Bb, M, N]</code>, then this returns a <code>Tensor</code> holding
<code>[B1,...,Bb, M, N]</code>, equivalent to <a href="../../tf/shape.html"><code>tf.shape(A)</code></a>.</p>
<h4 id="args_18">Args:</h4>
<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns_21">Returns:</h4>
<p><code>int32</code> <code>Tensor</code></p>
<h3 id="solve"><code>solve</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">solve</span><span class="p">(</span>
    <span class="n">rhs</span><span class="p">,</span>
    <span class="n">adjoint</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">adjoint_arg</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;solve&#39;</span>
<span class="p">)</span>
</pre></div>


<p>Solve (exact or approx) <code>R</code> (batch) systems of equations: <code>A X = rhs</code>.</p>
<p>The returned <code>Tensor</code> will be close to an exact solution if <code>A</code> is well
conditioned. Otherwise closeness will vary. See class docstring for details.</p>
<h4 id="examples">Examples:</h4>
<div class="codehilite"><pre><span></span><span class="c1"># Make an operator acting like batch matrix A.  Assume A.shape = [..., M, N]</span>
<span class="n">operator</span> <span class="o">=</span> <span class="n">LinearOperator</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">operator</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">]</span>

<span class="c1"># Solve R &gt; 0 linear systems for every member of the batch.</span>
<span class="n">RHS</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># shape [..., M, R]</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">operator</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">RHS</span><span class="p">)</span>
<span class="c1"># X[..., :, r] is the solution to the r&#39;th linear system</span>
<span class="c1"># sum_j A[..., :, j] X[..., j, r] = RHS[..., :, r]</span>

<span class="n">operator</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="o">==&gt;</span> <span class="n">RHS</span>
</pre></div>


<h4 id="args_19">Args:</h4>
<ul>
<li><b><code>rhs</code></b>: <code>Tensor</code> with same <code>dtype</code> as this operator and compatible shape.
  <code>rhs</code> is treated like a [batch] matrix meaning for every set of leading
  dimensions, the last two dimensions defines a matrix.
  See class docstring for definition of compatibility.</li>
<li><b><code>adjoint</code></b>: Python <code>bool</code>.  If <code>True</code>, solve the system involving the adjoint
  of this <code>LinearOperator</code>:  <code>A^H X = rhs</code>.</li>
<li><b><code>adjoint_arg</code></b>:  Python <code>bool</code>.  If <code>True</code>, solve <code>A X = rhs^H</code> where <code>rhs^H</code>
  is the hermitian transpose (transposition and complex conjugation).</li>
<li><b><code>name</code></b>:  A name scope to use for ops added by this method.</li>
</ul>
<h4 id="returns_22">Returns:</h4>
<p><code>Tensor</code> with shape <code>[...,N, R]</code> and same <code>dtype</code> as <code>rhs</code>.</p>
<h4 id="raises_5">Raises:</h4>
<ul>
<li><b><code>NotImplementedError</code></b>:  If <code>self.is_non_singular</code> or <code>is_square</code> is False.</li>
</ul>
<h3 id="solvevec"><code>solvevec</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">solvevec</span><span class="p">(</span>
    <span class="n">rhs</span><span class="p">,</span>
    <span class="n">adjoint</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;solve&#39;</span>
<span class="p">)</span>
</pre></div>


<p>Solve single equation with best effort: <code>A X = rhs</code>.</p>
<p>The returned <code>Tensor</code> will be close to an exact solution if <code>A</code> is well
conditioned. Otherwise closeness will vary. See class docstring for details.</p>
<h4 id="examples_1">Examples:</h4>
<div class="codehilite"><pre><span></span><span class="c1"># Make an operator acting like batch matrix A.  Assume A.shape = [..., M, N]</span>
<span class="n">operator</span> <span class="o">=</span> <span class="n">LinearOperator</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">operator</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">]</span>

<span class="c1"># Solve one linear system for every member of the batch.</span>
<span class="n">RHS</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># shape [..., M]</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">operator</span><span class="o">.</span><span class="n">solvevec</span><span class="p">(</span><span class="n">RHS</span><span class="p">)</span>
<span class="c1"># X is the solution to the linear system</span>
<span class="c1"># sum_j A[..., :, j] X[..., j] = RHS[..., :]</span>

<span class="n">operator</span><span class="o">.</span><span class="n">matvec</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="o">==&gt;</span> <span class="n">RHS</span>
</pre></div>


<h4 id="args_20">Args:</h4>
<ul>
<li><b><code>rhs</code></b>: <code>Tensor</code> with same <code>dtype</code> as this operator.
  <code>rhs</code> is treated like a [batch] vector meaning for every set of leading
  dimensions, the last dimension defines a vector.  See class docstring
  for definition of compatibility regarding batch dimensions.</li>
<li><b><code>adjoint</code></b>: Python <code>bool</code>.  If <code>True</code>, solve the system involving the adjoint
  of this <code>LinearOperator</code>:  <code>A^H X = rhs</code>.</li>
<li><b><code>name</code></b>:  A name scope to use for ops added by this method.</li>
</ul>
<h4 id="returns_23">Returns:</h4>
<p><code>Tensor</code> with shape <code>[...,N]</code> and same <code>dtype</code> as <code>rhs</code>.</p>
<h4 id="raises_6">Raises:</h4>
<ul>
<li><b><code>NotImplementedError</code></b>:  If <code>self.is_non_singular</code> or <code>is_square</code> is False.</li>
</ul>
<h3 id="tensor_rank_tensor"><code>tensor_rank_tensor</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">tensor_rank_tensor</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;tensor_rank_tensor&#39;</span><span class="p">)</span>
</pre></div>


<p>Rank (in the sense of tensors) of matrix corresponding to this operator.</p>
<p>If this operator acts like the batch matrix <code>A</code> with
<code>A.shape = [B1,...,Bb, M, N]</code>, then this returns <code>b + 2</code>.</p>
<h4 id="args_21">Args:</h4>
<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns_24">Returns:</h4>
<p><code>int32</code> <code>Tensor</code>, determined at runtime.</p>
<h3 id="to_dense"><code>to_dense</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">to_dense</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;to_dense&#39;</span><span class="p">)</span>
</pre></div>


<p>Return a dense (batch) matrix representing this operator.</p>
<h3 id="trace"><code>trace</code></h3>

<p><a target="_blank" href="/code/stable/tensorflow/python/ops/linalg/linear_operator.py">View source</a></p>
<div class="codehilite"><pre><span></span><span class="n">trace</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;trace&#39;</span><span class="p">)</span>
</pre></div>


<p>Trace of the linear operator, equal to sum of <code>self.diag_part()</code>.</p>
<p>If the operator is square, this is also the sum of the eigenvalues.</p>
<h4 id="args_22">Args:</h4>
<ul>
<li><b><code>name</code></b>:  A name for this <code>Op</code>.</li>
</ul>
<h4 id="returns_25">Returns:</h4>
<p>Shape <code>[B1,...,Bb]</code> <code>Tensor</code> of same <code>dtype</code> as <code>self</code>.</p>
    </body>
    </html>
   