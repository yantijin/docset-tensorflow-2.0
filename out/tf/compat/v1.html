
    <html lang="zh-cn">
    <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <link href=../../../default.css" rel="stylesheet">
    <link href="
   ../../../github.css" rel="stylesheet">
    </head>
    <body>
    <div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.compat.v1" />
<meta itemprop="path" content="Stable" />
<meta itemprop="property" content="AUTO_REUSE"/>
<meta itemprop="property" content="COMPILER_VERSION"/>
<meta itemprop="property" content="CXX11_ABI_FLAG"/>
<meta itemprop="property" content="GIT_VERSION"/>
<meta itemprop="property" content="GRAPH_DEF_VERSION"/>
<meta itemprop="property" content="GRAPH_DEF_VERSION_MIN_CONSUMER"/>
<meta itemprop="property" content="GRAPH_DEF_VERSION_MIN_PRODUCER"/>
<meta itemprop="property" content="MONOLITHIC_BUILD"/>
<meta itemprop="property" content="QUANTIZED_DTYPES"/>
<meta itemprop="property" content="VERSION"/>
<meta itemprop="property" content="__version__"/>
<meta itemprop="property" content="bfloat16"/>
<meta itemprop="property" content="bool"/>
<meta itemprop="property" content="complex128"/>
<meta itemprop="property" content="complex64"/>
<meta itemprop="property" content="double"/>
<meta itemprop="property" content="float16"/>
<meta itemprop="property" content="float32"/>
<meta itemprop="property" content="float64"/>
<meta itemprop="property" content="half"/>
<meta itemprop="property" content="int16"/>
<meta itemprop="property" content="int32"/>
<meta itemprop="property" content="int64"/>
<meta itemprop="property" content="int8"/>
<meta itemprop="property" content="qint16"/>
<meta itemprop="property" content="qint32"/>
<meta itemprop="property" content="qint8"/>
<meta itemprop="property" content="quint16"/>
<meta itemprop="property" content="quint8"/>
<meta itemprop="property" content="resource"/>
<meta itemprop="property" content="string"/>
<meta itemprop="property" content="uint16"/>
<meta itemprop="property" content="uint32"/>
<meta itemprop="property" content="uint64"/>
<meta itemprop="property" content="uint8"/>
<meta itemprop="property" content="variant"/>
</div>

<h1 id="module-tfcompatv1">Module: tf.compat.v1</h1>
<table class="tfo-notebook-buttons tfo-api" align="left">
</table>

<p>Bring in all of the public TensorFlow interface into this module.</p>
<h2 id="modules">Modules</h2>
<p><a href="../../tf/compat/v1/app.html"><code>app</code></a> module: Generic entry point script.</p>
<p><a href="../../tf/compat/v1/audio.html"><code>audio</code></a> module: Public API for tf.audio namespace.</p>
<p><a href="../../tf/compat/v1/autograph.html"><code>autograph</code></a> module: Conversion of plain Python into TensorFlow graph code.</p>
<p><a href="../../tf/compat/v1/bitwise.html"><code>bitwise</code></a> module: Operations for manipulating the binary representations of integers.</p>
<p><a href="../../tf/compat/v1/compat.html"><code>compat</code></a> module: Functions for Python 2 vs. 3 compatibility.</p>
<p><a href="../../tf/compat/v1/config.html"><code>config</code></a> module: Public API for tf.config namespace.</p>
<p><a href="../../tf/compat/v1/data.html"><code>data</code></a> module: <a href="../../tf/data/Dataset.html"><code>tf.data.Dataset</code></a> API for input pipelines.</p>
<p><a href="../../tf/compat/v1/debugging.html"><code>debugging</code></a> module: Public API for tf.debugging namespace.</p>
<p><a href="../../tf/compat/v1/distribute.html"><code>distribute</code></a> module: Library for running a computation across multiple devices.</p>
<p><a href="../../tf/compat/v1/distributions.html"><code>distributions</code></a> module: Core module for TensorFlow distribution objects and helpers.</p>
<p><a href="../../tf/compat/v1/dtypes.html"><code>dtypes</code></a> module: Public API for tf.dtypes namespace.</p>
<p><a href="../../tf/compat/v1/errors.html"><code>errors</code></a> module: Exception types for TensorFlow errors.</p>
<p><a href="../../tf/compat/v1/estimator.html"><code>estimator</code></a> module: Estimator: High level tools for working with models.</p>
<p><a href="../../tf/compat/v1/experimental.html"><code>experimental</code></a> module: Public API for tf.experimental namespace.</p>
<p><a href="../../tf/compat/v1/feature_column.html"><code>feature_column</code></a> module: Public API for tf.feature_column namespace.</p>
<p><a href="../../tf/compat/v1/flags.html"><code>flags</code></a> module: Import router for absl.flags. See https://github.com/abseil/abseil-py.</p>
<p><a href="../../tf/compat/v1/gfile.html"><code>gfile</code></a> module: Import router for file_io.</p>
<p><a href="../../tf/compat/v1/graph_util.html"><code>graph_util</code></a> module: Helpers to manipulate a tensor graph in python.</p>
<p><a href="../../tf/compat/v1/image.html"><code>image</code></a> module: Image processing and decoding ops.</p>
<p><a href="../../tf/compat/v1/initializers.html"><code>initializers</code></a> module: Public API for tf.initializers namespace.</p>
<p><a href="../../tf/compat/v1/io.html"><code>io</code></a> module: Public API for tf.io namespace.</p>
<p><a href="../../tf/compat/v1/keras.html"><code>keras</code></a> module: Implementation of the Keras API meant to be a high-level API for TensorFlow.</p>
<p><a href="../../tf/compat/v1/layers.html"><code>layers</code></a> module: Public API for tf.layers namespace.</p>
<p><a href="../../tf/compat/v1/linalg.html"><code>linalg</code></a> module: Operations for linear algebra.</p>
<p><a href="../../tf/compat/v1/lite.html"><code>lite</code></a> module: Public API for tf.lite namespace.</p>
<p><a href="../../tf/compat/v1/logging.html"><code>logging</code></a> module: Logging and Summary Operations.</p>
<p><a href="../../tf/compat/v1/lookup.html"><code>lookup</code></a> module: Public API for tf.lookup namespace.</p>
<p><a href="../../tf/compat/v1/losses.html"><code>losses</code></a> module: Loss operations for use in neural networks.</p>
<p><a href="../../tf/compat/v1/manip.html"><code>manip</code></a> module: Operators for manipulating tensors.</p>
<p><a href="../../tf/compat/v1/math.html"><code>math</code></a> module: Math Operations.</p>
<p><a href="../../tf/compat/v1/metrics.html"><code>metrics</code></a> module: Evaluation-related metrics.</p>
<p><a href="../../tf/compat/v1/nest.html"><code>nest</code></a> module: Public API for tf.nest namespace.</p>
<p><a href="../../tf/compat/v1/nn.html"><code>nn</code></a> module: Wrappers for primitive Neural Net (NN) Operations.</p>
<p><a href="../../tf/compat/v1/profiler.html"><code>profiler</code></a> module: Public API for tf.profiler namespace.</p>
<p><a href="../../tf/compat/v1/python_io.html"><code>python_io</code></a> module: Python functions for directly manipulating TFRecord-formatted files.</p>
<p><a href="../../tf/compat/v1/quantization.html"><code>quantization</code></a> module: Public API for tf.quantization namespace.</p>
<p><a href="../../tf/compat/v1/queue.html"><code>queue</code></a> module: Public API for tf.queue namespace.</p>
<p><a href="../../tf/compat/v1/ragged.html"><code>ragged</code></a> module: Ragged Tensors.</p>
<p><a href="../../tf/compat/v1/random.html"><code>random</code></a> module: Public API for tf.random namespace.</p>
<p><a href="../../tf/compat/v1/raw_ops.html"><code>raw_ops</code></a> module: Public API for tf.raw_ops namespace.</p>
<p><a href="../../tf/compat/v1/resource_loader.html"><code>resource_loader</code></a> module: Resource management library.</p>
<p><a href="../../tf/compat/v1/saved_model.html"><code>saved_model</code></a> module: Public API for tf.saved_model namespace.</p>
<p><a href="../../tf/compat/v1/sets.html"><code>sets</code></a> module: Tensorflow set operations.</p>
<p><a href="../../tf/compat/v1/signal.html"><code>signal</code></a> module: Signal processing operations.</p>
<p><a href="../../tf/compat/v1/sparse.html"><code>sparse</code></a> module: Sparse Tensor Representation.</p>
<p><a href="../../tf/compat/v1/spectral.html"><code>spectral</code></a> module: Public API for tf.spectral namespace.</p>
<p><a href="../../tf/compat/v1/strings.html"><code>strings</code></a> module: Operations for working with string Tensors.</p>
<p><a href="../../tf/compat/v1/summary.html"><code>summary</code></a> module: Operations for writing summary data, for use in analysis and visualization.</p>
<p><a href="../../tf/compat/v1/sysconfig.html"><code>sysconfig</code></a> module: System configuration library.</p>
<p><a href="../../tf/compat/v1/test.html"><code>test</code></a> module: Testing.</p>
<p><a href="../../tf/compat/v1/tpu.html"><code>tpu</code></a> module: Ops related to Tensor Processing Units.</p>
<p><a href="../../tf/compat/v1/train.html"><code>train</code></a> module: Support for training models.</p>
<p><a href="../../tf/compat/v1/user_ops.html"><code>user_ops</code></a> module: Public API for tf.user_ops namespace.</p>
<p><a href="../../tf/compat/v1/version.html"><code>version</code></a> module: Public API for tf.version namespace.</p>
<p><a href="../../tf/compat/v1/xla.html"><code>xla</code></a> module: Public API for tf.xla namespace.</p>
<h2 id="classes">Classes</h2>
<p><a href="../../tf/AggregationMethod.html"><code>class AggregationMethod</code></a>: A class listing aggregation methods used to combine gradients.</p>
<p><a href="../../tf/compat/v1/AttrValue.html"><code>class AttrValue</code></a>: A ProtocolMessage</p>
<p><a href="../../tf/compat/v1/ConditionalAccumulator.html"><code>class ConditionalAccumulator</code></a>: A conditional accumulator for aggregating gradients.</p>
<p><a href="../../tf/compat/v1/ConditionalAccumulatorBase.html"><code>class ConditionalAccumulatorBase</code></a>: A conditional accumulator for aggregating gradients.</p>
<p><a href="../../tf/compat/v1/ConfigProto.html"><code>class ConfigProto</code></a>: A ProtocolMessage</p>
<p><a href="../../tf/CriticalSection.html"><code>class CriticalSection</code></a>: Critical section.</p>
<p><a href="../../tf/dtypes/DType.html"><code>class DType</code></a>: Represents the type of the elements in a <code>Tensor</code>.</p>
<p><a href="../../tf/compat/v1/DeviceSpec.html"><code>class DeviceSpec</code></a>: Represents a (possibly partial) specification for a TensorFlow device.</p>
<p><a href="../../tf/compat/v1/Dimension.html"><code>class Dimension</code></a>: Represents the value of one dimension in a TensorShape.</p>
<p><a href="../../tf/compat/v1/Event.html"><code>class Event</code></a>: A ProtocolMessage</p>
<p><a href="../../tf/queue/FIFOQueue.html"><code>class FIFOQueue</code></a>: A queue implementation that dequeues elements in first-in first-out order.</p>
<p><a href="../../tf/io/FixedLenFeature.html"><code>class FixedLenFeature</code></a>: Configuration for parsing a fixed-length input feature.</p>
<p><a href="../../tf/io/FixedLenSequenceFeature.html"><code>class FixedLenSequenceFeature</code></a>: Configuration for parsing a variable-length input feature into a <code>Tensor</code>.</p>
<p><a href="../../tf/compat/v1/FixedLengthRecordReader.html"><code>class FixedLengthRecordReader</code></a>: A Reader that outputs fixed-length records from a file.</p>
<p><a href="../../tf/compat/v1/GPUOptions.html"><code>class GPUOptions</code></a>: A ProtocolMessage</p>
<p><a href="../../tf/GradientTape.html"><code>class GradientTape</code></a>: Record operations for automatic differentiation.</p>
<p><a href="../../tf/Graph.html"><code>class Graph</code></a>: A TensorFlow computation, represented as a dataflow graph.</p>
<p><a href="../../tf/compat/v1/GraphDef.html"><code>class GraphDef</code></a>: A ProtocolMessage</p>
<p><a href="../../tf/compat/v1/GraphKeys.html"><code>class GraphKeys</code></a>: Standard names to use for graph collections.</p>
<p><a href="../../tf/compat/v1/GraphOptions.html"><code>class GraphOptions</code></a>: A ProtocolMessage</p>
<p><a href="../../tf/compat/v1/HistogramProto.html"><code>class HistogramProto</code></a>: A ProtocolMessage</p>
<p><a href="../../tf/compat/v1/IdentityReader.html"><code>class IdentityReader</code></a>: A Reader that outputs the queued work as both the key and value.</p>
<p><a href="../../tf/IndexedSlices.html"><code>class IndexedSlices</code></a>: A sparse representation of a set of tensor slices at given indices.</p>
<p><a href="../../tf/IndexedSlicesSpec.html"><code>class IndexedSlicesSpec</code></a>: Type specification for a <a href="../../tf/IndexedSlices.html"><code>tf.IndexedSlices</code></a>.</p>
<p><a href="../../tf/compat/v1/InteractiveSession.html"><code>class InteractiveSession</code></a>: A TensorFlow <code>Session</code> for use in interactive contexts, such as a shell.</p>
<p><a href="../../tf/compat/v1/LMDBReader.html"><code>class LMDBReader</code></a>: A Reader that outputs the records from a LMDB file.</p>
<p><a href="../../tf/compat/v1/LogMessage.html"><code>class LogMessage</code></a>: A ProtocolMessage</p>
<p><a href="../../tf/compat/v1/MetaGraphDef.html"><code>class MetaGraphDef</code></a>: A ProtocolMessage</p>
<p><a href="../../tf/Module.html"><code>class Module</code></a>: Base neural network module class.</p>
<p><a href="../../tf/compat/v1/NameAttrList.html"><code>class NameAttrList</code></a>: A ProtocolMessage</p>
<p><a href="../../tf/compat/v1/NodeDef.html"><code>class NodeDef</code></a>: A ProtocolMessage</p>
<p><a href="../../tf/errors/OpError.html"><code>class OpError</code></a>: A generic error that is raised when TensorFlow execution fails.</p>
<p><a href="../../tf/Operation.html"><code>class Operation</code></a>: Represents a graph node that performs computation on tensors.</p>
<p><a href="../../tf/compat/v1/OptimizerOptions.html"><code>class OptimizerOptions</code></a>: A ProtocolMessage</p>
<p><a href="../../tf/OptionalSpec.html"><code>class OptionalSpec</code></a>: Represents an optional potentially containing a structured value.</p>
<p><a href="../../tf/queue/PaddingFIFOQueue.html"><code>class PaddingFIFOQueue</code></a>: A FIFOQueue that supports batching variable-sized tensors by padding.</p>
<p><a href="../../tf/queue/PriorityQueue.html"><code>class PriorityQueue</code></a>: A queue implementation that dequeues elements in prioritized order.</p>
<p><a href="../../tf/queue/QueueBase.html"><code>class QueueBase</code></a>: Base class for queue implementations.</p>
<p><a href="../../tf/RaggedTensor.html"><code>class RaggedTensor</code></a>: Represents a ragged tensor.</p>
<p><a href="../../tf/RaggedTensorSpec.html"><code>class RaggedTensorSpec</code></a>: Type specification for a <a href="../../tf/RaggedTensor.html"><code>tf.RaggedTensor</code></a>.</p>
<p><a href="../../tf/queue/RandomShuffleQueue.html"><code>class RandomShuffleQueue</code></a>: A queue implementation that dequeues elements in a random order.</p>
<p><a href="../../tf/compat/v1/ReaderBase.html"><code>class ReaderBase</code></a>: Base class for different Reader types, that produce a record every step.</p>
<p><a href="../../tf/RegisterGradient.html"><code>class RegisterGradient</code></a>: A decorator for registering the gradient function for an op type.</p>
<p><a href="../../tf/compat/v1/RunMetadata.html"><code>class RunMetadata</code></a>: A ProtocolMessage</p>
<p><a href="../../tf/compat/v1/RunOptions.html"><code>class RunOptions</code></a>: A ProtocolMessage</p>
<p><a href="../../tf/compat/v1/Session.html"><code>class Session</code></a>: A class for running TensorFlow operations.</p>
<p><a href="../../tf/compat/v1/SessionLog.html"><code>class SessionLog</code></a>: A ProtocolMessage</p>
<p><a href="../../tf/compat/v1/SparseConditionalAccumulator.html"><code>class SparseConditionalAccumulator</code></a>: A conditional accumulator for aggregating sparse gradients.</p>
<p><a href="../../tf/io/SparseFeature.html"><code>class SparseFeature</code></a>: Configuration for parsing a sparse input feature from an <code>Example</code>.</p>
<p><a href="../../tf/sparse/SparseTensor.html"><code>class SparseTensor</code></a>: Represents a sparse tensor.</p>
<p><a href="../../tf/SparseTensorSpec.html"><code>class SparseTensorSpec</code></a>: Type specification for a <a href="../../tf/sparse/SparseTensor.html"><code>tf.SparseTensor</code></a>.</p>
<p><a href="../../tf/compat/v1/SparseTensorValue.html"><code>class SparseTensorValue</code></a>: SparseTensorValue(indices, values, dense_shape)</p>
<p><a href="../../tf/compat/v1/Summary.html"><code>class Summary</code></a>: A ProtocolMessage</p>
<p><a href="../../tf/compat/v1/SummaryMetadata.html"><code>class SummaryMetadata</code></a>: A ProtocolMessage</p>
<p><a href="../../tf/compat/v1/TFRecordReader.html"><code>class TFRecordReader</code></a>: A Reader that outputs the records from a TFRecords file.</p>
<p><a href="../../tf/Tensor.html"><code>class Tensor</code></a>: Represents one of the outputs of an <code>Operation</code>.</p>
<p><a href="../../tf/TensorArray.html"><code>class TensorArray</code></a>: Class wrapping dynamic-sized, per-time-step, write-once Tensor arrays.</p>
<p><a href="../../tf/TensorArraySpec.html"><code>class TensorArraySpec</code></a>: Type specification for a <a href="../../tf/TensorArray.html"><code>tf.TensorArray</code></a>.</p>
<p><a href="../../tf/compat/v1/TensorInfo.html"><code>class TensorInfo</code></a>: A ProtocolMessage</p>
<p><a href="../../tf/TensorShape.html"><code>class TensorShape</code></a>: Represents the shape of a <code>Tensor</code>.</p>
<p><a href="../../tf/TensorSpec.html"><code>class TensorSpec</code></a>: Describes a tf.Tensor.</p>
<p><a href="../../tf/compat/v1/TextLineReader.html"><code>class TextLineReader</code></a>: A Reader that outputs the lines of a file delimited by newlines.</p>
<p><a href="../../tf/TypeSpec.html"><code>class TypeSpec</code></a>: Specifies a TensorFlow value type.</p>
<p><a href="../../tf/UnconnectedGradients.html"><code>class UnconnectedGradients</code></a>: Controls how gradient computation behaves when y does not depend on x.</p>
<p><a href="../../tf/io/VarLenFeature.html"><code>class VarLenFeature</code></a>: Configuration for parsing a variable-length input feature.</p>
<p><a href="../../tf/compat/v1/Variable.html"><code>class Variable</code></a>: See the <a href="https://tensorflow.org/guide/variables">Variables Guide</a>.</p>
<p><a href="../../tf/compat/v1/VariableAggregation.html"><code>class VariableAggregation</code></a>: Indicates how a distributed variable will be aggregated.</p>
<p><a href="../../tf/compat/v1/VariableScope.html"><code>class VariableScope</code></a>: Variable scope object to carry defaults to provide to <code>get_variable</code>.</p>
<p><a href="../../tf/VariableSynchronization.html"><code>class VariableSynchronization</code></a>: Indicates when a distributed variable will be synced.</p>
<p><a href="../../tf/compat/v1/WholeFileReader.html"><code>class WholeFileReader</code></a>: A Reader that outputs the entire contents of a file as a value.</p>
<p><a href="../../tf/compat/v1/keras/initializers/Constant.html"><code>class constant_initializer</code></a>: Initializer that generates tensors with constant values.</p>
<p><a href="../../tf/compat/v1/keras/initializers/glorot_normal.html"><code>class glorot_normal_initializer</code></a>: The Glorot normal initializer, also called Xavier normal initializer.</p>
<p><a href="../../tf/compat/v1/keras/initializers/glorot_uniform.html"><code>class glorot_uniform_initializer</code></a>: The Glorot uniform initializer, also called Xavier uniform initializer.</p>
<p><a href="../../tf/compat/v1/keras/backend/name_scope.html"><code>class name_scope</code></a>: A context manager for use when defining a Python op.</p>
<p><a href="../../tf/compat/v1/keras/initializers/Ones.html"><code>class ones_initializer</code></a>: Initializer that generates tensors initialized to 1.</p>
<p><a href="../../tf/compat/v1/keras/initializers/Orthogonal.html"><code>class orthogonal_initializer</code></a>: Initializer that generates an orthogonal matrix.</p>
<p><a href="../../tf/compat/v1/random_normal_initializer.html"><code>class random_normal_initializer</code></a>: Initializer that generates tensors with a normal distribution.</p>
<p><a href="../../tf/compat/v1/random_uniform_initializer.html"><code>class random_uniform_initializer</code></a>: Initializer that generates tensors with a uniform distribution.</p>
<p><a href="../../tf/compat/v1/truncated_normal_initializer.html"><code>class truncated_normal_initializer</code></a>: Initializer that generates a truncated normal distribution.</p>
<p><a href="../../tf/compat/v1/uniform_unit_scaling_initializer.html"><code>class uniform_unit_scaling_initializer</code></a>: Initializer that generates tensors without scaling variance.</p>
<p><a href="../../tf/compat/v1/variable_scope.html"><code>class variable_scope</code></a>: A context manager for defining ops that creates variables (layers).</p>
<p><a href="../../tf/compat/v1/keras/initializers/VarianceScaling.html"><code>class variance_scaling_initializer</code></a>: Initializer capable of adapting its scale to the shape of weights tensors.</p>
<p><a href="../../tf/compat/v1/keras/initializers/Zeros.html"><code>class zeros_initializer</code></a>: Initializer that generates tensors initialized to 0.</p>
<h2 id="functions">Functions</h2>
<p><a href="../../tf/debugging/Assert.html"><code>Assert(...)</code></a>: Asserts that the given condition is true.</p>
<p><a href="../../tf/no_gradient.html"><code>NoGradient(...)</code></a>: Specifies that ops of type <code>op_type</code> is not differentiable.</p>
<p><a href="../../tf/no_gradient.html"><code>NotDifferentiable(...)</code></a>: Specifies that ops of type <code>op_type</code> is not differentiable.</p>
<p><a href="../../tf/compat/v1/Print.html"><code>Print(...)</code></a>: Prints a list of tensors. (deprecated)</p>
<p><a href="../../tf/math/abs.html"><code>abs(...)</code></a>: Computes the absolute value of a tensor.</p>
<p><a href="../../tf/math/accumulate_n.html"><code>accumulate_n(...)</code></a>: Returns the element-wise sum of a list of tensors.</p>
<p><a href="../../tf/math/acos.html"><code>acos(...)</code></a>: Computes acos of x element-wise.</p>
<p><a href="../../tf/math/acosh.html"><code>acosh(...)</code></a>: Computes inverse hyperbolic cosine of x element-wise.</p>
<p><a href="../../tf/math/add.html"><code>add(...)</code></a>: Returns x + y element-wise.</p>
<p><a href="../../tf/compat/v1/add_check_numerics_ops.html"><code>add_check_numerics_ops(...)</code></a>: Connect a <a href="../../tf/debugging/check_numerics.html"><code>tf.debugging.check_numerics</code></a> to every floating point tensor.</p>
<p><a href="../../tf/math/add_n.html"><code>add_n(...)</code></a>: Adds all input tensors element-wise.</p>
<p><a href="../../tf/compat/v1/add_to_collection.html"><code>add_to_collection(...)</code></a>: Wrapper for <code>Graph.add_to_collection()</code> using the default graph.</p>
<p><a href="../../tf/compat/v1/add_to_collections.html"><code>add_to_collections(...)</code></a>: Wrapper for <code>Graph.add_to_collections()</code> using the default graph.</p>
<p><a href="../../tf/compat/v1/all_variables.html"><code>all_variables(...)</code></a>: Use <a href="../../tf/compat/v1/global_variables.html"><code>tf.compat.v1.global_variables</code></a> instead. (deprecated)</p>
<p><a href="../../tf/math/angle.html"><code>angle(...)</code></a>: Returns the element-wise argument of a complex (or real) tensor.</p>
<p><a href="../../tf/compat/v1/arg_max.html"><code>arg_max(...)</code></a>: Returns the index with the largest value across dimensions of a tensor.</p>
<p><a href="../../tf/compat/v1/arg_min.html"><code>arg_min(...)</code></a>: Returns the index with the smallest value across dimensions of a tensor.</p>
<p><a href="../../tf/compat/v1/argmax.html"><code>argmax(...)</code></a>: Returns the index with the largest value across axes of a tensor. (deprecated arguments)</p>
<p><a href="../../tf/compat/v1/argmin.html"><code>argmin(...)</code></a>: Returns the index with the smallest value across axes of a tensor. (deprecated arguments)</p>
<p><a href="../../tf/argsort.html"><code>argsort(...)</code></a>: Returns the indices of a tensor that give its sorted order along an axis.</p>
<p><a href="../../tf/dtypes/as_dtype.html"><code>as_dtype(...)</code></a>: Converts the given <code>type_value</code> to a <code>DType</code>.</p>
<p><a href="../../tf/strings/as_string.html"><code>as_string(...)</code></a>: Converts each entry in the given tensor to strings.</p>
<p><a href="../../tf/math/asin.html"><code>asin(...)</code></a>: Computes the trignometric inverse sine of x element-wise.</p>
<p><a href="../../tf/math/asinh.html"><code>asinh(...)</code></a>: Computes inverse hyperbolic sine of x element-wise.</p>
<p><a href="../../tf/compat/v1/assert_equal.html"><code>assert_equal(...)</code></a>: Assert the condition <code>x == y</code> holds element-wise.</p>
<p><a href="../../tf/compat/v1/assert_greater.html"><code>assert_greater(...)</code></a>: Assert the condition <code>x &gt; y</code> holds element-wise.</p>
<p><a href="../../tf/compat/v1/assert_greater_equal.html"><code>assert_greater_equal(...)</code></a>: Assert the condition <code>x &gt;= y</code> holds element-wise.</p>
<p><a href="../../tf/compat/v1/assert_integer.html"><code>assert_integer(...)</code></a>: Assert that <code>x</code> is of integer dtype.</p>
<p><a href="../../tf/compat/v1/assert_less.html"><code>assert_less(...)</code></a>: Assert the condition <code>x &lt; y</code> holds element-wise.</p>
<p><a href="../../tf/compat/v1/assert_less_equal.html"><code>assert_less_equal(...)</code></a>: Assert the condition <code>x &lt;= y</code> holds element-wise.</p>
<p><a href="../../tf/compat/v1/assert_near.html"><code>assert_near(...)</code></a>: Assert the condition <code>x</code> and <code>y</code> are close element-wise.</p>
<p><a href="../../tf/compat/v1/assert_negative.html"><code>assert_negative(...)</code></a>: Assert the condition <code>x &lt; 0</code> holds element-wise.</p>
<p><a href="../../tf/compat/v1/assert_non_negative.html"><code>assert_non_negative(...)</code></a>: Assert the condition <code>x &gt;= 0</code> holds element-wise.</p>
<p><a href="../../tf/compat/v1/assert_non_positive.html"><code>assert_non_positive(...)</code></a>: Assert the condition <code>x &lt;= 0</code> holds element-wise.</p>
<p><a href="../../tf/compat/v1/assert_none_equal.html"><code>assert_none_equal(...)</code></a>: Assert the condition <code>x != y</code> holds for all elements.</p>
<p><a href="../../tf/compat/v1/assert_positive.html"><code>assert_positive(...)</code></a>: Assert the condition <code>x &gt; 0</code> holds element-wise.</p>
<p><a href="../../tf/debugging/assert_proper_iterable.html"><code>assert_proper_iterable(...)</code></a>: Static assert that values is a "proper" iterable.</p>
<p><a href="../../tf/compat/v1/assert_rank.html"><code>assert_rank(...)</code></a>: Assert <code>x</code> has rank equal to <code>rank</code>.</p>
<p><a href="../../tf/compat/v1/assert_rank_at_least.html"><code>assert_rank_at_least(...)</code></a>: Assert <code>x</code> has rank equal to <code>rank</code> or higher.</p>
<p><a href="../../tf/compat/v1/assert_rank_in.html"><code>assert_rank_in(...)</code></a>: Assert <code>x</code> has rank in <code>ranks</code>.</p>
<p><a href="../../tf/debugging/assert_same_float_dtype.html"><code>assert_same_float_dtype(...)</code></a>: Validate and return float type based on <code>tensors</code> and <code>dtype</code>.</p>
<p><a href="../../tf/compat/v1/assert_scalar.html"><code>assert_scalar(...)</code></a>: Asserts that the given <code>tensor</code> is a scalar (i.e. zero-dimensional).</p>
<p><a href="../../tf/compat/v1/assert_type.html"><code>assert_type(...)</code></a>: Statically asserts that the given <code>Tensor</code> is of the specified type.</p>
<p><a href="../../tf/compat/v1/assert_variables_initialized.html"><code>assert_variables_initialized(...)</code></a>: Returns an Op to check if variables are initialized.</p>
<p><a href="../../tf/compat/v1/assign.html"><code>assign(...)</code></a>: Update <code>ref</code> by assigning <code>value</code> to it.</p>
<p><a href="../../tf/compat/v1/assign_add.html"><code>assign_add(...)</code></a>: Update <code>ref</code> by adding <code>value</code> to it.</p>
<p><a href="../../tf/compat/v1/assign_sub.html"><code>assign_sub(...)</code></a>: Update <code>ref</code> by subtracting <code>value</code> from it.</p>
<p><a href="../../tf/math/atan.html"><code>atan(...)</code></a>: Computes the trignometric inverse tangent of x element-wise.</p>
<p><a href="../../tf/math/atan2.html"><code>atan2(...)</code></a>: Computes arctangent of <code>y/x</code> element-wise, respecting signs of the arguments.</p>
<p><a href="../../tf/math/atanh.html"><code>atanh(...)</code></a>: Computes inverse hyperbolic tangent of x element-wise.</p>
<p><a href="../../tf/compat/v1/batch_gather.html"><code>batch_gather(...)</code></a>: Gather slices from params according to indices with leading batch dims. (deprecated)</p>
<p><a href="../../tf/compat/v1/batch_scatter_update.html"><code>batch_scatter_update(...)</code></a>: Generalization of <a href="../../tf/compat/v1/scatter_update.html"><code>tf.compat.v1.scatter_update</code></a> to axis different than 0. (deprecated)</p>
<p><a href="../../tf/compat/v1/batch_to_space.html"><code>batch_to_space(...)</code></a>: BatchToSpace for 4-D tensors of type T.</p>
<p><a href="../../tf/compat/v1/batch_to_space_nd.html"><code>batch_to_space_nd(...)</code></a>: BatchToSpace for N-D tensors of type T.</p>
<p><a href="../../tf/math/betainc.html"><code>betainc(...)</code></a>: Compute the regularized incomplete beta integral \(I_x(a, b)\).</p>
<p><a href="../../tf/compat/v1/bincount.html"><code>bincount(...)</code></a>: Counts the number of occurrences of each value in an integer array.</p>
<p><a href="../../tf/bitcast.html"><code>bitcast(...)</code></a>: Bitcasts a tensor from one type to another without copying data.</p>
<p><a href="../../tf/compat/v1/boolean_mask.html"><code>boolean_mask(...)</code></a>: Apply boolean mask to tensor.</p>
<p><a href="../../tf/broadcast_dynamic_shape.html"><code>broadcast_dynamic_shape(...)</code></a>: Computes the shape of a broadcast given symbolic shapes.</p>
<p><a href="../../tf/broadcast_static_shape.html"><code>broadcast_static_shape(...)</code></a>: Computes the shape of a broadcast given known shapes.</p>
<p><a href="../../tf/broadcast_to.html"><code>broadcast_to(...)</code></a>: Broadcast an array for a compatible shape.</p>
<p><a href="../../tf/compat/v1/case.html"><code>case(...)</code></a>: Create a case operation.</p>
<p><a href="../../tf/dtypes/cast.html"><code>cast(...)</code></a>: Casts a tensor to a new type.</p>
<p><a href="../../tf/math/ceil.html"><code>ceil(...)</code></a>: Returns element-wise smallest integer not less than x.</p>
<p><a href="../../tf/debugging/check_numerics.html"><code>check_numerics(...)</code></a>: Checks a tensor for NaN and Inf values.</p>
<p><a href="../../tf/linalg/cholesky.html"><code>cholesky(...)</code></a>: Computes the Cholesky decomposition of one or more square matrices.</p>
<p><a href="../../tf/linalg/cholesky_solve.html"><code>cholesky_solve(...)</code></a>: Solves systems of linear eqns <code>A X = RHS</code>, given Cholesky factorizations.</p>
<p><a href="../../tf/compat/v1/clip_by_average_norm.html"><code>clip_by_average_norm(...)</code></a>: Clips tensor values to a maximum average L2-norm. (deprecated)</p>
<p><a href="../../tf/clip_by_global_norm.html"><code>clip_by_global_norm(...)</code></a>: Clips values of multiple tensors by the ratio of the sum of their norms.</p>
<p><a href="../../tf/clip_by_norm.html"><code>clip_by_norm(...)</code></a>: Clips tensor values to a maximum L2-norm.</p>
<p><a href="../../tf/clip_by_value.html"><code>clip_by_value(...)</code></a>: Clips tensor values to a specified min and max.</p>
<p><a href="../../tf/compat/v1/colocate_with.html"><code>colocate_with(...)</code></a>: DEPRECATED FUNCTION</p>
<p><a href="../../tf/dtypes/complex.html"><code>complex(...)</code></a>: Converts two real numbers to a complex number.</p>
<p><a href="../../tf/concat.html"><code>concat(...)</code></a>: Concatenates tensors along one dimension.</p>
<p><a href="../../tf/compat/v1/cond.html"><code>cond(...)</code></a>: Return <code>true_fn()</code> if the predicate <code>pred</code> is true else <code>false_fn()</code>. (deprecated arguments)</p>
<p><a href="../../tf/compat/v1/confusion_matrix.html"><code>confusion_matrix(...)</code></a>: Computes the confusion matrix from predictions and labels.</p>
<p><a href="../../tf/math/conj.html"><code>conj(...)</code></a>: Returns the complex conjugate of a complex number.</p>
<p><a href="../../tf/compat/v1/constant.html"><code>constant(...)</code></a>: Creates a constant tensor.</p>
<p><a href="../../tf/compat/v1/container.html"><code>container(...)</code></a>: Wrapper for <code>Graph.container()</code> using the default graph.</p>
<p><a href="../../tf/control_dependencies.html"><code>control_dependencies(...)</code></a>: Wrapper for <code>Graph.control_dependencies()</code> using the default graph.</p>
<p><a href="../../tf/compat/v1/control_flow_v2_enabled.html"><code>control_flow_v2_enabled(...)</code></a>: Returns <code>True</code> if v2 control flow is enabled.</p>
<p><a href="../../tf/compat/v1/convert_to_tensor.html"><code>convert_to_tensor(...)</code></a>: Converts the given <code>value</code> to a <code>Tensor</code>.</p>
<p><a href="../../tf/compat/v1/convert_to_tensor_or_indexed_slices.html"><code>convert_to_tensor_or_indexed_slices(...)</code></a>: Converts the given object to a <code>Tensor</code> or an <code>IndexedSlices</code>.</p>
<p><a href="../../tf/compat/v1/convert_to_tensor_or_sparse_tensor.html"><code>convert_to_tensor_or_sparse_tensor(...)</code></a>: Converts value to a <code>SparseTensor</code> or <code>Tensor</code>.</p>
<p><a href="../../tf/math/cos.html"><code>cos(...)</code></a>: Computes cos of x element-wise.</p>
<p><a href="../../tf/math/cosh.html"><code>cosh(...)</code></a>: Computes hyperbolic cosine of x element-wise.</p>
<p><a href="../../tf/compat/v1/count_nonzero.html"><code>count_nonzero(...)</code></a>: Computes number of nonzero elements across dimensions of a tensor. (deprecated arguments) (deprecated arguments)</p>
<p><a href="../../tf/compat/v1/count_up_to.html"><code>count_up_to(...)</code></a>: Increments 'ref' until it reaches 'limit'. (deprecated)</p>
<p><a href="../../tf/compat/v1/create_partitioned_variables.html"><code>create_partitioned_variables(...)</code></a>: Create a list of partitioned variables according to the given <code>slicing</code>. (deprecated)</p>
<p><a href="../../tf/linalg/cross.html"><code>cross(...)</code></a>: Compute the pairwise cross product.</p>
<p><a href="../../tf/math/cumprod.html"><code>cumprod(...)</code></a>: Compute the cumulative product of the tensor <code>x</code> along <code>axis</code>.</p>
<p><a href="../../tf/math/cumsum.html"><code>cumsum(...)</code></a>: Compute the cumulative sum of the tensor <code>x</code> along <code>axis</code>.</p>
<p><a href="../../tf/custom_gradient.html"><code>custom_gradient(...)</code></a>: Decorator to define a function with a custom gradient.</p>
<p><a href="../../tf/io/decode_base64.html"><code>decode_base64(...)</code></a>: Decode web-safe base64-encoded strings.</p>
<p><a href="../../tf/io/decode_compressed.html"><code>decode_compressed(...)</code></a>: Decompress strings.</p>
<p><a href="../../tf/compat/v1/decode_csv.html"><code>decode_csv(...)</code></a>: Convert CSV records to tensors. Each column maps to one tensor.</p>
<p><a href="../../tf/io/decode_json_example.html"><code>decode_json_example(...)</code></a>: Convert JSON-encoded Example records to binary protocol buffer strings.</p>
<p><a href="../../tf/compat/v1/decode_raw.html"><code>decode_raw(...)</code></a>: Convert raw byte strings into tensors. (deprecated arguments)</p>
<p><a href="../../tf/compat/v1/delete_session_tensor.html"><code>delete_session_tensor(...)</code></a>: Delete the tensor for the given tensor handle.</p>
<p><a href="../../tf/compat/v1/depth_to_space.html"><code>depth_to_space(...)</code></a>: DepthToSpace for tensors of type T.</p>
<p><a href="../../tf/quantization/dequantize.html"><code>dequantize(...)</code></a>: Dequantize the 'input' tensor into a float Tensor.</p>
<p><a href="../../tf/io/deserialize_many_sparse.html"><code>deserialize_many_sparse(...)</code></a>: Deserialize and concatenate <code>SparseTensors</code> from a serialized minibatch.</p>
<p><a href="../../tf/compat/v1/device.html"><code>device(...)</code></a>: Wrapper for <code>Graph.device()</code> using the default graph.</p>
<p><a href="../../tf/linalg/tensor_diag.html"><code>diag(...)</code></a>: Returns a diagonal tensor with a given diagonal values.</p>
<p><a href="../../tf/linalg/tensor_diag_part.html"><code>diag_part(...)</code></a>: Returns the diagonal part of the tensor.</p>
<p><a href="../../tf/math/digamma.html"><code>digamma(...)</code></a>: Computes Psi, the derivative of Lgamma (the log of the absolute value of</p>
<p><a href="../../tf/compat/dimension_at_index.html"><code>dimension_at_index(...)</code></a>: Compatibility utility required to allow for both V1 and V2 behavior in TF.</p>
<p><a href="../../tf/compat/dimension_value.html"><code>dimension_value(...)</code></a>: Compatibility utility required to allow for both V1 and V2 behavior in TF.</p>
<p><a href="../../tf/compat/v1/disable_control_flow_v2.html"><code>disable_control_flow_v2(...)</code></a>: Opts out of control flow v2.</p>
<p><a href="../../tf/compat/v1/disable_eager_execution.html"><code>disable_eager_execution(...)</code></a>: Disables eager execution.</p>
<p><a href="../../tf/compat/v1/disable_resource_variables.html"><code>disable_resource_variables(...)</code></a>: Opts out of resource variables. (deprecated)</p>
<p><a href="../../tf/compat/v1/disable_tensor_equality.html"><code>disable_tensor_equality(...)</code></a>: Compare Tensors by their id and be hashable.</p>
<p><a href="../../tf/compat/v1/disable_v2_behavior.html"><code>disable_v2_behavior(...)</code></a>: Disables TensorFlow 2.x behaviors.</p>
<p><a href="../../tf/compat/v1/disable_v2_tensorshape.html"><code>disable_v2_tensorshape(...)</code></a>: Disables the V2 TensorShape behavior and reverts to V1 behavior.</p>
<p><a href="../../tf/RaggedTensor.html#__div__"><code>div(...)</code></a>: Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)</p>
<p><a href="../../tf/math/divide_no_nan.html"><code>div_no_nan(...)</code></a>: Computes an unsafe divide which returns 0 if the y is zero.</p>
<p><a href="../../tf/math/divide.html"><code>divide(...)</code></a>: Computes Python style division of <code>x</code> by <code>y</code>.</p>
<p><a href="../../tf/dynamic_partition.html"><code>dynamic_partition(...)</code></a>: Partitions <code>data</code> into <code>num_partitions</code> tensors using indices from <code>partitions</code>.</p>
<p><a href="../../tf/dynamic_stitch.html"><code>dynamic_stitch(...)</code></a>: Interleave the values from the <code>data</code> tensors into a single tensor.</p>
<p><a href="../../tf/edit_distance.html"><code>edit_distance(...)</code></a>: Computes the Levenshtein distance between sequences.</p>
<p><a href="../../tf/einsum.html"><code>einsum(...)</code></a>: A generalized contraction between tensors of arbitrary dimension.</p>
<p><a href="../../tf/compat/v1/enable_control_flow_v2.html"><code>enable_control_flow_v2(...)</code></a>: Use control flow v2.</p>
<p><a href="../../tf/compat/v1/enable_eager_execution.html"><code>enable_eager_execution(...)</code></a>: Enables eager execution for the lifetime of this program.</p>
<p><a href="../../tf/compat/v1/enable_resource_variables.html"><code>enable_resource_variables(...)</code></a>: Creates resource variables by default.</p>
<p><a href="../../tf/compat/v1/enable_tensor_equality.html"><code>enable_tensor_equality(...)</code></a>: Compare Tensors with element-wise comparison and thus be unhashable.</p>
<p><a href="../../tf/compat/v1/enable_v2_behavior.html"><code>enable_v2_behavior(...)</code></a>: Enables TensorFlow 2.x behaviors.</p>
<p><a href="../../tf/compat/v1/enable_v2_tensorshape.html"><code>enable_v2_tensorshape(...)</code></a>: In TensorFlow 2.0, iterating over a TensorShape instance returns values.</p>
<p><a href="../../tf/io/encode_base64.html"><code>encode_base64(...)</code></a>: Encode strings into web-safe base64 format.</p>
<p><a href="../../tf/ensure_shape.html"><code>ensure_shape(...)</code></a>: Updates the shape of a tensor and checks at runtime that the shape holds.</p>
<p><a href="../../tf/math/equal.html"><code>equal(...)</code></a>: Returns the truth value of (x == y) element-wise.</p>
<p><a href="../../tf/math/erf.html"><code>erf(...)</code></a>: Computes the Gauss error function of <code>x</code> element-wise.</p>
<p><a href="../../tf/math/erfc.html"><code>erfc(...)</code></a>: Computes the complementary error function of <code>x</code> element-wise.</p>
<p><a href="../../tf/executing_eagerly.html"><code>executing_eagerly(...)</code></a>: Returns True if the current thread has eager execution enabled.</p>
<p><a href="../../tf/math/exp.html"><code>exp(...)</code></a>: Computes exponential of x element-wise.  \(y = e^x\).</p>
<p><a href="../../tf/compat/v1/expand_dims.html"><code>expand_dims(...)</code></a>: Inserts a dimension of 1 into a tensor's shape. (deprecated arguments)</p>
<p><a href="../../tf/math/expm1.html"><code>expm1(...)</code></a>: Computes <code>exp(x) - 1</code> element-wise.</p>
<p><a href="../../tf/compat/v1/extract_image_patches.html"><code>extract_image_patches(...)</code></a>: Extract <code>patches</code> from <code>images</code> and put them in the "depth" output dimension.</p>
<p><a href="../../tf/extract_volume_patches.html"><code>extract_volume_patches(...)</code></a>: Extract <code>patches</code> from <code>input</code> and put them in the "depth" output dimension. 3D extension of <code>extract_image_patches</code>.</p>
<p><a href="../../tf/eye.html"><code>eye(...)</code></a>: Construct an identity matrix, or a batch of matrices.</p>
<p><a href="../../tf/quantization/fake_quant_with_min_max_args.html"><code>fake_quant_with_min_max_args(...)</code></a>: Fake-quantize the 'inputs' tensor, type float to 'outputs' tensor of same type.</p>
<p><a href="../../tf/quantization/fake_quant_with_min_max_args_gradient.html"><code>fake_quant_with_min_max_args_gradient(...)</code></a>: Compute gradients for a FakeQuantWithMinMaxArgs operation.</p>
<p><a href="../../tf/quantization/fake_quant_with_min_max_vars.html"><code>fake_quant_with_min_max_vars(...)</code></a>: Fake-quantize the 'inputs' tensor of type float via global float scalars <code>min</code></p>
<p><a href="../../tf/quantization/fake_quant_with_min_max_vars_gradient.html"><code>fake_quant_with_min_max_vars_gradient(...)</code></a>: Compute gradients for a FakeQuantWithMinMaxVars operation.</p>
<p><a href="../../tf/quantization/fake_quant_with_min_max_vars_per_channel.html"><code>fake_quant_with_min_max_vars_per_channel(...)</code></a>: Fake-quantize the 'inputs' tensor of type float and one of the shapes: <code>[d]</code>,</p>
<p><a href="../../tf/quantization/fake_quant_with_min_max_vars_per_channel_gradient.html"><code>fake_quant_with_min_max_vars_per_channel_gradient(...)</code></a>: Compute gradients for a FakeQuantWithMinMaxVarsPerChannel operation.</p>
<p><a href="../../tf/signal/fft.html"><code>fft(...)</code></a>: Fast Fourier transform.</p>
<p><a href="../../tf/signal/fft2d.html"><code>fft2d(...)</code></a>: 2D fast Fourier transform.</p>
<p><a href="../../tf/signal/fft3d.html"><code>fft3d(...)</code></a>: 3D fast Fourier transform.</p>
<p><a href="../../tf/fill.html"><code>fill(...)</code></a>: Creates a tensor filled with a scalar value.</p>
<p><a href="../../tf/fingerprint.html"><code>fingerprint(...)</code></a>: Generates fingerprint values.</p>
<p><a href="../../tf/compat/v1/fixed_size_partitioner.html"><code>fixed_size_partitioner(...)</code></a>: Partitioner to specify a fixed number of shards along given axis.</p>
<p><a href="../../tf/math/floor.html"><code>floor(...)</code></a>: Returns element-wise largest integer not greater than x.</p>
<p><a href="../../tf/compat/v1/floor_div.html"><code>floor_div(...)</code></a>: Returns x // y element-wise.</p>
<p><a href="../../tf/math/floordiv.html"><code>floordiv(...)</code></a>: Divides <code>x / y</code> elementwise, rounding toward the most negative integer.</p>
<p><a href="../../tf/math/floormod.html"><code>floormod(...)</code></a>: Returns element-wise remainder of division. When <code>x &lt; 0</code> xor <code>y &lt; 0</code> is</p>
<p><a href="../../tf/foldl.html"><code>foldl(...)</code></a>: foldl on the list of tensors unpacked from <code>elems</code> on dimension 0.</p>
<p><a href="../../tf/foldr.html"><code>foldr(...)</code></a>: foldr on the list of tensors unpacked from <code>elems</code> on dimension 0.</p>
<p><a href="../../tf/function.html"><code>function(...)</code></a>: Creates a callable TensorFlow graph from a Python function.</p>
<p><a href="../../tf/compat/v1/gather.html"><code>gather(...)</code></a>: Gather slices from params axis axis according to indices.</p>
<p><a href="../../tf/compat/v1/gather_nd.html"><code>gather_nd(...)</code></a>: Gather slices from <code>params</code> into a Tensor with shape specified by <code>indices</code>.</p>
<p><a href="../../tf/compat/v1/get_collection.html"><code>get_collection(...)</code></a>: Wrapper for <code>Graph.get_collection()</code> using the default graph.</p>
<p><a href="../../tf/compat/v1/get_collection_ref.html"><code>get_collection_ref(...)</code></a>: Wrapper for <code>Graph.get_collection_ref()</code> using the default graph.</p>
<p><a href="../../tf/compat/v1/get_default_graph.html"><code>get_default_graph(...)</code></a>: Returns the default graph for the current thread.</p>
<p><a href="../../tf/compat/v1/get_default_session.html"><code>get_default_session(...)</code></a>: Returns the default session for the current thread.</p>
<p><a href="../../tf/compat/v1/get_local_variable.html"><code>get_local_variable(...)</code></a>: Gets an existing <em>local</em> variable or creates a new one.</p>
<p><a href="../../tf/get_logger.html"><code>get_logger(...)</code></a>: Return TF logger instance.</p>
<p><a href="../../tf/compat/v1/get_seed.html"><code>get_seed(...)</code></a>: Returns the local seeds an operation should use given an op-specific seed.</p>
<p><a href="../../tf/compat/v1/get_session_handle.html"><code>get_session_handle(...)</code></a>: Return the handle of <code>data</code>.</p>
<p><a href="../../tf/compat/v1/get_session_tensor.html"><code>get_session_tensor(...)</code></a>: Get the tensor of type <code>dtype</code> by feeding a tensor handle.</p>
<p><a href="../../tf/get_static_value.html"><code>get_static_value(...)</code></a>: Returns the constant value of the given tensor, if efficiently calculable.</p>
<p><a href="../../tf/compat/v1/get_variable.html"><code>get_variable(...)</code></a>: Gets an existing variable with these parameters or create a new one.</p>
<p><a href="../../tf/compat/v1/get_variable_scope.html"><code>get_variable_scope(...)</code></a>: Returns the current variable scope.</p>
<p><a href="../../tf/linalg/global_norm.html"><code>global_norm(...)</code></a>: Computes the global norm of multiple tensors.</p>
<p><a href="../../tf/compat/v1/global_variables.html"><code>global_variables(...)</code></a>: Returns global variables.</p>
<p><a href="../../tf/compat/v1/global_variables_initializer.html"><code>global_variables_initializer(...)</code></a>: Returns an Op that initializes global variables.</p>
<p><a href="../../tf/grad_pass_through.html"><code>grad_pass_through(...)</code></a>: Creates a grad-pass-through op with the forward behavior provided in f.</p>
<p><a href="../../tf/compat/v1/gradients.html"><code>gradients(...)</code></a>: Constructs symbolic derivatives of sum of <code>ys</code> w.r.t. x in <code>xs</code>.</p>
<p><a href="../../tf/math/greater.html"><code>greater(...)</code></a>: Returns the truth value of (x &gt; y) element-wise.</p>
<p><a href="../../tf/math/greater_equal.html"><code>greater_equal(...)</code></a>: Returns the truth value of (x &gt;= y) element-wise.</p>
<p><a href="../../tf/group.html"><code>group(...)</code></a>: Create an op that groups multiple operations.</p>
<p><a href="../../tf/guarantee_const.html"><code>guarantee_const(...)</code></a>: Gives a guarantee to the TF runtime that the input tensor is a constant.</p>
<p><a href="../../tf/compat/v1/hessians.html"><code>hessians(...)</code></a>: Constructs the Hessian of sum of <code>ys</code> with respect to <code>x</code> in <code>xs</code>.</p>
<p><a href="../../tf/histogram_fixed_width.html"><code>histogram_fixed_width(...)</code></a>: Return histogram of values.</p>
<p><a href="../../tf/histogram_fixed_width_bins.html"><code>histogram_fixed_width_bins(...)</code></a>: Bins the given values for use in a histogram.</p>
<p><a href="../../tf/identity.html"><code>identity(...)</code></a>: Return a tensor with the same shape and contents as input.</p>
<p><a href="../../tf/identity_n.html"><code>identity_n(...)</code></a>: Returns a list of tensors with the same shapes and contents as the input</p>
<p><a href="../../tf/signal/ifft.html"><code>ifft(...)</code></a>: Inverse fast Fourier transform.</p>
<p><a href="../../tf/signal/ifft2d.html"><code>ifft2d(...)</code></a>: Inverse 2D fast Fourier transform.</p>
<p><a href="../../tf/signal/ifft3d.html"><code>ifft3d(...)</code></a>: Inverse 3D fast Fourier transform.</p>
<p><a href="../../tf/math/igamma.html"><code>igamma(...)</code></a>: Compute the lower regularized incomplete Gamma function <code>P(a, x)</code>.</p>
<p><a href="../../tf/math/igammac.html"><code>igammac(...)</code></a>: Compute the upper regularized incomplete Gamma function <code>Q(a, x)</code>.</p>
<p><a href="../../tf/math/imag.html"><code>imag(...)</code></a>: Returns the imaginary part of a complex (or real) tensor.</p>
<p><a href="../../tf/graph_util/import_graph_def.html"><code>import_graph_def(...)</code></a>: Imports the graph from <code>graph_def</code> into the current default <code>Graph</code>. (deprecated arguments)</p>
<p><a href="../../tf/init_scope.html"><code>init_scope(...)</code></a>: A context manager that lifts ops out of control-flow scopes and function-building graphs.</p>
<p><a href="../../tf/compat/v1/initialize_all_tables.html"><code>initialize_all_tables(...)</code></a>: Returns an Op that initializes all tables of the default graph. (deprecated)</p>
<p><a href="../../tf/compat/v1/initialize_all_variables.html"><code>initialize_all_variables(...)</code></a>: See <a href="../../tf/compat/v1/global_variables_initializer.html"><code>tf.compat.v1.global_variables_initializer</code></a>. (deprecated)</p>
<p><a href="../../tf/compat/v1/initialize_local_variables.html"><code>initialize_local_variables(...)</code></a>: See <a href="../../tf/compat/v1/local_variables_initializer.html"><code>tf.compat.v1.local_variables_initializer</code></a>. (deprecated)</p>
<p><a href="../../tf/compat/v1/initialize_variables.html"><code>initialize_variables(...)</code></a>: See <a href="../../tf/compat/v1/variables_initializer.html"><code>tf.compat.v1.variables_initializer</code></a>. (deprecated)</p>
<p><a href="../../tf/math/invert_permutation.html"><code>invert_permutation(...)</code></a>: Computes the inverse permutation of a tensor.</p>
<p><a href="../../tf/math/is_finite.html"><code>is_finite(...)</code></a>: Returns which elements of x are finite.</p>
<p><a href="../../tf/math/is_inf.html"><code>is_inf(...)</code></a>: Returns which elements of x are Inf.</p>
<p><a href="../../tf/math/is_nan.html"><code>is_nan(...)</code></a>: Returns which elements of x are NaN.</p>
<p><a href="../../tf/math/is_non_decreasing.html"><code>is_non_decreasing(...)</code></a>: Returns <code>True</code> if <code>x</code> is non-decreasing.</p>
<p><a href="../../tf/debugging/is_numeric_tensor.html"><code>is_numeric_tensor(...)</code></a>: Returns <code>True</code> if the elements of <code>tensor</code> are numbers.</p>
<p><a href="../../tf/math/is_strictly_increasing.html"><code>is_strictly_increasing(...)</code></a>: Returns <code>True</code> if <code>x</code> is strictly increasing.</p>
<p><a href="../../tf/is_tensor.html"><code>is_tensor(...)</code></a>: Checks whether <code>x</code> is a tensor or "tensor-like".</p>
<p><a href="../../tf/compat/v1/is_variable_initialized.html"><code>is_variable_initialized(...)</code></a>: Tests if a variable has been initialized.</p>
<p><a href="../../tf/math/lbeta.html"><code>lbeta(...)</code></a>: Computes \(ln(|Beta(x)|)\), reducing along the last dimension.</p>
<p><a href="../../tf/math/less.html"><code>less(...)</code></a>: Returns the truth value of (x &lt; y) element-wise.</p>
<p><a href="../../tf/math/less_equal.html"><code>less_equal(...)</code></a>: Returns the truth value of (x &lt;= y) element-wise.</p>
<p><a href="../../tf/math/lgamma.html"><code>lgamma(...)</code></a>: Computes the log of the absolute value of <code>Gamma(x)</code> element-wise.</p>
<p><a href="../../tf/linspace.html"><code>lin_space(...)</code></a>: Generates values in an interval.</p>
<p><a href="../../tf/linspace.html"><code>linspace(...)</code></a>: Generates values in an interval.</p>
<p><a href="../../tf/compat/v1/load_file_system_library.html"><code>load_file_system_library(...)</code></a>: Loads a TensorFlow plugin, containing file system implementation. (deprecated)</p>
<p><a href="../../tf/load_library.html"><code>load_library(...)</code></a>: Loads a TensorFlow plugin.</p>
<p><a href="../../tf/load_op_library.html"><code>load_op_library(...)</code></a>: Loads a TensorFlow plugin, containing custom ops and kernels.</p>
<p><a href="../../tf/compat/v1/local_variables.html"><code>local_variables(...)</code></a>: Returns local variables.</p>
<p><a href="../../tf/compat/v1/local_variables_initializer.html"><code>local_variables_initializer(...)</code></a>: Returns an Op that initializes all local variables.</p>
<p><a href="../../tf/math/log.html"><code>log(...)</code></a>: Computes natural logarithm of x element-wise.</p>
<p><a href="../../tf/math/log1p.html"><code>log1p(...)</code></a>: Computes natural logarithm of (1 + x) element-wise.</p>
<p><a href="../../tf/math/log_sigmoid.html"><code>log_sigmoid(...)</code></a>: Computes log sigmoid of <code>x</code> element-wise.</p>
<p><a href="../../tf/math/logical_and.html"><code>logical_and(...)</code></a>: Returns the truth value of x AND y element-wise.</p>
<p><a href="../../tf/math/logical_not.html"><code>logical_not(...)</code></a>: Returns the truth value of NOT x element-wise.</p>
<p><a href="../../tf/math/logical_or.html"><code>logical_or(...)</code></a>: Returns the truth value of x OR y element-wise.</p>
<p><a href="../../tf/math/logical_xor.html"><code>logical_xor(...)</code></a>: Logical XOR function.</p>
<p><a href="../../tf/make_ndarray.html"><code>make_ndarray(...)</code></a>: Create a numpy ndarray from a tensor.</p>
<p><a href="../../tf/compat/v1/make_template.html"><code>make_template(...)</code></a>: Given an arbitrary function, wrap it so that it does variable sharing.</p>
<p><a href="../../tf/make_tensor_proto.html"><code>make_tensor_proto(...)</code></a>: Create a TensorProto.</p>
<p><a href="../../tf/map_fn.html"><code>map_fn(...)</code></a>: map on the list of tensors unpacked from <code>elems</code> on dimension 0.</p>
<p><a href="../../tf/io/matching_files.html"><code>matching_files(...)</code></a>: Returns the set of files matching one or more glob patterns.</p>
<p><a href="../../tf/linalg/matmul.html"><code>matmul(...)</code></a>: Multiplies matrix <code>a</code> by matrix <code>b</code>, producing <code>a</code> * <code>b</code>.</p>
<p><a href="../../tf/linalg/band_part.html"><code>matrix_band_part(...)</code></a>: Copy a tensor setting everything outside a central band in each innermost matrix</p>
<p><a href="../../tf/linalg/det.html"><code>matrix_determinant(...)</code></a>: Computes the determinant of one or more square matrices.</p>
<p><a href="../../tf/linalg/diag.html"><code>matrix_diag(...)</code></a>: Returns a batched diagonal tensor with given batched diagonal values.</p>
<p><a href="../../tf/linalg/diag_part.html"><code>matrix_diag_part(...)</code></a>: Returns the batched diagonal part of a batched tensor.</p>
<p><a href="../../tf/linalg/inv.html"><code>matrix_inverse(...)</code></a>: Computes the inverse of one or more square invertible matrices or their</p>
<p><a href="../../tf/linalg/set_diag.html"><code>matrix_set_diag(...)</code></a>: Returns a batched matrix tensor with new batched diagonal values.</p>
<p><a href="../../tf/linalg/solve.html"><code>matrix_solve(...)</code></a>: Solves systems of linear equations.</p>
<p><a href="../../tf/linalg/lstsq.html"><code>matrix_solve_ls(...)</code></a>: Solves one or more linear least-squares problems.</p>
<p><a href="../../tf/linalg/sqrtm.html"><code>matrix_square_root(...)</code></a>: Computes the matrix square root of one or more square matrices:</p>
<p><a href="../../tf/linalg/matrix_transpose.html"><code>matrix_transpose(...)</code></a>: Transposes last two dimensions of tensor <code>a</code>.</p>
<p><a href="../../tf/linalg/triangular_solve.html"><code>matrix_triangular_solve(...)</code></a>: Solves systems of linear equations with upper or lower triangular matrices by backsubstitution.</p>
<p><a href="../../tf/math/maximum.html"><code>maximum(...)</code></a>: Returns the max of x and y (i.e. x &gt; y ? x : y) element-wise.</p>
<p><a href="../../tf/meshgrid.html"><code>meshgrid(...)</code></a>: Broadcasts parameters for evaluation on an N-D grid.</p>
<p><a href="../../tf/compat/v1/min_max_variable_partitioner.html"><code>min_max_variable_partitioner(...)</code></a>: Partitioner to allocate minimum size per slice.</p>
<p><a href="../../tf/math/minimum.html"><code>minimum(...)</code></a>: Returns the min of x and y (i.e. x &lt; y ? x : y) element-wise.</p>
<p><a href="../../tf/math/floormod.html"><code>mod(...)</code></a>: Returns element-wise remainder of division. When <code>x &lt; 0</code> xor <code>y &lt; 0</code> is</p>
<p><a href="../../tf/compat/v1/model_variables.html"><code>model_variables(...)</code></a>: Returns all variables in the MODEL_VARIABLES collection.</p>
<p><a href="../../tf/compat/v1/moving_average_variables.html"><code>moving_average_variables(...)</code></a>: Returns all variables that maintain their moving averages.</p>
<p><a href="../../tf/compat/v1/multinomial.html"><code>multinomial(...)</code></a>: Draws samples from a multinomial distribution. (deprecated)</p>
<p><a href="../../tf/math/multiply.html"><code>multiply(...)</code></a>: Returns x * y element-wise.</p>
<p><a href="../../tf/math/negative.html"><code>negative(...)</code></a>: Computes numerical negative value element-wise.</p>
<p><a href="../../tf/no_gradient.html"><code>no_gradient(...)</code></a>: Specifies that ops of type <code>op_type</code> is not differentiable.</p>
<p><a href="../../tf/no_op.html"><code>no_op(...)</code></a>: Does nothing. Only useful as a placeholder for control edges.</p>
<p><a href="../../tf/compat/v1/no_regularizer.html"><code>no_regularizer(...)</code></a>: Use this function to prevent regularization of variables.</p>
<p><a href="../../tf/nondifferentiable_batch_function.html"><code>nondifferentiable_batch_function(...)</code></a>: Batches the computation done by the decorated function.</p>
<p><a href="../../tf/compat/v1/norm.html"><code>norm(...)</code></a>: Computes the norm of vectors, matrices, and tensors. (deprecated arguments)</p>
<p><a href="../../tf/math/not_equal.html"><code>not_equal(...)</code></a>: Returns the truth value of (x != y) element-wise.</p>
<p><a href="../../tf/numpy_function.html"><code>numpy_function(...)</code></a>: Wraps a python function and uses it as a TensorFlow op.</p>
<p><a href="../../tf/one_hot.html"><code>one_hot(...)</code></a>: Returns a one-hot tensor.</p>
<p><a href="../../tf/ones.html"><code>ones(...)</code></a>: Creates a tensor with all elements set to 1.</p>
<p><a href="../../tf/compat/v1/ones_like.html"><code>ones_like(...)</code></a>: Creates a tensor with all elements set to 1.</p>
<p><a href="../../tf/compat/v1/op_scope.html"><code>op_scope(...)</code></a>: DEPRECATED. Same as name_scope above, just different argument order.</p>
<p><a href="../../tf/compat/v1/pad.html"><code>pad(...)</code></a>: Pads a tensor.</p>
<p><a href="../../tf/parallel_stack.html"><code>parallel_stack(...)</code></a>: Stacks a list of rank-<code>R</code> tensors into one rank-<code>(R+1)</code> tensor in parallel.</p>
<p><a href="../../tf/compat/v1/parse_example.html"><code>parse_example(...)</code></a>: Parses <code>Example</code> protos into a <code>dict</code> of tensors.</p>
<p><a href="../../tf/compat/v1/parse_single_example.html"><code>parse_single_example(...)</code></a>: Parses a single <code>Example</code> proto.</p>
<p><a href="../../tf/io/parse_single_sequence_example.html"><code>parse_single_sequence_example(...)</code></a>: Parses a single <code>SequenceExample</code> proto.</p>
<p><a href="../../tf/io/parse_tensor.html"><code>parse_tensor(...)</code></a>: Transforms a serialized tensorflow.TensorProto proto into a Tensor.</p>
<p><a href="../../tf/compat/v1/placeholder.html"><code>placeholder(...)</code></a>: Inserts a placeholder for a tensor that will be always fed.</p>
<p><a href="../../tf/compat/v1/placeholder_with_default.html"><code>placeholder_with_default(...)</code></a>: A placeholder op that passes through <code>input</code> when its output is not fed.</p>
<p><a href="../../tf/math/polygamma.html"><code>polygamma(...)</code></a>: Compute the polygamma function \(\psi^{(n)}(x)\).</p>
<p><a href="../../tf/math/pow.html"><code>pow(...)</code></a>: Computes the power of one value to another.</p>
<p><a href="../../tf/print.html"><code>print(...)</code></a>: Print the specified inputs.</p>
<p><a href="../../tf/compat/v1/py_func.html"><code>py_func(...)</code></a>: Wraps a python function and uses it as a TensorFlow op.</p>
<p><a href="../../tf/py_function.html"><code>py_function(...)</code></a>: Wraps a python function into a TensorFlow op that executes it eagerly.</p>
<p><a href="../../tf/linalg/qr.html"><code>qr(...)</code></a>: Computes the QR decompositions of one or more matrices.</p>
<p><a href="../../tf/quantization/quantize.html"><code>quantize(...)</code></a>: Quantize the 'input' tensor of type float to 'output' tensor of type 'T'.</p>
<p><a href="../../tf/compat/v1/quantize_v2.html"><code>quantize_v2(...)</code></a>: Please use <a href="../../tf/quantization/quantize.html"><code>tf.quantization.quantize</code></a> instead.</p>
<p><a href="../../tf/quantization/quantized_concat.html"><code>quantized_concat(...)</code></a>: Concatenates quantized tensors along one dimension.</p>
<p><a href="../../tf/image/random_crop.html"><code>random_crop(...)</code></a>: Randomly crops a tensor to a given size.</p>
<p><a href="../../tf/random/gamma.html"><code>random_gamma(...)</code></a>: Draws <code>shape</code> samples from each of the given Gamma distribution(s).</p>
<p><a href="../../tf/random/normal.html"><code>random_normal(...)</code></a>: Outputs random values from a normal distribution.</p>
<p><a href="../../tf/compat/v1/random_poisson.html"><code>random_poisson(...)</code></a>: Draws <code>shape</code> samples from each of the given Poisson distribution(s).</p>
<p><a href="../../tf/random/shuffle.html"><code>random_shuffle(...)</code></a>: Randomly shuffles a tensor along its first dimension.</p>
<p><a href="../../tf/random/uniform.html"><code>random_uniform(...)</code></a>: Outputs random values from a uniform distribution.</p>
<p><a href="../../tf/range.html"><code>range(...)</code></a>: Creates a sequence of numbers.</p>
<p><a href="../../tf/rank.html"><code>rank(...)</code></a>: Returns the rank of a tensor.</p>
<p><a href="../../tf/io/read_file.html"><code>read_file(...)</code></a>: Reads and outputs the entire contents of the input filename.</p>
<p><a href="../../tf/math/real.html"><code>real(...)</code></a>: Returns the real part of a complex (or real) tensor.</p>
<p><a href="../../tf/realdiv.html"><code>realdiv(...)</code></a>: Returns x / y element-wise for real types.</p>
<p><a href="../../tf/math/reciprocal.html"><code>reciprocal(...)</code></a>: Computes the reciprocal of x element-wise.</p>
<p><a href="../../tf/recompute_grad.html"><code>recompute_grad(...)</code></a>: An eager-compatible version of recompute_grad.</p>
<p><a href="../../tf/compat/v1/reduce_all.html"><code>reduce_all(...)</code></a>: Computes the "logical and" of elements across dimensions of a tensor. (deprecated arguments)</p>
<p><a href="../../tf/compat/v1/reduce_any.html"><code>reduce_any(...)</code></a>: Computes the "logical or" of elements across dimensions of a tensor. (deprecated arguments)</p>
<p><a href="../../tf/compat/v1/reduce_join.html"><code>reduce_join(...)</code></a>: Joins a string Tensor across the given dimensions.</p>
<p><a href="../../tf/compat/v1/reduce_logsumexp.html"><code>reduce_logsumexp(...)</code></a>: Computes log(sum(exp(elements across dimensions of a tensor))). (deprecated arguments)</p>
<p><a href="../../tf/compat/v1/reduce_max.html"><code>reduce_max(...)</code></a>: Computes the maximum of elements across dimensions of a tensor. (deprecated arguments)</p>
<p><a href="../../tf/compat/v1/reduce_mean.html"><code>reduce_mean(...)</code></a>: Computes the mean of elements across dimensions of a tensor.</p>
<p><a href="../../tf/compat/v1/reduce_min.html"><code>reduce_min(...)</code></a>: Computes the minimum of elements across dimensions of a tensor. (deprecated arguments)</p>
<p><a href="../../tf/compat/v1/reduce_prod.html"><code>reduce_prod(...)</code></a>: Computes the product of elements across dimensions of a tensor. (deprecated arguments)</p>
<p><a href="../../tf/compat/v1/reduce_sum.html"><code>reduce_sum(...)</code></a>: Computes the sum of elements across dimensions of a tensor. (deprecated arguments)</p>
<p><a href="../../tf/strings/regex_replace.html"><code>regex_replace(...)</code></a>: Replace elements of <code>input</code> matching regex <code>pattern</code> with <code>rewrite</code>.</p>
<p><a href="../../tf/register_tensor_conversion_function.html"><code>register_tensor_conversion_function(...)</code></a>: Registers a function for converting objects of <code>base_type</code> to <code>Tensor</code>.</p>
<p><a href="../../tf/compat/v1/report_uninitialized_variables.html"><code>report_uninitialized_variables(...)</code></a>: Adds ops to list the names of uninitialized variables.</p>
<p><a href="../../tf/required_space_to_batch_paddings.html"><code>required_space_to_batch_paddings(...)</code></a>: Calculate padding required to make block_shape divide input_shape.</p>
<p><a href="../../tf/compat/v1/reset_default_graph.html"><code>reset_default_graph(...)</code></a>: Clears the default graph stack and resets the global default graph.</p>
<p><a href="../../tf/reshape.html"><code>reshape(...)</code></a>: Reshapes a tensor.</p>
<p><a href="../../tf/compat/v1/resource_variables_enabled.html"><code>resource_variables_enabled(...)</code></a>: Returns <code>True</code> if resource variables are enabled.</p>
<p><a href="../../tf/reverse.html"><code>reverse(...)</code></a>: Reverses specific dimensions of a tensor.</p>
<p><a href="../../tf/compat/v1/reverse_sequence.html"><code>reverse_sequence(...)</code></a>: Reverses variable length slices.</p>
<p><a href="../../tf/reverse.html"><code>reverse_v2(...)</code></a>: Reverses specific dimensions of a tensor.</p>
<p><a href="../../tf/math/rint.html"><code>rint(...)</code></a>: Returns element-wise integer closest to x.</p>
<p><a href="../../tf/roll.html"><code>roll(...)</code></a>: Rolls the elements of a tensor along an axis.</p>
<p><a href="../../tf/math/round.html"><code>round(...)</code></a>: Rounds the values of a tensor to the nearest integer, element-wise.</p>
<p><a href="../../tf/math/rsqrt.html"><code>rsqrt(...)</code></a>: Computes reciprocal of square root of x element-wise.</p>
<p><a href="../../tf/dtypes/saturate_cast.html"><code>saturate_cast(...)</code></a>: Performs a safe saturating cast of <code>value</code> to <code>dtype</code>.</p>
<p><a href="../../tf/compat/v1/scalar_mul.html"><code>scalar_mul(...)</code></a>: Multiplies a scalar times a <code>Tensor</code> or <code>IndexedSlices</code> object.</p>
<p><a href="../../tf/scan.html"><code>scan(...)</code></a>: scan on the list of tensors unpacked from <code>elems</code> on dimension 0.</p>
<p><a href="../../tf/compat/v1/scatter_add.html"><code>scatter_add(...)</code></a>: Adds sparse updates to the variable referenced by <code>resource</code>.</p>
<p><a href="../../tf/compat/v1/scatter_div.html"><code>scatter_div(...)</code></a>: Divides a variable reference by sparse updates.</p>
<p><a href="../../tf/compat/v1/scatter_max.html"><code>scatter_max(...)</code></a>: Reduces sparse updates into a variable reference using the <code>max</code> operation.</p>
<p><a href="../../tf/compat/v1/scatter_min.html"><code>scatter_min(...)</code></a>: Reduces sparse updates into a variable reference using the <code>min</code> operation.</p>
<p><a href="../../tf/compat/v1/scatter_mul.html"><code>scatter_mul(...)</code></a>: Multiplies sparse updates into a variable reference.</p>
<p><a href="../../tf/scatter_nd.html"><code>scatter_nd(...)</code></a>: Scatter <code>updates</code> into a new tensor according to <code>indices</code>.</p>
<p><a href="../../tf/compat/v1/scatter_nd_add.html"><code>scatter_nd_add(...)</code></a>: Applies sparse addition to individual values or slices in a Variable.</p>
<p><a href="../../tf/compat/v1/scatter_nd_sub.html"><code>scatter_nd_sub(...)</code></a>: Applies sparse subtraction to individual values or slices in a Variable.</p>
<p><a href="../../tf/compat/v1/scatter_nd_update.html"><code>scatter_nd_update(...)</code></a>: Applies sparse <code>updates</code> to individual values or slices in a Variable.</p>
<p><a href="../../tf/compat/v1/scatter_sub.html"><code>scatter_sub(...)</code></a>: Subtracts sparse updates to a variable reference.</p>
<p><a href="../../tf/compat/v1/scatter_update.html"><code>scatter_update(...)</code></a>: Applies sparse updates to a variable reference.</p>
<p><a href="../../tf/searchsorted.html"><code>searchsorted(...)</code></a>: Searches input tensor for values on the innermost dimension.</p>
<p><a href="../../tf/math/segment_max.html"><code>segment_max(...)</code></a>: Computes the maximum along segments of a tensor.</p>
<p><a href="../../tf/math/segment_mean.html"><code>segment_mean(...)</code></a>: Computes the mean along segments of a tensor.</p>
<p><a href="../../tf/math/segment_min.html"><code>segment_min(...)</code></a>: Computes the minimum along segments of a tensor.</p>
<p><a href="../../tf/math/segment_prod.html"><code>segment_prod(...)</code></a>: Computes the product along segments of a tensor.</p>
<p><a href="../../tf/math/segment_sum.html"><code>segment_sum(...)</code></a>: Computes the sum along segments of a tensor.</p>
<p><a href="../../tf/linalg/eigh.html"><code>self_adjoint_eig(...)</code></a>: Computes the eigen decomposition of a batch of self-adjoint matrices.</p>
<p><a href="../../tf/linalg/eigvalsh.html"><code>self_adjoint_eigvals(...)</code></a>: Computes the eigenvalues of one or more self-adjoint matrices.</p>
<p><a href="../../tf/sequence_mask.html"><code>sequence_mask(...)</code></a>: Returns a mask tensor representing the first N positions of each cell.</p>
<p><a href="../../tf/compat/v1/serialize_many_sparse.html"><code>serialize_many_sparse(...)</code></a>: Serialize <code>N</code>-minibatch <code>SparseTensor</code> into an <code>[N, 3]</code> <code>Tensor</code>.</p>
<p><a href="../../tf/compat/v1/serialize_sparse.html"><code>serialize_sparse(...)</code></a>: Serialize a <code>SparseTensor</code> into a 3-vector (1-D <code>Tensor</code>) object.</p>
<p><a href="../../tf/io/serialize_tensor.html"><code>serialize_tensor(...)</code></a>: Transforms a Tensor into a serialized TensorProto proto.</p>
<p><a href="../../tf/compat/v1/set_random_seed.html"><code>set_random_seed(...)</code></a>: Sets the graph-level random seed for the default graph.</p>
<p><a href="../../tf/compat/v1/setdiff1d.html"><code>setdiff1d(...)</code></a>: Computes the difference between two lists of numbers or strings.</p>
<p><a href="../../tf/compat/v1/shape.html"><code>shape(...)</code></a>: Returns the shape of a tensor.</p>
<p><a href="../../tf/shape_n.html"><code>shape_n(...)</code></a>: Returns shape of tensors.</p>
<p><a href="../../tf/math/sigmoid.html"><code>sigmoid(...)</code></a>: Computes sigmoid of <code>x</code> element-wise.</p>
<p><a href="../../tf/math/sign.html"><code>sign(...)</code></a>: Returns an element-wise indication of the sign of a number.</p>
<p><a href="../../tf/math/sin.html"><code>sin(...)</code></a>: Computes sine of x element-wise.</p>
<p><a href="../../tf/math/sinh.html"><code>sinh(...)</code></a>: Computes hyperbolic sine of x element-wise.</p>
<p><a href="../../tf/compat/v1/size.html"><code>size(...)</code></a>: Returns the size of a tensor.</p>
<p><a href="../../tf/slice.html"><code>slice(...)</code></a>: Extracts a slice from a tensor.</p>
<p><a href="../../tf/sort.html"><code>sort(...)</code></a>: Sorts a tensor.</p>
<p><a href="../../tf/compat/v1/space_to_batch.html"><code>space_to_batch(...)</code></a>: SpaceToBatch for 4-D tensors of type T.</p>
<p><a href="../../tf/space_to_batch_nd.html"><code>space_to_batch_nd(...)</code></a>: SpaceToBatch for N-D tensors of type T.</p>
<p><a href="../../tf/compat/v1/space_to_depth.html"><code>space_to_depth(...)</code></a>: SpaceToDepth for tensors of type T.</p>
<p><a href="../../tf/compat/v1/sparse_add.html"><code>sparse_add(...)</code></a>: Adds two tensors, at least one of each is a <code>SparseTensor</code>. (deprecated arguments)</p>
<p><a href="../../tf/compat/v1/sparse_concat.html"><code>sparse_concat(...)</code></a>: Concatenates a list of <code>SparseTensor</code> along the specified dimension. (deprecated arguments)</p>
<p><a href="../../tf/sparse/fill_empty_rows.html"><code>sparse_fill_empty_rows(...)</code></a>: Fills empty rows in the input 2-D <code>SparseTensor</code> with a default value.</p>
<p><a href="../../tf/sparse/mask.html"><code>sparse_mask(...)</code></a>: Masks elements of <code>IndexedSlices</code>.</p>
<p><a href="../../tf/compat/v1/sparse_matmul.html"><code>sparse_matmul(...)</code></a>: Multiply matrix "a" by matrix "b".</p>
<p><a href="../../tf/sparse/maximum.html"><code>sparse_maximum(...)</code></a>: Returns the element-wise max of two SparseTensors.</p>
<p><a href="../../tf/compat/v1/sparse_merge.html"><code>sparse_merge(...)</code></a>: Combines a batch of feature ids and values into a single <code>SparseTensor</code>. (deprecated)</p>
<p><a href="../../tf/sparse/minimum.html"><code>sparse_minimum(...)</code></a>: Returns the element-wise min of two SparseTensors.</p>
<p><a href="../../tf/compat/v1/sparse_placeholder.html"><code>sparse_placeholder(...)</code></a>: Inserts a placeholder for a sparse tensor that will be always fed.</p>
<p><a href="../../tf/compat/v1/sparse_reduce_max.html"><code>sparse_reduce_max(...)</code></a>: Computes the max of elements across dimensions of a SparseTensor. (deprecated arguments) (deprecated arguments)</p>
<p><a href="../../tf/compat/v1/sparse_reduce_max_sparse.html"><code>sparse_reduce_max_sparse(...)</code></a>: Computes the max of elements across dimensions of a SparseTensor. (deprecated arguments)</p>
<p><a href="../../tf/compat/v1/sparse_reduce_sum.html"><code>sparse_reduce_sum(...)</code></a>: Computes the sum of elements across dimensions of a SparseTensor. (deprecated arguments) (deprecated arguments)</p>
<p><a href="../../tf/compat/v1/sparse_reduce_sum_sparse.html"><code>sparse_reduce_sum_sparse(...)</code></a>: Computes the sum of elements across dimensions of a SparseTensor. (deprecated arguments)</p>
<p><a href="../../tf/sparse/reorder.html"><code>sparse_reorder(...)</code></a>: Reorders a <code>SparseTensor</code> into the canonical, row-major ordering.</p>
<p><a href="../../tf/sparse/reset_shape.html"><code>sparse_reset_shape(...)</code></a>: Resets the shape of a <code>SparseTensor</code> with indices and values unchanged.</p>
<p><a href="../../tf/sparse/reshape.html"><code>sparse_reshape(...)</code></a>: Reshapes a <code>SparseTensor</code> to represent values in a new dense shape.</p>
<p><a href="../../tf/sparse/retain.html"><code>sparse_retain(...)</code></a>: Retains specified non-empty values within a <code>SparseTensor</code>.</p>
<p><a href="../../tf/compat/v1/sparse_segment_mean.html"><code>sparse_segment_mean(...)</code></a>: Computes the mean along sparse segments of a tensor.</p>
<p><a href="../../tf/compat/v1/sparse_segment_sqrt_n.html"><code>sparse_segment_sqrt_n(...)</code></a>: Computes the sum along sparse segments of a tensor divided by the sqrt(N).</p>
<p><a href="../../tf/compat/v1/sparse_segment_sum.html"><code>sparse_segment_sum(...)</code></a>: Computes the sum along sparse segments of a tensor.</p>
<p><a href="../../tf/sparse/slice.html"><code>sparse_slice(...)</code></a>: Slice a <code>SparseTensor</code> based on the <code>start</code> and `size.</p>
<p><a href="../../tf/sparse/softmax.html"><code>sparse_softmax(...)</code></a>: Applies softmax to a batched N-D <code>SparseTensor</code>.</p>
<p><a href="../../tf/compat/v1/sparse_split.html"><code>sparse_split(...)</code></a>: Split a <code>SparseTensor</code> into <code>num_split</code> tensors along <code>axis</code>. (deprecated arguments)</p>
<p><a href="../../tf/sparse/sparse_dense_matmul.html"><code>sparse_tensor_dense_matmul(...)</code></a>: Multiply SparseTensor (of rank 2) "A" by dense matrix "B".</p>
<p><a href="../../tf/sparse/to_dense.html"><code>sparse_tensor_to_dense(...)</code></a>: Converts a <code>SparseTensor</code> into a dense tensor.</p>
<p><a href="../../tf/compat/v1/sparse_to_dense.html"><code>sparse_to_dense(...)</code></a>: Converts a sparse representation into a dense tensor. (deprecated)</p>
<p><a href="../../tf/sparse/to_indicator.html"><code>sparse_to_indicator(...)</code></a>: Converts a <code>SparseTensor</code> of ids into a dense bool indicator tensor.</p>
<p><a href="../../tf/sparse/transpose.html"><code>sparse_transpose(...)</code></a>: Transposes a <code>SparseTensor</code></p>
<p><a href="../../tf/split.html"><code>split(...)</code></a>: Splits a tensor into sub tensors.</p>
<p><a href="../../tf/math/sqrt.html"><code>sqrt(...)</code></a>: Computes square root of x element-wise.</p>
<p><a href="../../tf/math/square.html"><code>square(...)</code></a>: Computes square of x element-wise.</p>
<p><a href="../../tf/math/squared_difference.html"><code>squared_difference(...)</code></a>: Returns (x - y)(x - y) element-wise.</p>
<p><a href="../../tf/compat/v1/squeeze.html"><code>squeeze(...)</code></a>: Removes dimensions of size 1 from the shape of a tensor. (deprecated arguments)</p>
<p><a href="../../tf/stack.html"><code>stack(...)</code></a>: Stacks a list of rank-<code>R</code> tensors into one rank-<code>(R+1)</code> tensor.</p>
<p><a href="../../tf/stop_gradient.html"><code>stop_gradient(...)</code></a>: Stops gradient computation.</p>
<p><a href="../../tf/strided_slice.html"><code>strided_slice(...)</code></a>: Extracts a strided slice of a tensor (generalized python array indexing).</p>
<p><a href="../../tf/strings/join.html"><code>string_join(...)</code></a>: Joins the strings in the given list of string tensors into one tensor;</p>
<p><a href="../../tf/compat/v1/string_split.html"><code>string_split(...)</code></a>: Split elements of <code>source</code> based on <code>delimiter</code>. (deprecated arguments)</p>
<p><a href="../../tf/strings/strip.html"><code>string_strip(...)</code></a>: Strip leading and trailing whitespaces from the Tensor.</p>
<p><a href="../../tf/compat/v1/string_to_hash_bucket.html"><code>string_to_hash_bucket(...)</code></a>: Converts each string in the input Tensor to its hash mod by a number of buckets.</p>
<p><a href="../../tf/strings/to_hash_bucket_fast.html"><code>string_to_hash_bucket_fast(...)</code></a>: Converts each string in the input Tensor to its hash mod by a number of buckets.</p>
<p><a href="../../tf/strings/to_hash_bucket_strong.html"><code>string_to_hash_bucket_strong(...)</code></a>: Converts each string in the input Tensor to its hash mod by a number of buckets.</p>
<p><a href="../../tf/compat/v1/string_to_number.html"><code>string_to_number(...)</code></a>: Converts each string in the input Tensor to the specified numeric type.</p>
<p><a href="../../tf/compat/v1/substr.html"><code>substr(...)</code></a>: Return substrings from <code>Tensor</code> of strings.</p>
<p><a href="../../tf/math/subtract.html"><code>subtract(...)</code></a>: Returns x - y element-wise.</p>
<p><a href="../../tf/linalg/svd.html"><code>svd(...)</code></a>: Computes the singular value decompositions of one or more matrices.</p>
<p><a href="../../tf/switch_case.html"><code>switch_case(...)</code></a>: Create a switch/case operation, i.e. an integer-indexed conditional.</p>
<p><a href="../../tf/compat/v1/tables_initializer.html"><code>tables_initializer(...)</code></a>: Returns an Op that initializes all tables of the default graph.</p>
<p><a href="../../tf/math/tan.html"><code>tan(...)</code></a>: Computes tan of x element-wise.</p>
<p><a href="../../tf/math/tanh.html"><code>tanh(...)</code></a>: Computes hyperbolic tangent of <code>x</code> element-wise.</p>
<p><a href="../../tf/tensor_scatter_nd_add.html"><code>tensor_scatter_add(...)</code></a>: Adds sparse <code>updates</code> to an existing tensor according to <code>indices</code>.</p>
<p><a href="../../tf/tensor_scatter_nd_add.html"><code>tensor_scatter_nd_add(...)</code></a>: Adds sparse <code>updates</code> to an existing tensor according to <code>indices</code>.</p>
<p><a href="../../tf/tensor_scatter_nd_sub.html"><code>tensor_scatter_nd_sub(...)</code></a>: Subtracts sparse <code>updates</code> from an existing tensor according to <code>indices</code>.</p>
<p><a href="../../tf/tensor_scatter_nd_update.html"><code>tensor_scatter_nd_update(...)</code></a>: Scatter <code>updates</code> into an existing tensor according to <code>indices</code>.</p>
<p><a href="../../tf/tensor_scatter_nd_sub.html"><code>tensor_scatter_sub(...)</code></a>: Subtracts sparse <code>updates</code> from an existing tensor according to <code>indices</code>.</p>
<p><a href="../../tf/tensor_scatter_nd_update.html"><code>tensor_scatter_update(...)</code></a>: Scatter <code>updates</code> into an existing tensor according to <code>indices</code>.</p>
<p><a href="../../tf/tensordot.html"><code>tensordot(...)</code></a>: Tensor contraction of a and b along specified axes.</p>
<p><a href="../../tf/tile.html"><code>tile(...)</code></a>: Constructs a tensor by tiling a given tensor.</p>
<p><a href="../../tf/timestamp.html"><code>timestamp(...)</code></a>: Provides the time since epoch in seconds.</p>
<p><a href="../../tf/compat/v1/to_bfloat16.html"><code>to_bfloat16(...)</code></a>: Casts a tensor to type <code>bfloat16</code>. (deprecated)</p>
<p><a href="../../tf/compat/v1/to_complex128.html"><code>to_complex128(...)</code></a>: Casts a tensor to type <code>complex128</code>. (deprecated)</p>
<p><a href="../../tf/compat/v1/to_complex64.html"><code>to_complex64(...)</code></a>: Casts a tensor to type <code>complex64</code>. (deprecated)</p>
<p><a href="../../tf/compat/v1/to_double.html"><code>to_double(...)</code></a>: Casts a tensor to type <code>float64</code>. (deprecated)</p>
<p><a href="../../tf/compat/v1/to_float.html"><code>to_float(...)</code></a>: Casts a tensor to type <code>float32</code>. (deprecated)</p>
<p><a href="../../tf/compat/v1/to_int32.html"><code>to_int32(...)</code></a>: Casts a tensor to type <code>int32</code>. (deprecated)</p>
<p><a href="../../tf/compat/v1/to_int64.html"><code>to_int64(...)</code></a>: Casts a tensor to type <code>int64</code>. (deprecated)</p>
<p><a href="../../tf/linalg/trace.html"><code>trace(...)</code></a>: Compute the trace of a tensor <code>x</code>.</p>
<p><a href="../../tf/compat/v1/trainable_variables.html"><code>trainable_variables(...)</code></a>: Returns all variables created with <code>trainable=True</code>.</p>
<p><a href="../../tf/compat/v1/transpose.html"><code>transpose(...)</code></a>: Transposes <code>a</code>.</p>
<p><a href="../../tf/math/truediv.html"><code>truediv(...)</code></a>: Divides x / y elementwise (using Python 3 division operator semantics).</p>
<p><a href="../../tf/random/truncated_normal.html"><code>truncated_normal(...)</code></a>: Outputs random values from a truncated normal distribution.</p>
<p><a href="../../tf/truncatediv.html"><code>truncatediv(...)</code></a>: Returns x / y element-wise for integer types.</p>
<p><a href="../../tf/truncatemod.html"><code>truncatemod(...)</code></a>: Returns element-wise remainder of division. This emulates C semantics in that</p>
<p><a href="../../tf/compat/v1/tuple.html"><code>tuple(...)</code></a>: Group tensors together.</p>
<p><a href="../../tf/unique.html"><code>unique(...)</code></a>: Finds unique elements in a 1-D tensor.</p>
<p><a href="../../tf/unique_with_counts.html"><code>unique_with_counts(...)</code></a>: Finds unique elements in a 1-D tensor.</p>
<p><a href="../../tf/unravel_index.html"><code>unravel_index(...)</code></a>: Converts a flat index or array of flat indices into a tuple of</p>
<p><a href="../../tf/math/unsorted_segment_max.html"><code>unsorted_segment_max(...)</code></a>: Computes the maximum along segments of a tensor.</p>
<p><a href="../../tf/math/unsorted_segment_mean.html"><code>unsorted_segment_mean(...)</code></a>: Computes the mean along segments of a tensor.</p>
<p><a href="../../tf/math/unsorted_segment_min.html"><code>unsorted_segment_min(...)</code></a>: Computes the minimum along segments of a tensor.</p>
<p><a href="../../tf/math/unsorted_segment_prod.html"><code>unsorted_segment_prod(...)</code></a>: Computes the product along segments of a tensor.</p>
<p><a href="../../tf/math/unsorted_segment_sqrt_n.html"><code>unsorted_segment_sqrt_n(...)</code></a>: Computes the sum along segments of a tensor divided by the sqrt(N).</p>
<p><a href="../../tf/math/unsorted_segment_sum.html"><code>unsorted_segment_sum(...)</code></a>: Computes the sum along segments of a tensor.</p>
<p><a href="../../tf/unstack.html"><code>unstack(...)</code></a>: Unpacks the given dimension of a rank-<code>R</code> tensor into rank-<code>(R-1)</code> tensors.</p>
<p><a href="../../tf/compat/v1/variable_axis_size_partitioner.html"><code>variable_axis_size_partitioner(...)</code></a>: Get a partitioner for VariableScope to keep shards below <code>max_shard_bytes</code>.</p>
<p><a href="../../tf/compat/v1/variable_creator_scope.html"><code>variable_creator_scope(...)</code></a>: Scope which defines a variable creation function to be used by variable().</p>
<p><a href="../../tf/compat/v1/variable_op_scope.html"><code>variable_op_scope(...)</code></a>: Deprecated: context manager for defining an op that creates variables.</p>
<p><a href="../../tf/compat/v1/variables_initializer.html"><code>variables_initializer(...)</code></a>: Returns an Op that initializes a list of variables.</p>
<p><a href="../../tf/vectorized_map.html"><code>vectorized_map(...)</code></a>: Parallel map on the list of tensors unpacked from <code>elems</code> on dimension 0.</p>
<p><a href="../../tf/compat/v1/verify_tensor_all_finite.html"><code>verify_tensor_all_finite(...)</code></a>: Assert that the tensor does not contain any NaN's or Inf's.</p>
<p><a href="../../tf/compat/v1/where.html"><code>where(...)</code></a>: Return the elements, either from <code>x</code> or <code>y</code>, depending on the <code>condition</code>.</p>
<p><a href="../../tf/where.html"><code>where_v2(...)</code></a>: Return the elements, either from <code>x</code> or <code>y</code>, depending on the <code>condition</code>.</p>
<p><a href="../../tf/compat/v1/while_loop.html"><code>while_loop(...)</code></a>: Repeat <code>body</code> while the condition <code>cond</code> is true.</p>
<p><a href="../../tf/compat/v1/wrap_function.html"><code>wrap_function(...)</code></a>: Wraps the TF 1.x function fn into a graph function.</p>
<p><a href="../../tf/io/write_file.html"><code>write_file(...)</code></a>: Writes contents to the file at input filename. Creates file and recursively</p>
<p><a href="../../tf/zeros.html"><code>zeros(...)</code></a>: Creates a tensor with all elements set to zero.</p>
<p><a href="../../tf/compat/v1/zeros_like.html"><code>zeros_like(...)</code></a>: Creates a tensor with all elements set to zero.</p>
<p><a href="../../tf/math/zeta.html"><code>zeta(...)</code></a>: Compute the Hurwitz zeta function \(\zeta(x, q)\).</p>
<h2 id="other-members">Other Members</h2>
<ul>
<li><code>AUTO_REUSE</code> <a id="AUTO_REUSE"></a></li>
<li><code>COMPILER_VERSION = '7.3.1 20180303'</code> <a id="COMPILER_VERSION"></a></li>
<li><code>CXX11_ABI_FLAG = 0</code> <a id="CXX11_ABI_FLAG"></a></li>
<li><code>GIT_VERSION = 'v2.0.0-rc2-26-g64c3d38'</code> <a id="GIT_VERSION"></a></li>
<li><code>GRAPH_DEF_VERSION = 119</code> <a id="GRAPH_DEF_VERSION"></a></li>
<li><code>GRAPH_DEF_VERSION_MIN_CONSUMER = 0</code> <a id="GRAPH_DEF_VERSION_MIN_CONSUMER"></a></li>
<li><code>GRAPH_DEF_VERSION_MIN_PRODUCER = 0</code> <a id="GRAPH_DEF_VERSION_MIN_PRODUCER"></a></li>
<li><code>MONOLITHIC_BUILD = 0</code> <a id="MONOLITHIC_BUILD"></a></li>
<li><code>QUANTIZED_DTYPES</code> <a id="QUANTIZED_DTYPES"></a></li>
<li><code>VERSION = '2.0.0'</code> <a id="VERSION"></a></li>
<li><code>__version__ = '2.0.0'</code> <a id="__version__"></a></li>
<li><code>bfloat16</code> <a id="bfloat16"></a></li>
<li><code>bool</code> <a id="bool"></a></li>
<li><code>complex128</code> <a id="complex128"></a></li>
<li><code>complex64</code> <a id="complex64"></a></li>
<li><code>double</code> <a id="double"></a></li>
<li><code>float16</code> <a id="float16"></a></li>
<li><code>float32</code> <a id="float32"></a></li>
<li><code>float64</code> <a id="float64"></a></li>
<li><code>half</code> <a id="half"></a></li>
<li><code>int16</code> <a id="int16"></a></li>
<li><code>int32</code> <a id="int32"></a></li>
<li><code>int64</code> <a id="int64"></a></li>
<li><code>int8</code> <a id="int8"></a></li>
<li><code>qint16</code> <a id="qint16"></a></li>
<li><code>qint32</code> <a id="qint32"></a></li>
<li><code>qint8</code> <a id="qint8"></a></li>
<li><code>quint16</code> <a id="quint16"></a></li>
<li><code>quint8</code> <a id="quint8"></a></li>
<li><code>resource</code> <a id="resource"></a></li>
<li><code>string</code> <a id="string"></a></li>
<li><code>uint16</code> <a id="uint16"></a></li>
<li><code>uint32</code> <a id="uint32"></a></li>
<li><code>uint64</code> <a id="uint64"></a></li>
<li><code>uint8</code> <a id="uint8"></a></li>
<li><code>variant</code> <a id="variant"></a></li>
</ul>
    </body>
    </html>
   