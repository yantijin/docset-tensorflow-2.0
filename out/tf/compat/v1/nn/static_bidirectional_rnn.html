
    <html lang="zh-cn">
    <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <link href="../../../../../default.css" rel="stylesheet">
    <link href="
   ../../../../../github.css" rel="stylesheet">
    </head>
    <body>
    <div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.compat.v1.nn.static_bidirectional_rnn" />
<meta itemprop="path" content="Stable" />
</div>

<h1 id="tfcompatv1nnstatic_bidirectional_rnn">tf.compat.v1.nn.static_bidirectional_rnn</h1>
<!-- Insert buttons -->

<table class="tfo-notebook-buttons tfo-api" align="left">
</table>

<p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/ops/rnn.py">View source</a></p>
<!-- Start diff -->

<p>Creates a bidirectional recurrent neural network. (deprecated)</p>
<div class="codehilite"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">static_bidirectional_rnn</span><span class="p">(</span>
    <span class="n">cell_fw</span><span class="p">,</span>
    <span class="n">cell_bw</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">,</span>
    <span class="n">initial_state_fw</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">initial_state_bw</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sequence_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">scope</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</pre></div>


<!-- Placeholder for "Used in" -->

<p>Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
Instructions for updating:
Please use <code>keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))</code>, which is equivalent to this API</p>
<p>Similar to the unidirectional case above (rnn) but takes input and builds
independent forward and backward RNNs with the final forward and backward
outputs depth-concatenated, such that the output will have the format
[time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of
forward and backward cell must match. The initial state for both directions
is zero by default (but can be set optionally) and no intermediate states are
ever returned -- the network is fully unrolled for the given (passed in)
length(s) of the sequence(s) or completely unrolled if length(s) is not given.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>cell_fw</code></b>: An instance of RNNCell, to be used for forward direction.</li>
<li><b><code>cell_bw</code></b>: An instance of RNNCell, to be used for backward direction.</li>
<li><b><code>inputs</code></b>: A length T list of inputs, each a tensor of shape [batch_size,
  input_size], or a nested tuple of such elements.</li>
<li><b><code>initial_state_fw</code></b>: (optional) An initial state for the forward RNN. This must
  be a tensor of appropriate type and shape <code>[batch_size,
  cell_fw.state_size]</code>. If <code>cell_fw.state_size</code> is a tuple, this should be a
  tuple of tensors having shapes <code>[batch_size, s] for s in
  cell_fw.state_size</code>.</li>
<li><b><code>initial_state_bw</code></b>: (optional) Same as for <code>initial_state_fw</code>, but using the
  corresponding properties of <code>cell_bw</code>.</li>
<li><b><code>dtype</code></b>: (optional) The data type for the initial state.  Required if either
  of the initial states are not provided.</li>
<li><b><code>sequence_length</code></b>: (optional) An int32/int64 vector, size <code>[batch_size]</code>,
  containing the actual lengths for each of the sequences.</li>
<li><b><code>scope</code></b>: VariableScope for the created subgraph; defaults to
  "bidirectional_rnn"</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A tuple (outputs, output_state_fw, output_state_bw) where:
  outputs is a length <code>T</code> list of outputs (one for each input), which
    are depth-concatenated forward and backward outputs.
  output_state_fw is the final state of the forward rnn.
  output_state_bw is the final state of the backward rnn.</p>
<h4 id="raises">Raises:</h4>
<ul>
<li><b><code>TypeError</code></b>: If <code>cell_fw</code> or <code>cell_bw</code> is not an instance of <code>RNNCell</code>.</li>
<li><b><code>ValueError</code></b>: If inputs is None or an empty list.</li>
</ul>
    </body>
    </html>
   