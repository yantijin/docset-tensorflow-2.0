
    <html lang="zh-cn">
    <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <link href="../../default.css" rel="stylesheet">
    <link href="
   ../../github.css" rel="stylesheet">
    </head>
    <body>
    <div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tf.recompute_grad" />
<meta itemprop="path" content="Stable" />
</div>

<h1 id="tfrecompute_grad">tf.recompute_grad</h1>
<!-- Insert buttons -->

<table class="tfo-notebook-buttons tfo-api" align="left">
</table>

<p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/ops/custom_gradient.py">View source</a></p>
<!-- Start diff -->

<p>An eager-compatible version of recompute_grad.</p>
<h3 id="aliases">Aliases:</h3>
<ul>
<li><code>tf.compat.v1.recompute_grad</code></li>
<li><code>tf.compat.v2.recompute_grad</code></li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">recompute_grad</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>


<!-- Placeholder for "Used in" -->

<p>For f(<em>args, </em>*kwargs), this supports gradients with respect to args, or to
gradients with respect to any variables residing in the kwarg 'variables'.
Note that for keras layer and model objects, this is handled automatically.</p>
<p>Warning: If <code>f</code> was originally a tf.keras Model or Layer object, <code>g</code> will not
be able to access the member variables of that object, because <code>g</code> returns
through the wrapper function <code>inner</code>.  When recomputing gradients through
objects that inherit from keras, we suggest keeping a reference to the
underlying object around for the purpose of accessing these variables.</p>
<h4 id="args">Args:</h4>
<ul>
<li><b><code>f</code></b>: function <code>f(*x)</code> that returns a <code>Tensor</code> or sequence of <code>Tensor</code> outputs.</li>
</ul>
<h4 id="returns">Returns:</h4>
<p>A function <code>g</code> that wraps <code>f</code>, but which recomputes <code>f</code> on the backwards
pass of a gradient call.</p>
    </body>
    </html>
   